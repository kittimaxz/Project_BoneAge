{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWMVOrfoiR9NI2VCXOROC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittimaxz/Project_BoneAge/blob/main/Test_BoNet_RSNA_RHPE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BCV-Uniandes/Bonet.git\n",
        "!cd Bonet"
      ],
      "metadata": {
        "id": "8YshQVzWho78",
        "outputId": "d056c41f-a35b-4bc2-c175-dc5fd62cb412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Bonet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra # เป็นการ import numpy เพื่อเปิดใช้ฟังก์ชันในการทำงาน\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # เป็น library ในการจัดการ dataframe"
      ],
      "metadata": {
        "id": "Kno738cbwESa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Bonet"
      ],
      "metadata": {
        "id": "Wj-RW6EuI2-k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard lib imports\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import time\n",
        "import argparse\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os.path as osp"
      ],
      "metadata": {
        "id": "ZUsIgmmk7D3i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "!pip install horovod\n",
        "import horovod.torch as hvd\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmNDPKn09VZh",
        "outputId": "8e6ea488-b26a-49c6-d49e-545898244993"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: horovod in /usr/local/lib/python3.8/dist-packages (0.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from horovod) (5.4.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from horovod) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from horovod) (1.15.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from horovod) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from horovod) (21.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.4.0->horovod) (2.21)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->horovod) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other imports\n",
        "from tqdm import tqdm\n",
        "import pdb"
      ],
      "metadata": {
        "id": "iLQexxu090bz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "objPvC22OY0j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()"
      ],
      "metadata": {
        "id": "mtKHhSaJOd6V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloading-related settings\n",
        "parser.add_argument('--heatmaps', default=False, action='store_true',\n",
        "                help='Train model with gaussian heatmaps')\n",
        "parser.add_argument('--cropped', default=False, action='store_true',\n",
        "                help='Train model with cropped images according to bbox')\n",
        "parser.add_argument('--dataset', default='RSNA', type=str,choices=['RSNA','RHPE'],\n",
        "                help='Dataset to perform training')\n",
        "\n",
        "parser.add_argument('--data-train', default='data/train/', type=str,\n",
        "                help='path to train data folder')\n",
        "parser.add_argument('--ann-path-train', default='train.csv', type=str,\n",
        "                help='path to BAA annotations file')\n",
        "parser.add_argument('--rois-path-train', default='train.json',\n",
        "                type=str, help='path to ROIs annotations in coco format')\n",
        "\n",
        "parser.add_argument('--data-val', default='data/val/', type=str,\n",
        "                help='path to val data folder')\n",
        "parser.add_argument('--ann-path-val', default='val.csv', type=str,\n",
        "                help='path to BAA annotations file')\n",
        "parser.add_argument('--rois-path-val', default='val.json',\n",
        "                type=str, help='path to ROIs annotations in coco format')\n",
        "\n",
        "parser.add_argument('--save-folder', default='TRAIN/new_test/',\n",
        "                help='location to save checkpoint models')\n",
        "parser.add_argument('--snapshot', default='boneage_bonet_weights.pth',\n",
        "                help='path to weight snapshot file')\n",
        "parser.add_argument('--optim-snapshot', type=str,\n",
        "                default='boneage_bonet_optim.pth',\n",
        "                help='path to optimizer state snapshot')\n",
        "\n",
        "parser.add_argument('--eval-first', default=False, action='store_true',\n",
        "                help='evaluate model weights before training')\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                help='number of data loading workers (default: 4)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp2pcxr_Ogb-",
        "outputId": "20195846-2b6b-48c8-c97c-eba29dc3b605"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['-j', '--workers'], dest='workers', nargs=None, const=None, default=4, type=<class 'int'>, choices=None, help='number of data loading workers (default: 4)', metavar='N')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training procedure settings\n",
        "parser.add_argument('--batch-size', default=1, type=int,\n",
        "                help='Batch size for training')\n",
        "parser.add_argument('--epochs', type=int, default=20,\n",
        "                help='upper epoch limit')\n",
        "parser.add_argument('--lr', '--learning-rate', default=1e-5, type=float,\n",
        "                help='initial learning rate')\n",
        "parser.add_argument('--patience', default=2, type=int,\n",
        "                help='patience epochs for LR decreasing')\n",
        "parser.add_argument('--start-epoch', type=int, default=1,\n",
        "                help='epoch number to resume')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--log-interval', type=int, default=30, metavar='N',\n",
        "                    help='report interval')\n",
        "\n",
        "parser.add_argument('--gpu', type=str, default='2,3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A93-WbbOlk8",
        "outputId": "247af2b3-6499-4413-94f5-d94539647608"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--gpu'], dest='gpu', nargs=None, const=None, default='2,3', type=<class 'str'>, choices=None, help=None, metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args(args=[])\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at1glcMbOpVd",
        "outputId": "56688e77-211b-4853-9f44-d9e3e76822bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(ann_path_train='train.csv', ann_path_val='val.csv', batch_size=1, cropped=False, data_train='data/train/', data_val='data/val/', dataset='RSNA', epochs=20, eval_first=False, gpu='2,3', heatmaps=False, log_interval=30, lr=1e-05, optim_snapshot='boneage_bonet_optim.pth', patience=2, rois_path_train='train.json', rois_path_val='val.json', save_folder='TRAIN/new_test/', seed=1111, snapshot='boneage_bonet_weights.pth', start_epoch=1, workers=4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args_dict = vars(args)\n",
        "print('Argument list to program')\n",
        "print('\\n'.join(['--{0} {1}'.format(arg, args_dict[arg])\n",
        "                 for arg in args_dict]))\n",
        "print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AW-AjPHOsBr",
        "outputId": "59f2a927-b9d6-4f3a-f66f-6a4e8b289dec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argument list to program\n",
            "--heatmaps False\n",
            "--cropped False\n",
            "--dataset RSNA\n",
            "--data_train data/train/\n",
            "--ann_path_train train.csv\n",
            "--rois_path_train train.json\n",
            "--data_val data/val/\n",
            "--ann_path_val val.csv\n",
            "--rois_path_val val.json\n",
            "--save_folder TRAIN/new_test/\n",
            "--snapshot boneage_bonet_weights.pth\n",
            "--optim_snapshot boneage_bonet_optim.pth\n",
            "--eval_first False\n",
            "--workers 4\n",
            "--batch_size 1\n",
            "--epochs 20\n",
            "--lr 1e-05\n",
            "--patience 2\n",
            "--start_epoch 1\n",
            "--seed 1111\n",
            "--log_interval 30\n",
            "--gpu 2,3\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(args.seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu"
      ],
      "metadata": {
        "id": "ynHsTVUyPR3L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(args.save_folder):\n",
        "    os.makedirs(args.save_folder)"
      ],
      "metadata": {
        "id": "aAKAmLh-aNrs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horovod settings\n",
        "hvd.init()\n",
        "torch.cuda.set_device(hvd.local_rank())\n",
        "torch.cuda.manual_seed(hvd.size())\n",
        "\n",
        "args.distributed = hvd.size() > 1\n",
        "args.rank = hvd.rank()\n",
        "args.size = hvd.size()"
      ],
      "metadata": {
        "id": "y_4mmkjjaQ0y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE NETWORK ARCHITECTURE AND LOAD THE BEST MODEL\n",
        "if args.heatmaps:\n",
        "    from Bonet.models.bonet_heatmap import BoNet\n",
        "else:\n",
        "    from Bonet.models.bonet import BoNet"
      ],
      "metadata": {
        "id": "cOp2XVL1bQnd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = BoNet()"
      ],
      "metadata": {
        "id": "4wnyiJE8iFIx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.rank == 0:\n",
        "    print('---> Number of params: {}'.format(\n",
        "        sum([p.data.nelement() for p in net.parameters()])))"
      ],
      "metadata": {
        "id": "DUkrLDWvM47E",
        "outputId": "57826536-b952-44f4-8d29-42dbe6ed78ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---> Number of params: 123172057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if osp.exists(args.snapshot):\n",
        "    model_to_load=args.snapshot\n",
        "else:\n",
        "    model_to_load=args.save_folder+'/'+args.snapshot"
      ],
      "metadata": {
        "id": "Hpw0q-P2M9s_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if osp.exists(model_to_load) and args.rank == 0:\n",
        "    print('Loading state dict from: {0}'.format(model_to_load))\n",
        "    snapshot_dict = torch.load(model_to_load, map_location=lambda storage, loc: storage)\n",
        "    weights= net.state_dict()\n",
        "    new_snapshot_dict=snapshot_dict.copy()\n",
        "    for key in snapshot_dict:\n",
        "        if key not in weights.keys():\n",
        "            new_key='inception_v3.'+key\n",
        "            new_snapshot_dict[new_key]=snapshot_dict[key]\n",
        "            new_snapshot_dict.pop(key)\n",
        "\n",
        "    net.load_state_dict(new_snapshot_dict)\n",
        "\n",
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "cruc2f2ANA9r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criterion\n",
        "criterion = nn.L1Loss()"
      ],
      "metadata": {
        "id": "yJb-U7sHNHeb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=args.lr * args.size)\n",
        "annealing = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.8, patience=args.patience, cooldown=5,\n",
        "    min_lr=0.00001, eps=0.00001, verbose=True)"
      ],
      "metadata": {
        "id": "GLR2PzBPNMKf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if osp.exists(args.optim_snapshot):\n",
        "    optim_to_load=args.optim_snapshot\n",
        "else:\n",
        "    optim_to_load=args.save_folder+'/'+args.optim_snapshot"
      ],
      "metadata": {
        "id": "hpOplrbLNOdf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if osp.exists(optim_to_load):\n",
        "    print('loading optim snapshot from {}'.format(optim_to_load))\n",
        "    optimizer.load_state_dict(torch.load(optim_to_load, map_location=lambda storage,\n",
        "                                             loc: storage))"
      ],
      "metadata": {
        "id": "qX4XgnLzNQab"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Horovod\n",
        "hvd.broadcast_parameters(net.state_dict(), root_rank=0)\n",
        "\n",
        "optimizer = hvd.DistributedOptimizer(\n",
        "    optimizer, named_parameters=net.named_parameters())\n",
        "hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n",
        "group = optimizer.param_groups[0]\n",
        "group['betas'] = (float(group['betas'][0]), float(group['betas'][1]))"
      ],
      "metadata": {
        "id": "BrsWh5qgNSej"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders\n",
        "train_transform = transforms.Compose([transforms.Resize((500, 500)),\n",
        "                               transforms.RandomAffine(\n",
        "                                   20, translate=(0.2, 0.2),\n",
        "                                   scale=(1, 1.2)),\n",
        "                               transforms.RandomHorizontalFlip(),\n",
        "                               transforms.ToTensor()])\n",
        "train_transform"
      ],
      "metadata": {
        "id": "O2-014AENVBn",
        "outputId": "46d8363a-84cb-443b-badd-c38041a006ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(500, 500), interpolation=bilinear, max_size=None, antialias=None)\n",
              "    RandomAffine(degrees=[-20.0, 20.0], translate=(0.2, 0.2), scale=(1, 1.2))\n",
              "    RandomHorizontalFlip(p=0.5)\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([transforms.Resize((500, 500)),\n",
        "                               transforms.ToTensor()])\n",
        "val_transform"
      ],
      "metadata": {
        "id": "tw_6cAedNa9X",
        "outputId": "6ac50a66-2e18-44da-ca4b-35fa83caa2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(500, 500), interpolation=bilinear, max_size=None, antialias=None)\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.heatmaps:\n",
        "    from Bonet.data.data_loader import Boneage_HeatmapDataset as Dataset\n",
        "else:\n",
        "    from Bonet.data.data_loader import BoneageDataset as Dataset"
      ],
      "metadata": {
        "id": "aWBrf3eVN6Gi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(args.data_train, args.ann_path_train,args.rois_path_train,\n",
        "                                   img_transform=train_transform,crop=args.cropped,dataset=args.dataset)\n",
        "val_dataset = Dataset(args.data_val, args.ann_path_val,args.rois_path_val,\n",
        "                                 img_transform=val_transform,crop=args.cropped,dataset=args.dataset)"
      ],
      "metadata": {
        "id": "8SUYw4WvOkfU",
        "outputId": "9f02f0cc-b1e7-48c0-df38-7750c672be3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-27d48f94c0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = Dataset(args.data_train, args.ann_path_train,args.rois_path_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    img_transform=train_transform,crop=args.cropped,dataset=args.dataset)\n\u001b[1;32m      3\u001b[0m val_dataset = Dataset(args.data_val, args.ann_path_val,args.rois_path_val,\n\u001b[1;32m      4\u001b[0m                                  img_transform=val_transform,crop=args.cropped,dataset=args.dataset)\n",
            "\u001b[0;32m/content/Bonet/data/data_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir, ann_file, json_file, img_transform, crop, dataset)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,dtype=object)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    }
  ]
}