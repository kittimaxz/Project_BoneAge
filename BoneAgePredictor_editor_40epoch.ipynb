{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kittimaxz/Project_BoneAge/blob/main/BoneAgePredictor_editor_40epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import skimage.transform\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "pduFNGhc55Dw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # เชื่อม drive ของเรา ถ้าเชื่อมสำเร็จจะขึ้นคำว่าMounted at /content/drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnsm5FPI6met",
        "outputId": "e31b824b-cf60-4b63-ce7f-486d7fa1ff0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_path(*rel_path):\n",
        "    return os.path.join('/content/drive/My Drive/Project_Boneage', *rel_path);"
      ],
      "metadata": {
        "id": "aJrvhf4DLz6e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "rC0vbsIGL0iC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoneAgeTrainingDataset(Dataset):\n",
        "    def __init__(self,csv_path,img_folder):\n",
        "        self.csv = pd.read_csv(dataset_path(csv_path));\n",
        "        self.img_folder = img_folder;        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        male = np.array([1]) if (self.csv['male'][idx] == 'TRUE') else np.array([0])\n",
        "        return transform(Image.open(dataset_path(self.img_folder,str(self.csv['id'][idx])+'.png')).resize((256,256))).double(),\\\n",
        "               torch.from_numpy(np.array(self.csv['boneage'][idx])).double(),\\\n",
        "               torch.from_numpy(male).double()"
      ],
      "metadata": {
        "id": "0z8xCq3zL3FH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoneAgeValidationDataset(Dataset):\n",
        "    def __init__(self,csv_path,img_folder):\n",
        "        self.csv = pd.read_csv(dataset_path(csv_path));\n",
        "        self.img_folder = img_folder;        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        male = np.array([1]) if (self.csv['male'][idx] == 'TRUE') else np.array([0])\n",
        "        return transform(Image.open(dataset_path(self.img_folder,str(self.csv['id'][idx])+'.png')).resize((256,256))).double(),\\\n",
        "               torch.from_numpy(np.array(self.csv['boneage'][idx])).double(),\\\n",
        "               torch.from_numpy(male).double()"
      ],
      "metadata": {
        "id": "bVfRU1l-L5Cs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_model = torch.load('/content/drive/My Drive/Project_Boneage/model-weight/model_1.pth')\n",
        "state_model"
      ],
      "metadata": {
        "id": "JG9uMc7NIRl5",
        "outputId": "70080188-e917-43da-bf9b-3bd1fb051e18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 20,\n",
              " 'train_loss': [28.353672330379336,\n",
              "  19.710847054320194,\n",
              "  19.51972219580259,\n",
              "  16.29548190658947,\n",
              "  15.50649901241298,\n",
              "  14.998880133864493,\n",
              "  13.418039646991513,\n",
              "  12.62556178687756,\n",
              "  11.683637718728496,\n",
              "  10.551020275444667,\n",
              "  11.090826994635924,\n",
              "  11.151380214214072,\n",
              "  9.43952403048509,\n",
              "  9.9742263734937,\n",
              "  8.458766399670786,\n",
              "  7.828151191525706,\n",
              "  8.212304508225682,\n",
              "  10.175536312299519,\n",
              "  9.632327163577209,\n",
              "  5.287516447717074],\n",
              " 'val_loss': [27.749473292705126,\n",
              "  16.635473862342245,\n",
              "  15.473569759168862,\n",
              "  14.952480410337062,\n",
              "  14.424107741554623,\n",
              "  14.562585181593033,\n",
              "  13.791616215549167,\n",
              "  13.063095126096107,\n",
              "  12.964469003324773,\n",
              "  12.828109000405451,\n",
              "  13.160015021456244,\n",
              "  13.378300669675513,\n",
              "  12.299280365422602,\n",
              "  13.07167924074644,\n",
              "  12.177992400209318,\n",
              "  11.75570358319044,\n",
              "  12.545062198853143,\n",
              "  14.265497366204208,\n",
              "  12.914326647892374,\n",
              "  11.333223239568529],\n",
              " 'state_dict': OrderedDict([('conv1.weight',\n",
              "               tensor([[[[-0.7045,  0.3546,  0.2245],\n",
              "                         [ 0.6008, -0.4599,  0.1262],\n",
              "                         [-0.0488,  0.2693, -0.4736]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.6555, -0.2186,  1.2564],\n",
              "                         [-0.2983, -0.4273, -0.1435],\n",
              "                         [-0.2184, -0.1488, -0.4374]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.3209,  0.0649, -0.2703],\n",
              "                         [-0.7867, -1.0204, -0.0575],\n",
              "                         [-0.4928, -0.4679, -1.3332]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.1611,  0.4769, -0.1942],\n",
              "                         [ 0.0567, -0.8493,  0.0937],\n",
              "                         [-0.4017,  0.8739,  0.1299]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.4765,  0.1090,  0.3230],\n",
              "                         [-0.5248, -0.4769, -1.0578],\n",
              "                         [-0.5168, -0.6631, -0.6374]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.7195, -0.1442, -0.0452],\n",
              "                         [ 0.1821,  0.3726, -1.3239],\n",
              "                         [ 0.2004,  0.4818, -0.1088]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.2185,  0.2461,  0.4638],\n",
              "                         [ 0.0521, -0.7114, -0.2819],\n",
              "                         [-0.0572,  0.1411,  0.2593]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.0558, -0.4593, -0.5207],\n",
              "                         [-0.5868,  0.1180,  0.1213],\n",
              "                         [ 0.7951, -0.1735,  0.5088]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.5823, -0.3491, -0.1119],\n",
              "                         [ 0.7522,  0.0852,  0.5233],\n",
              "                         [-0.6656, -0.3755, -0.4609]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.1637, -0.3788, -0.0116],\n",
              "                         [ 0.3038, -0.9282,  0.0960],\n",
              "                         [ 0.4478,  0.9007, -0.6027]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.2898, -0.2664,  0.2628],\n",
              "                         [ 0.6572,  0.4510,  0.1754],\n",
              "                         [-0.0429,  0.1681,  0.7739]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.2866, -0.2305, -0.3146],\n",
              "                         [ 0.6265, -0.0027, -0.2447],\n",
              "                         [ 0.4211, -0.5660, -1.3523]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.1620,  0.2169, -0.7810],\n",
              "                         [ 0.3931,  0.8438,  0.2007],\n",
              "                         [ 0.5290,  0.5269,  0.3014]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.1841, -1.0697,  0.3778],\n",
              "                         [-0.1193,  0.4312,  0.3554],\n",
              "                         [ 0.1222,  0.4409, -0.2096]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.4628,  0.1810,  0.3237],\n",
              "                         [-0.3020,  0.9538,  0.1597],\n",
              "                         [-1.2027,  0.0459,  0.2878]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.2619, -0.7655, -0.3000],\n",
              "                         [ 0.1617, -0.4846, -0.2968],\n",
              "                         [-0.0739,  0.8023,  1.2058]]]], dtype=torch.float64)),\n",
              "              ('conv1.bias',\n",
              "               tensor([ 0.2171,  0.1973,  0.0818,  0.2396, -0.0975,  0.0731, -0.2225, -0.0083,\n",
              "                       -0.3042, -0.2754,  0.1257,  0.0561, -0.2391, -0.0801,  0.1835, -0.0055],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch1.weight',\n",
              "               tensor([0.8622, 1.2135, 0.7457, 0.9021, 0.7516, 0.7451, 0.9189, 0.8970, 1.0997,\n",
              "                       1.3428, 0.5125, 0.7930, 0.5993, 0.6848, 1.1117, 1.3604],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch1.bias',\n",
              "               tensor([-0.1666,  0.0912, -0.2427,  0.0046, -0.1529, -0.1750, -0.2097, -0.3131,\n",
              "                        0.1386,  0.1698, -0.0741, -0.2188,  0.0224,  0.0311, -0.1255,  0.1282],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch1.running_mean',\n",
              "               tensor([ 0.1966,  0.1995, -0.7807,  0.2446, -0.6449,  0.1352, -0.2421, -0.0540,\n",
              "                       -0.3085, -0.2763,  0.5801, -0.1971,  0.2018, -0.0534,  0.1801, -0.0064],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch1.running_var',\n",
              "               tensor([7.0055e-04, 3.4450e-03, 7.3658e-01, 6.5996e-04, 3.0147e-01, 8.8860e-03,\n",
              "                       1.0397e-03, 4.4131e-03, 2.3187e-03, 2.2504e-03, 2.0413e-01, 7.1397e-02,\n",
              "                       1.9663e-01, 2.2956e-03, 6.1207e-03, 6.0989e-03], dtype=torch.float64)),\n",
              "              ('batch1.num_batches_tracked', tensor(6320)),\n",
              "              ('conv2.weight',\n",
              "               tensor([[[[ 1.5218e-01, -4.3163e-02, -9.6726e-02],\n",
              "                         [-5.3097e-02, -6.8594e-02, -1.5748e-02],\n",
              "                         [-1.4202e-01, -2.2084e-01, -2.5241e-02]],\n",
              "               \n",
              "                        [[ 2.4966e-02, -2.2946e-01, -1.3400e-01],\n",
              "                         [-3.9222e-02,  8.8735e-02, -1.4263e-01],\n",
              "                         [-3.2824e-01, -1.8097e-01, -2.3114e-01]],\n",
              "               \n",
              "                        [[ 9.7929e-02, -1.3241e-01, -1.1675e-02],\n",
              "                         [-1.0966e-01,  7.9786e-02,  9.1450e-02],\n",
              "                         [ 1.0577e-01, -1.5636e-01,  1.8495e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-4.7079e-02, -2.3097e-01, -4.6169e-02],\n",
              "                         [ 2.6414e-01, -2.3775e-01, -1.2729e-01],\n",
              "                         [-1.2036e-01, -1.6355e-01, -2.0716e-01]],\n",
              "               \n",
              "                        [[ 1.1798e-02,  2.0669e-01, -1.2933e-01],\n",
              "                         [-2.3104e-02, -3.4386e-01, -5.3312e-02],\n",
              "                         [-2.1303e-01, -1.6614e-01,  1.4677e-01]],\n",
              "               \n",
              "                        [[-1.0673e-01, -1.6273e-01,  6.0949e-02],\n",
              "                         [-1.4339e-01, -2.0169e-01, -1.4892e-01],\n",
              "                         [ 2.0952e-01,  3.2093e-02, -8.9595e-02]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 7.2513e-02,  6.7268e-02, -9.0911e-02],\n",
              "                         [ 6.9251e-03, -2.8581e-02, -9.6010e-02],\n",
              "                         [-1.0067e-01, -1.5271e-01, -5.8402e-02]],\n",
              "               \n",
              "                        [[ 2.3124e-01,  1.7006e-01,  9.1205e-02],\n",
              "                         [-4.1978e-02, -2.1880e-01,  3.6085e-02],\n",
              "                         [ 1.6376e-01,  1.5669e-01,  6.6028e-02]],\n",
              "               \n",
              "                        [[ 2.7454e-01,  8.0351e-02, -2.3461e-01],\n",
              "                         [-5.8548e-02, -6.1285e-03,  1.1887e-02],\n",
              "                         [ 4.3605e-02,  2.6838e-01,  1.4235e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-1.9670e-01,  9.2697e-03,  1.0045e-02],\n",
              "                         [ 8.5123e-02,  1.2559e-01, -2.0060e-02],\n",
              "                         [-2.1763e-01, -9.9671e-02,  2.7726e-02]],\n",
              "               \n",
              "                        [[ 9.3614e-03, -1.1363e-01,  3.4469e-02],\n",
              "                         [ 4.0043e-01,  1.1739e-01, -5.1980e-02],\n",
              "                         [ 1.7915e-01,  9.1259e-02, -4.1462e-02]],\n",
              "               \n",
              "                        [[-7.8673e-02, -1.6349e-01,  2.2479e-01],\n",
              "                         [-3.9262e-02,  1.5790e-01,  3.1294e-02],\n",
              "                         [-2.2862e-01, -1.7614e-01, -2.3886e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 7.7413e-03,  1.0580e-01,  1.6866e-01],\n",
              "                         [ 1.3256e-01, -1.6977e-01,  2.1598e-01],\n",
              "                         [ 4.9591e-02,  2.7044e-01,  4.0018e-02]],\n",
              "               \n",
              "                        [[ 1.3798e-02, -1.4355e-01, -1.6552e-01],\n",
              "                         [ 3.8041e-02, -3.3459e-01, -7.2771e-02],\n",
              "                         [ 9.0330e-03, -1.7183e-01,  1.6509e-02]],\n",
              "               \n",
              "                        [[ 2.7802e-02,  7.6341e-02, -1.5222e-01],\n",
              "                         [-2.0071e-01, -6.4691e-02, -1.8000e-01],\n",
              "                         [-1.1529e-01, -1.9799e-01,  9.1351e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 4.8342e-04, -1.1225e-01, -2.1143e-01],\n",
              "                         [ 1.2360e-01, -2.5729e-01, -9.3531e-02],\n",
              "                         [-2.5425e-01, -2.4543e-01,  7.1082e-03]],\n",
              "               \n",
              "                        [[ 3.4596e-02, -3.4155e-02,  1.2631e-01],\n",
              "                         [ 6.0211e-02, -6.2392e-02,  1.0391e-01],\n",
              "                         [ 8.9614e-02, -2.1089e-01,  2.0057e-01]],\n",
              "               \n",
              "                        [[ 1.8962e-01,  1.8588e-01,  5.1415e-02],\n",
              "                         [ 7.8211e-02,  1.7274e-01,  5.5632e-02],\n",
              "                         [ 3.5868e-02,  5.6012e-02,  2.4171e-01]]],\n",
              "               \n",
              "               \n",
              "                       ...,\n",
              "               \n",
              "               \n",
              "                       [[[ 5.9412e-02, -1.4108e-01, -1.5276e-01],\n",
              "                         [ 9.4773e-02, -3.5704e-01, -2.4018e-02],\n",
              "                         [-6.6974e-02, -2.5991e-01, -1.8969e-01]],\n",
              "               \n",
              "                        [[ 4.0512e-02,  5.6470e-02, -3.9300e-03],\n",
              "                         [ 1.9147e-01, -6.7164e-02,  9.3694e-02],\n",
              "                         [ 1.8462e-01,  3.0211e-01,  1.2992e-01]],\n",
              "               \n",
              "                        [[-1.2271e-01, -1.1628e-01, -1.1510e-01],\n",
              "                         [-1.4441e-01,  2.3034e-02, -8.9869e-02],\n",
              "                         [ 7.5194e-02,  1.8259e-01,  1.2786e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 4.3120e-02, -7.2054e-02,  5.9172e-02],\n",
              "                         [-1.6923e-01, -1.5336e-01, -7.2970e-02],\n",
              "                         [-3.1596e-01, -1.6255e-01,  1.1883e-01]],\n",
              "               \n",
              "                        [[ 2.0193e-02, -7.1341e-02,  1.6223e-01],\n",
              "                         [-1.4775e-01, -1.4575e-01,  9.5704e-02],\n",
              "                         [-4.5265e-02, -1.7838e-01, -2.0738e-03]],\n",
              "               \n",
              "                        [[ 2.1193e-01,  2.4012e-01, -1.3142e-01],\n",
              "                         [-1.0489e-01,  1.1147e-01,  3.3088e-01],\n",
              "                         [ 5.5729e-02, -1.2770e-01,  2.6209e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[-6.2538e-04,  8.3070e-02, -1.7077e-01],\n",
              "                         [-1.3418e-01,  1.5611e-02, -1.6878e-02],\n",
              "                         [-1.3724e-01, -1.5642e-02, -2.1322e-01]],\n",
              "               \n",
              "                        [[ 6.0011e-03,  1.4355e-01, -1.1149e-01],\n",
              "                         [-8.9971e-02, -4.2377e-01, -1.2825e-01],\n",
              "                         [-1.3461e-02,  1.5281e-01,  4.1447e-02]],\n",
              "               \n",
              "                        [[-1.1624e-01,  2.2027e-01, -5.1207e-02],\n",
              "                         [ 4.7724e-02, -1.2459e-01, -3.4903e-02],\n",
              "                         [ 2.1685e-01, -2.4309e-03, -2.4590e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-4.8337e-02,  1.5499e-01, -7.1820e-02],\n",
              "                         [-1.3893e-01,  1.1025e-01,  1.7378e-01],\n",
              "                         [-2.1731e-02,  6.6939e-02, -2.6404e-01]],\n",
              "               \n",
              "                        [[-1.6644e-01, -8.5647e-03,  5.7197e-02],\n",
              "                         [-2.1124e-01, -2.4513e-01,  2.2481e-02],\n",
              "                         [-1.0200e-01, -2.6819e-01, -8.9685e-02]],\n",
              "               \n",
              "                        [[-7.0870e-02,  1.9797e-04,  1.7578e-01],\n",
              "                         [ 2.5533e-01,  8.8203e-02,  1.2610e-01],\n",
              "                         [ 1.1081e-01, -4.4231e-01, -5.5663e-02]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 1.8444e-02,  1.1041e-01,  2.0498e-02],\n",
              "                         [-2.5516e-01,  6.8738e-02,  5.1084e-02],\n",
              "                         [-1.4975e-01, -2.2777e-01, -8.6466e-02]],\n",
              "               \n",
              "                        [[ 9.7401e-03,  1.4167e-01,  9.0261e-02],\n",
              "                         [ 1.8338e-02, -1.6942e-02,  3.6981e-02],\n",
              "                         [-2.7404e-01, -7.4354e-02, -6.8350e-03]],\n",
              "               \n",
              "                        [[ 4.3415e-02,  6.5964e-02,  4.0716e-02],\n",
              "                         [ 8.9078e-02, -2.4892e-02, -1.7909e-01],\n",
              "                         [-1.4121e-02,  2.4811e-01,  1.1265e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 1.1345e-01, -9.4975e-02, -4.0345e-02],\n",
              "                         [-1.4006e-01, -2.2581e-02, -8.1048e-02],\n",
              "                         [ 5.0951e-04, -1.1501e-01, -1.1484e-01]],\n",
              "               \n",
              "                        [[-7.8352e-02,  2.3159e-01,  8.3379e-03],\n",
              "                         [-2.9253e-01, -1.3841e-01, -1.7359e-01],\n",
              "                         [-2.5595e-01,  4.4549e-03, -3.2531e-02]],\n",
              "               \n",
              "                        [[ 3.7288e-01, -8.8166e-03, -1.8310e-01],\n",
              "                         [ 3.2352e-02,  9.8903e-02, -2.4952e-01],\n",
              "                         [-1.9888e-01, -1.4882e-02, -1.7234e-01]]]], dtype=torch.float64)),\n",
              "              ('conv2.bias',\n",
              "               tensor([ 4.7222e-02,  2.9672e-02, -7.9204e-02,  3.0804e-02, -8.1422e-02,\n",
              "                        7.7022e-02,  3.2226e-02, -2.1289e-03, -3.2270e-02, -8.1350e-02,\n",
              "                       -2.9083e-02,  3.1229e-02,  4.7763e-02,  1.9432e-03,  7.4434e-02,\n",
              "                        3.6619e-02,  7.9674e-02, -6.4176e-05,  5.7970e-02,  2.7478e-02,\n",
              "                       -7.3661e-02, -7.2835e-02, -1.7178e-02,  6.8341e-02,  1.7728e-02,\n",
              "                       -6.7666e-02,  2.4070e-02,  4.6377e-03,  1.9970e-02,  6.3350e-02,\n",
              "                       -6.3860e-02, -6.2987e-02], dtype=torch.float64)),\n",
              "              ('batch2.weight',\n",
              "               tensor([0.8822, 0.8700, 0.8396, 1.1100, 1.0894, 0.9834, 1.2630, 1.1809, 0.8956,\n",
              "                       0.9642, 0.9007, 1.0011, 0.8214, 1.2506, 1.1188, 0.9567, 1.0718, 0.7723,\n",
              "                       1.1441, 1.0416, 0.9389, 1.0854, 1.2544, 1.0522, 1.0378, 1.0409, 0.7852,\n",
              "                       0.9249, 0.9427, 0.8075, 1.0750, 0.9921], dtype=torch.float64)),\n",
              "              ('batch2.bias',\n",
              "               tensor([-0.1935, -0.1372, -0.0590,  0.0650,  0.0709,  0.0225, -0.0385, -0.0240,\n",
              "                        0.0049, -0.0704, -0.1642, -0.0232, -0.2345, -0.0625, -0.0676, -0.0035,\n",
              "                       -0.0540, -0.0864, -0.1043, -0.0143, -0.1064, -0.2171,  0.0553, -0.0664,\n",
              "                       -0.0637, -0.0200, -0.0843, -0.0617, -0.0360, -0.1890,  0.0436, -0.1289],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch2.running_mean',\n",
              "               tensor([-1.8704, -0.4896, -1.4297, -0.6970, -0.1795,  0.2346, -0.5826, -0.0511,\n",
              "                        0.1783, -0.6783,  0.4785, -0.5192,  0.6983, -1.3675, -0.5360, -0.0632,\n",
              "                       -0.0265, -0.0787, -0.1372, -0.5183, -1.2246, -0.8244, -1.6398, -1.6064,\n",
              "                       -0.0926, -1.3104,  1.4956, -0.0913, -2.2075, -0.1169, -0.5889, -0.4510],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch2.running_var',\n",
              "               tensor([11.6180,  2.5173,  5.4848,  4.1630,  2.9990,  2.2100,  2.7613,  3.0768,\n",
              "                        2.1761,  2.8675,  2.4431,  2.3633,  1.8498,  6.6310,  1.9216,  1.5905,\n",
              "                        2.1527,  1.2668,  1.7968,  3.5274,  4.8666,  2.9681,  8.5157,  9.1471,\n",
              "                        1.4590,  5.8960, 12.0895,  1.4057, 12.5614,  2.0615,  2.6445,  2.8952],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch2.num_batches_tracked', tensor(6320)),\n",
              "              ('conv3.weight',\n",
              "               tensor([[[[ 1.4244e-01,  1.6640e-01,  1.7973e-01],\n",
              "                         [-2.6017e-02, -5.7470e-02,  2.7484e-02],\n",
              "                         [-2.1862e-03,  1.0554e-01,  3.2308e-02]],\n",
              "               \n",
              "                        [[ 8.9233e-02, -2.8791e-01,  3.1312e-03],\n",
              "                         [ 1.3842e-01,  7.3162e-02, -1.6986e-01],\n",
              "                         [ 6.5859e-03, -2.8949e-02, -1.0046e-01]],\n",
              "               \n",
              "                        [[-6.4221e-02, -1.4177e-01, -3.8985e-02],\n",
              "                         [-2.6351e-02,  2.5164e-02, -5.3202e-02],\n",
              "                         [-3.0203e-02, -6.9821e-02, -1.3609e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 2.0564e-01, -2.2528e-01, -7.1071e-02],\n",
              "                         [ 6.8241e-03,  1.6958e-02, -1.2670e-04],\n",
              "                         [ 1.3437e-01,  1.0867e-02,  1.2433e-01]],\n",
              "               \n",
              "                        [[ 1.5241e-01,  3.5976e-02,  6.1480e-02],\n",
              "                         [-9.3193e-03,  9.7043e-02, -1.0986e-01],\n",
              "                         [-6.6704e-03, -7.6582e-02,  3.0913e-02]],\n",
              "               \n",
              "                        [[ 1.1064e-01,  4.0121e-02,  3.4297e-02],\n",
              "                         [-4.4114e-02, -1.0010e-01, -7.2591e-02],\n",
              "                         [-1.6371e-01, -7.0588e-04, -1.3201e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 6.9337e-02, -1.6103e-02,  1.2000e-01],\n",
              "                         [ 4.1436e-02,  1.9827e-01,  1.2569e-03],\n",
              "                         [ 2.5562e-02,  1.4965e-01, -9.7653e-02]],\n",
              "               \n",
              "                        [[ 2.8166e-02, -1.3824e-01,  1.5396e-01],\n",
              "                         [-2.5056e-02, -1.1075e-02,  6.7605e-02],\n",
              "                         [ 2.5293e-02, -1.5346e-01, -7.3977e-03]],\n",
              "               \n",
              "                        [[ 2.9629e-02,  7.7593e-02,  1.4196e-01],\n",
              "                         [ 7.1720e-02,  1.2190e-01, -2.9184e-02],\n",
              "                         [ 7.0604e-02,  2.9947e-02,  5.8244e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-3.2224e-02,  3.3678e-02, -1.1640e-01],\n",
              "                         [-6.3646e-02,  5.2089e-02,  1.3082e-02],\n",
              "                         [-1.5370e-01, -9.6310e-02, -5.8738e-02]],\n",
              "               \n",
              "                        [[ 1.5537e-01,  6.2111e-02,  1.0534e-01],\n",
              "                         [-1.9976e-02,  1.7875e-01, -1.6073e-02],\n",
              "                         [-2.5306e-01, -6.2382e-02, -2.1544e-02]],\n",
              "               \n",
              "                        [[ 3.5892e-02, -1.1766e-01, -1.4433e-01],\n",
              "                         [-9.4744e-02, -1.2052e-02, -1.5280e-02],\n",
              "                         [ 8.3946e-02, -1.4862e-01,  4.9841e-02]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 6.5431e-02, -2.2518e-02, -8.7764e-03],\n",
              "                         [-2.7545e-02, -1.7389e-01, -3.5038e-02],\n",
              "                         [ 5.0490e-02,  6.6266e-02, -3.8212e-02]],\n",
              "               \n",
              "                        [[ 1.5817e-01,  8.4651e-02, -1.3327e-01],\n",
              "                         [ 1.9935e-01,  1.0764e-02, -1.6434e-01],\n",
              "                         [-3.7343e-02, -2.2605e-02, -7.1413e-02]],\n",
              "               \n",
              "                        [[ 3.7018e-02, -1.2709e-01,  8.8424e-02],\n",
              "                         [-2.0053e-01,  1.1518e-01, -4.2141e-02],\n",
              "                         [-2.1497e-02,  1.1642e-01, -9.2483e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 1.3563e-01,  2.7780e-01,  1.2964e-01],\n",
              "                         [ 1.3771e-01,  1.1686e-01, -1.6540e-01],\n",
              "                         [ 9.4158e-03, -1.0328e-01, -8.2094e-02]],\n",
              "               \n",
              "                        [[-1.9775e-01, -1.5673e-02,  2.7490e-01],\n",
              "                         [ 1.0385e-01,  1.4248e-01, -4.4491e-02],\n",
              "                         [-1.2424e-01, -2.4414e-02, -2.1287e-01]],\n",
              "               \n",
              "                        [[-1.0404e-01, -8.7845e-02, -1.3271e-01],\n",
              "                         [-4.2204e-02,  1.8790e-02,  4.8980e-02],\n",
              "                         [ 4.0772e-02, -7.1417e-02,  3.1761e-02]]],\n",
              "               \n",
              "               \n",
              "                       ...,\n",
              "               \n",
              "               \n",
              "                       [[[-8.5761e-02, -6.5436e-02, -6.4871e-02],\n",
              "                         [ 2.5447e-02,  1.6728e-02,  6.3027e-02],\n",
              "                         [-1.1587e-02,  4.0443e-02,  2.0342e-01]],\n",
              "               \n",
              "                        [[ 3.4371e-02,  1.2365e-01, -3.3747e-02],\n",
              "                         [-1.0323e-01, -6.1430e-03, -2.3967e-02],\n",
              "                         [-1.0426e-01, -8.6086e-02,  2.4294e-02]],\n",
              "               \n",
              "                        [[-1.8368e-01, -9.1117e-02, -8.9096e-02],\n",
              "                         [-4.4572e-02, -5.0972e-02,  2.5915e-01],\n",
              "                         [-1.4928e-01,  1.0195e-01,  3.0133e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-4.5860e-04, -1.6338e-01,  1.2891e-01],\n",
              "                         [-6.8716e-02,  3.5211e-02,  3.2228e-02],\n",
              "                         [-1.5487e-01, -3.5774e-02, -2.8073e-02]],\n",
              "               \n",
              "                        [[ 1.7439e-01,  1.7642e-01, -7.7302e-02],\n",
              "                         [-1.5884e-01,  1.6351e-01, -3.6095e-02],\n",
              "                         [-7.9082e-02, -9.0424e-02, -8.1675e-02]],\n",
              "               \n",
              "                        [[ 1.3799e-02, -8.8376e-02, -1.9696e-01],\n",
              "                         [-2.8744e-02,  1.0521e-01,  1.5272e-02],\n",
              "                         [ 1.4018e-01,  1.5925e-01,  9.9748e-02]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 1.1557e-01,  2.2853e-01,  1.2958e-02],\n",
              "                         [-3.3189e-02,  5.3637e-02,  4.3131e-02],\n",
              "                         [-9.9950e-04, -4.0826e-03,  7.2901e-02]],\n",
              "               \n",
              "                        [[-2.7873e-01, -1.4839e-01,  8.4134e-02],\n",
              "                         [-5.5639e-02,  1.7840e-01,  3.2075e-02],\n",
              "                         [-5.5099e-02, -9.2957e-03, -1.0837e-01]],\n",
              "               \n",
              "                        [[-1.4575e-02, -2.1359e-02, -1.1388e-02],\n",
              "                         [ 1.3318e-01, -7.9737e-02, -1.0675e-01],\n",
              "                         [ 7.2847e-02, -7.3565e-02,  5.7812e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-7.6439e-02, -5.5370e-02, -2.5318e-01],\n",
              "                         [-1.3896e-02, -1.7814e-01,  9.5704e-02],\n",
              "                         [-7.1388e-02,  2.7868e-02,  1.2172e-01]],\n",
              "               \n",
              "                        [[-1.0791e-02,  8.6373e-02,  2.5462e-02],\n",
              "                         [ 8.7382e-02,  3.0176e-02, -1.0735e-01],\n",
              "                         [-1.1810e-01,  8.5539e-02,  3.6466e-02]],\n",
              "               \n",
              "                        [[-3.3792e-01, -8.7745e-02,  7.2374e-02],\n",
              "                         [-3.1258e-02,  8.5001e-02,  1.2484e-01],\n",
              "                         [ 1.5108e-01, -6.8663e-02,  8.7782e-03]]],\n",
              "               \n",
              "               \n",
              "                       [[[-9.5992e-02, -2.6936e-02,  1.4816e-01],\n",
              "                         [ 2.7789e-02,  7.1505e-02, -9.3481e-02],\n",
              "                         [-1.0050e-01,  7.9813e-02,  1.3126e-01]],\n",
              "               \n",
              "                        [[ 7.7232e-03,  1.9733e-01,  5.5047e-02],\n",
              "                         [ 9.3128e-02,  6.8485e-02,  1.3610e-01],\n",
              "                         [ 4.0700e-02, -2.0705e-01,  2.3259e-01]],\n",
              "               \n",
              "                        [[-1.6339e-02, -5.7631e-02, -1.1063e-01],\n",
              "                         [ 8.4204e-03, -3.2798e-02, -7.7465e-02],\n",
              "                         [ 5.0546e-02,  3.2477e-02,  1.1596e-03]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-9.4896e-02,  1.1979e-02,  1.3493e-01],\n",
              "                         [-3.2417e-02, -9.8527e-03, -1.3685e-01],\n",
              "                         [-1.3482e-01, -2.6535e-02, -2.1522e-02]],\n",
              "               \n",
              "                        [[ 1.1584e-01,  2.6180e-01,  4.6735e-03],\n",
              "                         [-3.1400e-02,  1.0433e-01,  4.7917e-02],\n",
              "                         [ 5.6868e-02,  8.3138e-02, -9.8153e-02]],\n",
              "               \n",
              "                        [[ 1.5538e-01, -1.1990e-01, -8.4884e-03],\n",
              "                         [-6.8975e-02,  6.4582e-02, -9.3890e-02],\n",
              "                         [ 1.1227e-02, -1.6504e-02,  6.8188e-02]]]], dtype=torch.float64)),\n",
              "              ('conv3.bias',\n",
              "               tensor([-0.0011, -0.0330,  0.0063,  0.0421,  0.0419,  0.0466, -0.0005, -0.0308,\n",
              "                       -0.0529,  0.0200, -0.0277,  0.0226,  0.0585, -0.0041, -0.0528, -0.0578,\n",
              "                       -0.0238,  0.0021,  0.0023, -0.0388, -0.0492, -0.0444, -0.0048,  0.0108,\n",
              "                        0.0563,  0.0443,  0.0095, -0.0264,  0.0106, -0.0485,  0.0362, -0.0486,\n",
              "                       -0.0219,  0.0574, -0.0405,  0.0312,  0.0221,  0.0153,  0.0051,  0.0392,\n",
              "                       -0.0433, -0.0574,  0.0102,  0.0133, -0.0160, -0.0278, -0.0386,  0.0194,\n",
              "                       -0.0367,  0.0232, -0.0506, -0.0252,  0.0463, -0.0525,  0.0510,  0.0542,\n",
              "                       -0.0234, -0.0155,  0.0374, -0.0434,  0.0475,  0.0295,  0.0365, -0.0468],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch3.weight',\n",
              "               tensor([0.9843, 0.9330, 1.2015, 1.1072, 0.9682, 1.2323, 0.7619, 1.1471, 0.9246,\n",
              "                       0.8849, 1.0935, 0.8341, 1.0070, 1.0605, 1.0069, 0.9348, 0.6622, 1.2228,\n",
              "                       1.1377, 0.9326, 1.0079, 1.1416, 1.0435, 0.9172, 1.0273, 0.8915, 1.1442,\n",
              "                       0.6552, 1.0056, 0.8561, 0.9976, 0.9442, 1.1591, 1.0819, 0.7950, 0.9437,\n",
              "                       1.1369, 0.9232, 0.9601, 1.0116, 0.6285, 1.1971, 1.1227, 1.0700, 0.8639,\n",
              "                       0.9559, 1.0629, 1.0603, 0.9821, 1.1152, 1.1035, 1.0138, 1.0297, 1.0990,\n",
              "                       1.0705, 1.0995, 1.1387, 1.1229, 1.0185, 0.9782, 1.0179, 1.2074, 1.0723,\n",
              "                       1.0836], dtype=torch.float64)),\n",
              "              ('batch3.bias',\n",
              "               tensor([-0.1697, -0.2250, -0.1380, -0.0869, -0.1759, -0.2986, -0.1646, -0.0610,\n",
              "                       -0.1512, -0.1545, -0.1861, -0.0740, -0.1859, -0.1434, -0.1584, -0.2009,\n",
              "                       -0.0956, -0.2741, -0.0724, -0.2614, -0.2059, -0.1147, -0.1039, -0.1623,\n",
              "                       -0.0781, -0.1811, -0.1660, -0.0963, -0.1080, -0.1439, -0.1347, -0.2268,\n",
              "                       -0.1030, -0.1205, -0.1835, -0.1927, -0.1386, -0.0771, -0.1945, -0.0747,\n",
              "                       -0.1550, -0.1183, -0.2049, -0.0713, -0.1504,  0.0856,  0.0227, -0.0450,\n",
              "                       -0.1150, -0.1461, -0.0152, -0.0773,  0.0072, -0.0593, -0.2039, -0.1097,\n",
              "                       -0.1328, -0.1227, -0.1690, -0.0486, -0.1914, -0.1319, -0.2043, -0.2134],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch3.running_mean',\n",
              "               tensor([-2.1590, -0.2643, -1.7134, -1.7578, -3.0793, -0.6106, -1.9924, -1.4653,\n",
              "                       -1.0599, -2.8305, -1.9003, -0.6314, -2.5167, -1.8075, -0.6633, -0.8589,\n",
              "                        0.8607, -0.7770, -1.2591, -1.0844, -2.2652, -1.3925, -1.3324, -0.6702,\n",
              "                       -1.0162, -1.3038, -1.1490,  0.4694, -1.8253, -1.2314, -1.0238, -1.7592,\n",
              "                       -1.3494, -1.5708, -0.0116, -1.5611, -1.5661, -0.4702, -1.6046, -0.9751,\n",
              "                        1.3927, -0.7464, -0.9961, -1.2350, -1.6621, -1.3180, -0.7332, -1.3389,\n",
              "                       -1.3028, -1.5049, -0.5936, -0.9345, -1.0044, -0.8698, -2.0312, -1.7630,\n",
              "                       -2.6412, -1.8880, -1.5550, -1.2058, -1.4261, -0.8178, -1.1574, -1.7439],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch3.running_var',\n",
              "               tensor([ 8.5336,  4.9992,  4.7793,  5.4623, 26.6505,  5.5741,  3.9829,  5.6041,\n",
              "                        3.1001, 18.2363,  8.0341,  2.9523, 25.1816,  6.0146,  5.8974,  4.7588,\n",
              "                        2.1708,  5.5897,  9.2353,  6.4698, 10.6936,  6.5466,  3.3960,  6.4347,\n",
              "                        5.4302,  5.8159,  4.4304,  3.5338, 10.5109,  6.6067,  7.3571,  4.1308,\n",
              "                        6.0616,  2.9922,  2.7324, 13.4130,  6.8861,  3.2465,  3.4801,  8.1219,\n",
              "                       11.4832,  6.3373,  5.1014, 11.7327,  2.8055,  4.5556,  3.2426,  5.9332,\n",
              "                        6.1584,  4.6528,  3.5990,  4.3414,  3.0056,  3.2957,  9.6905,  5.4362,\n",
              "                        7.5912,  4.0464, 10.4424,  2.2985,  5.7178,  3.4250,  6.1508, 10.4979],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch3.num_batches_tracked', tensor(6320)),\n",
              "              ('conv4.weight',\n",
              "               tensor([[[[-4.0643e-02, -1.9642e-02, -2.1530e-02],\n",
              "                         [-3.7493e-02, -5.4362e-02,  5.0556e-02],\n",
              "                         [-9.0078e-02,  9.1713e-02, -2.2682e-02]],\n",
              "               \n",
              "                        [[-1.0740e-02,  1.5866e-01, -5.9907e-02],\n",
              "                         [-1.1450e-02, -3.7874e-03, -7.1923e-02],\n",
              "                         [ 7.1697e-02, -1.8773e-02,  4.8969e-02]],\n",
              "               \n",
              "                        [[-1.2922e-01, -2.1777e-01, -1.8598e-01],\n",
              "                         [-1.1354e-01, -3.0907e-02,  1.8241e-02],\n",
              "                         [-4.8838e-02,  1.7106e-03, -6.6224e-03]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 1.7847e-01,  1.2065e-01, -7.1480e-02],\n",
              "                         [-8.5770e-02,  8.0163e-02,  4.4187e-02],\n",
              "                         [-1.6225e-02,  7.3360e-02,  1.6597e-01]],\n",
              "               \n",
              "                        [[-1.2139e-01,  6.5554e-03, -4.7539e-02],\n",
              "                         [-5.4848e-02, -4.2136e-02, -1.2025e-01],\n",
              "                         [-5.2159e-02, -5.2237e-02, -1.5494e-02]],\n",
              "               \n",
              "                        [[-9.5266e-02, -1.9886e-01,  1.9498e-02],\n",
              "                         [-1.6329e-01, -2.1786e-01,  9.0300e-02],\n",
              "                         [-1.1514e-01,  1.3522e-01, -4.2275e-02]]],\n",
              "               \n",
              "               \n",
              "                       [[[-1.7691e-01, -1.7634e-01, -6.3967e-02],\n",
              "                         [ 1.7523e-01, -2.1898e-03,  7.0534e-02],\n",
              "                         [ 2.8448e-02, -8.1282e-02,  7.5529e-02]],\n",
              "               \n",
              "                        [[-1.3363e-01,  8.8484e-02, -1.0042e-01],\n",
              "                         [-7.6245e-02, -1.0347e-01, -1.4294e-01],\n",
              "                         [ 2.0389e-01,  1.5067e-01,  1.1249e-02]],\n",
              "               \n",
              "                        [[ 1.1493e-01,  2.0305e-02,  5.7914e-02],\n",
              "                         [-1.8623e-02,  5.6484e-03,  1.7114e-01],\n",
              "                         [-6.8382e-02,  7.0938e-02,  1.0661e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 1.4737e-02,  7.4731e-02,  4.2503e-02],\n",
              "                         [-1.5325e-02,  3.6790e-02, -2.8261e-02],\n",
              "                         [ 6.5620e-02,  2.9064e-02, -5.2422e-02]],\n",
              "               \n",
              "                        [[-2.0496e-01, -1.6470e-01, -1.6693e-01],\n",
              "                         [ 4.1799e-02,  1.4570e-01,  2.6643e-01],\n",
              "                         [-3.2671e-02,  1.3700e-01,  7.2819e-02]],\n",
              "               \n",
              "                        [[-1.0653e-01, -3.1556e-02,  7.0737e-02],\n",
              "                         [ 1.2427e-01,  1.3425e-01,  3.6392e-02],\n",
              "                         [ 1.2239e-01, -1.2679e-02, -1.3346e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[-1.8518e-02, -1.7828e-02,  7.5378e-02],\n",
              "                         [-1.3926e-01, -9.5768e-03, -9.3966e-02],\n",
              "                         [ 2.6345e-02,  5.2973e-02, -7.6109e-02]],\n",
              "               \n",
              "                        [[-4.0959e-02,  6.0139e-03,  2.9948e-02],\n",
              "                         [ 1.0517e-01, -1.0064e-01, -1.3307e-02],\n",
              "                         [ 1.1771e-01,  3.5609e-02, -6.1131e-02]],\n",
              "               \n",
              "                        [[-2.1615e-02, -4.6199e-02, -4.3149e-02],\n",
              "                         [-1.6479e-01, -9.7528e-02, -5.8670e-02],\n",
              "                         [ 1.0559e-01, -1.1872e-01,  1.9042e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 1.0727e-01, -5.2677e-02,  4.3474e-02],\n",
              "                         [ 1.5961e-02,  2.3172e-02,  4.4435e-03],\n",
              "                         [ 5.7749e-02, -1.2972e-03, -8.4116e-02]],\n",
              "               \n",
              "                        [[-2.6004e-02, -3.0429e-02,  7.8229e-02],\n",
              "                         [-4.6002e-02, -6.1827e-02,  2.4344e-02],\n",
              "                         [-7.1798e-02, -3.1690e-02,  4.4749e-02]],\n",
              "               \n",
              "                        [[ 8.6796e-03,  9.0714e-02,  1.0048e-02],\n",
              "                         [-1.3699e-01, -4.5678e-03,  1.1201e-01],\n",
              "                         [-9.1605e-02, -4.7062e-02, -3.5260e-02]]],\n",
              "               \n",
              "               \n",
              "                       ...,\n",
              "               \n",
              "               \n",
              "                       [[[-5.6618e-02, -5.0766e-02,  7.2616e-02],\n",
              "                         [-2.6536e-03, -2.7389e-02, -1.8658e-02],\n",
              "                         [-9.3929e-02,  7.7896e-03,  7.6719e-02]],\n",
              "               \n",
              "                        [[ 1.2593e-01, -1.7187e-02,  7.5263e-02],\n",
              "                         [ 1.6671e-01, -8.7719e-02,  1.1776e-01],\n",
              "                         [ 7.8108e-03, -3.2452e-02,  7.1027e-02]],\n",
              "               \n",
              "                        [[-8.0993e-02, -4.7409e-02, -6.3944e-03],\n",
              "                         [-2.2347e-03, -1.3250e-01, -3.4896e-02],\n",
              "                         [-3.8176e-02,  3.8050e-02,  1.5838e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-1.0143e-01, -1.5307e-02,  5.9653e-02],\n",
              "                         [-3.3334e-02, -7.1859e-02,  4.4446e-02],\n",
              "                         [ 1.3206e-01,  5.1205e-02, -1.4169e-01]],\n",
              "               \n",
              "                        [[-3.9752e-02, -2.6631e-03,  3.5842e-02],\n",
              "                         [ 6.3435e-02,  1.4472e-01,  1.6077e-01],\n",
              "                         [ 1.2106e-01,  2.6154e-02,  8.6470e-02]],\n",
              "               \n",
              "                        [[-6.1606e-02,  4.8401e-02,  1.9448e-01],\n",
              "                         [-1.5522e-01,  3.8226e-02,  2.4574e-02],\n",
              "                         [-8.1080e-02, -3.1098e-03,  1.4657e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 1.1033e-01,  9.0516e-02, -4.6779e-02],\n",
              "                         [ 1.4890e-01,  4.7502e-02,  7.6662e-03],\n",
              "                         [ 1.9314e-01,  2.1641e-02, -4.4958e-02]],\n",
              "               \n",
              "                        [[-4.9417e-02, -1.7257e-02,  5.3314e-03],\n",
              "                         [-1.0187e-01, -6.1714e-02, -7.9535e-02],\n",
              "                         [-1.8563e-01,  1.7412e-01, -7.2785e-02]],\n",
              "               \n",
              "                        [[-8.1397e-02,  6.2655e-04,  1.6389e-01],\n",
              "                         [-7.2267e-02,  4.2586e-02,  4.4712e-02],\n",
              "                         [ 6.2057e-02, -4.2945e-02, -1.7320e-01]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-2.1719e-02,  1.3203e-01,  1.2556e-01],\n",
              "                         [-3.2063e-02,  1.0655e-02,  9.3622e-02],\n",
              "                         [ 1.2586e-01,  8.9837e-03,  8.5228e-02]],\n",
              "               \n",
              "                        [[ 4.7410e-03, -8.7270e-02, -2.0990e-02],\n",
              "                         [ 2.7600e-02, -1.9290e-01, -4.0014e-02],\n",
              "                         [ 1.3483e-01, -1.9597e-01, -5.9664e-02]],\n",
              "               \n",
              "                        [[ 9.2889e-03,  1.3499e-01,  2.3234e-02],\n",
              "                         [-1.2377e-01,  3.8180e-02,  8.1821e-02],\n",
              "                         [-5.5282e-02, -6.2261e-02,  1.7073e-01]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 6.7751e-02, -8.1677e-03, -8.9267e-02],\n",
              "                         [-1.3619e-01, -2.2764e-02, -1.0658e-02],\n",
              "                         [ 1.3852e-01, -1.1037e-01,  4.3312e-02]],\n",
              "               \n",
              "                        [[ 5.7117e-02, -2.2713e-02,  1.7552e-01],\n",
              "                         [-2.2897e-02, -5.4326e-02,  1.1980e-01],\n",
              "                         [-4.7285e-02, -4.0934e-02,  8.0209e-02]],\n",
              "               \n",
              "                        [[-1.0288e-01, -1.7602e-01,  1.1318e-01],\n",
              "                         [ 7.5113e-02, -1.5535e-01,  6.1043e-02],\n",
              "                         [ 3.1394e-05, -4.0687e-02, -1.2251e-02]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-5.2201e-03,  6.1219e-02, -1.3715e-01],\n",
              "                         [ 2.2077e-02,  2.4717e-02, -1.4846e-01],\n",
              "                         [-3.8649e-02,  1.3761e-01, -3.9429e-02]],\n",
              "               \n",
              "                        [[-2.1127e-01, -3.1588e-02,  3.6160e-02],\n",
              "                         [-8.9363e-03, -8.0941e-02, -7.1656e-03],\n",
              "                         [ 4.0832e-02, -7.7212e-02,  1.2017e-01]],\n",
              "               \n",
              "                        [[-5.4646e-03,  2.8920e-02,  1.8007e-01],\n",
              "                         [ 6.3628e-03,  8.5784e-03,  1.9985e-01],\n",
              "                         [-3.3199e-02, -7.9030e-02,  7.6756e-03]]]], dtype=torch.float64)),\n",
              "              ('conv4.bias',\n",
              "               tensor([ 0.0139, -0.0074, -0.0229, -0.0280,  0.0144,  0.0124,  0.0182, -0.0374,\n",
              "                        0.0027, -0.0059, -0.0401,  0.0125,  0.0276, -0.0257,  0.0391,  0.0062,\n",
              "                        0.0040,  0.0173, -0.0079,  0.0251, -0.0006,  0.0033,  0.0202,  0.0034,\n",
              "                        0.0139,  0.0109,  0.0024, -0.0322,  0.0075, -0.0132, -0.0020,  0.0036,\n",
              "                        0.0058,  0.0307,  0.0251,  0.0246,  0.0401, -0.0162,  0.0077,  0.0344,\n",
              "                        0.0183, -0.0007,  0.0184, -0.0343, -0.0098, -0.0145, -0.0309,  0.0076,\n",
              "                       -0.0208, -0.0201,  0.0243,  0.0272,  0.0292,  0.0108, -0.0148, -0.0107,\n",
              "                        0.0307, -0.0154, -0.0174, -0.0104,  0.0043,  0.0297,  0.0199, -0.0288,\n",
              "                       -0.0154, -0.0073,  0.0347,  0.0119,  0.0119, -0.0300, -0.0090,  0.0346,\n",
              "                        0.0122,  0.0011,  0.0181,  0.0071, -0.0279, -0.0370,  0.0084,  0.0356,\n",
              "                       -0.0208, -0.0324,  0.0350, -0.0222, -0.0328, -0.0083, -0.0268,  0.0251,\n",
              "                        0.0160,  0.0220, -0.0354, -0.0388,  0.0210, -0.0340, -0.0282, -0.0114,\n",
              "                        0.0318,  0.0281, -0.0357, -0.0040, -0.0267, -0.0124, -0.0066, -0.0277,\n",
              "                       -0.0044,  0.0278, -0.0344,  0.0249,  0.0246, -0.0104, -0.0005, -0.0281,\n",
              "                       -0.0351,  0.0228,  0.0295,  0.0192, -0.0247, -0.0130, -0.0047,  0.0115,\n",
              "                       -0.0408,  0.0085, -0.0229,  0.0370,  0.0333, -0.0385, -0.0122, -0.0398],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch4.weight',\n",
              "               tensor([0.9178, 1.1622, 0.8074, 0.8322, 1.0618, 1.0036, 1.2559, 1.1560, 0.8670,\n",
              "                       1.0329, 1.1006, 0.8617, 0.9352, 1.0112, 0.8631, 1.1490, 0.8682, 1.0422,\n",
              "                       0.8625, 1.2513, 0.9983, 1.0119, 1.0227, 0.9911, 1.1380, 1.2076, 1.1542,\n",
              "                       1.0153, 1.1310, 0.9017, 1.1146, 0.9590, 1.1797, 1.1634, 0.8108, 0.9096,\n",
              "                       0.9348, 1.0356, 1.0101, 1.0638, 1.0988, 1.1687, 0.8104, 1.0933, 1.0366,\n",
              "                       1.1053, 1.0862, 1.1009, 1.1764, 1.0933, 0.9656, 1.0184, 0.9547, 1.1271,\n",
              "                       0.8677, 0.9284, 1.0335, 1.2020, 0.9835, 1.0142, 0.9992, 0.9880, 0.9819,\n",
              "                       1.0557, 0.9726, 0.9979, 1.0843, 1.0727, 1.1221, 0.8001, 1.2238, 1.1824,\n",
              "                       1.1137, 0.9187, 0.9336, 1.0759, 1.1027, 1.0713, 1.1673, 1.1124, 1.1082,\n",
              "                       1.1050, 0.9418, 0.9696, 1.0147, 1.0213, 0.6880, 1.1115, 0.8430, 1.1687,\n",
              "                       1.1184, 0.9893, 1.1176, 0.9371, 1.1044, 0.9560, 1.0247, 0.8254, 0.8547,\n",
              "                       1.0502, 1.2098, 1.0367, 1.0072, 0.9309, 1.0716, 0.8340, 1.0731, 1.1208,\n",
              "                       1.0986, 1.2290, 1.0321, 0.8328, 0.9459, 1.0562, 0.8633, 1.1249, 1.0971,\n",
              "                       1.0271, 0.8554, 1.1139, 1.1765, 1.0501, 1.1354, 0.9432, 1.0671, 0.9729,\n",
              "                       1.1305, 1.0268], dtype=torch.float64)),\n",
              "              ('batch4.bias',\n",
              "               tensor([-0.2722, -0.1717, -0.2146, -0.2054, -0.1460, -0.1763, -0.0932, -0.1513,\n",
              "                       -0.2130,  0.0378, -0.0491, -0.1412, -0.1950, -0.2535, -0.2168,  0.0165,\n",
              "                       -0.2071, -0.1753, -0.1175, -0.2676, -0.2398, -0.0876, -0.1584, -0.3323,\n",
              "                       -0.1857, -0.3208, -0.0819, -0.0367, -0.0826, -0.1612, -0.2154, -0.1421,\n",
              "                       -0.0125, -0.1113, -0.2642, -0.0446, -0.2051, -0.1123, -0.1215, -0.1387,\n",
              "                       -0.0143, -0.1473, -0.1720, -0.0224, -0.0486, -0.1708, -0.1213, -0.0964,\n",
              "                       -0.0202, -0.1466, -0.2114, -0.1574, -0.1546, -0.0565, -0.1983, -0.0810,\n",
              "                       -0.0185, -0.0283, -0.1342, -0.1816, -0.1465, -0.1889, -0.2626, -0.2494,\n",
              "                       -0.1648, -0.1527, -0.1338, -0.2820, -0.0608, -0.1581, -0.1568, -0.1609,\n",
              "                       -0.0707, -0.1678, -0.2055, -0.1163, -0.1851, -0.0413, -0.2354, -0.0816,\n",
              "                       -0.0798, -0.1836, -0.1461, -0.1630, -0.1440, -0.1559, -0.2524, -0.0717,\n",
              "                       -0.1988, -0.0251, -0.1508,  0.0083, -0.1410, -0.1500, -0.0838, -0.0934,\n",
              "                       -0.0518, -0.1408, -0.1938, -0.1908, -0.1423, -0.1039, -0.1474, -0.0132,\n",
              "                       -0.1393, -0.1763, -0.1076, -0.2536, -0.0881, -0.1031, -0.1012, -0.2058,\n",
              "                       -0.2296, -0.2166, -0.2478, -0.1199, -0.1985, -0.1409, -0.2129, -0.2009,\n",
              "                       -0.2468, -0.2025, -0.1861, -0.2706, -0.1816, -0.2342, -0.1093, -0.0942],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch4.running_mean',\n",
              "               tensor([-0.9781,  1.0173, -2.1909,  1.3281, -1.4996, -2.1837, -0.8793, -1.2262,\n",
              "                        2.4734, -1.0495, -1.7219,  1.1681, -1.5822,  0.0320,  2.3105, -3.6237,\n",
              "                        0.9732, -0.1773,  0.4573, -0.5514, -1.6885, -0.1827, -0.1163, -2.3793,\n",
              "                       -0.8887, -1.1088, -1.6324, -2.0021, -0.4360, -0.2285, -0.6329, -1.5462,\n",
              "                       -3.4889, -2.5162, -1.6935,  1.0649, -0.3234, -0.6567,  0.0095, -2.5895,\n",
              "                       -1.0040, -1.3462,  0.6836, -2.2759, -2.6302, -1.3254, -1.1647, -3.0897,\n",
              "                       -1.2930, -0.8845, -2.9285, -1.6078,  0.7153, -1.3021,  1.5406, -1.4087,\n",
              "                       -0.4597, -0.8416, -0.5898, -0.3764, -0.9503, -0.9052,  1.0463, -1.0407,\n",
              "                       -3.0542, -0.1699, -0.9131, -1.6899, -1.3082,  1.8975, -0.3428, -0.9061,\n",
              "                       -2.0625, -0.2471, -1.1498, -0.4221, -1.4342, -0.8606, -1.2303, -2.3668,\n",
              "                       -0.9766, -0.5804, -0.2481, -2.6768, -0.8157, -1.6878,  1.8467, -0.9818,\n",
              "                       -0.4744, -1.9110, -2.7678,  0.2016, -0.8542, -0.6253, -2.3008,  0.3209,\n",
              "                       -2.6088,  0.5602, -1.0052, -1.0550, -2.7919, -0.1556, -1.5477,  0.3246,\n",
              "                       -1.7837, -0.0312, -1.8370, -2.2129, -2.3425, -2.8812, -0.5828, -0.7089,\n",
              "                        0.6925, -1.8773, -1.1336, -0.0119, -1.3450, -1.9859, -0.6160, -1.6676,\n",
              "                       -0.6229, -1.3045, -1.6918, -1.4781, -0.7382, -1.2660, -1.6217, -0.6155],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch4.running_var',\n",
              "               tensor([1.5834, 2.2389, 1.5465, 3.2848, 3.5418, 4.5157, 2.0287, 2.8121, 4.0225,\n",
              "                       1.4998, 2.0010, 2.7069, 1.8518, 1.3527, 2.7501, 6.1618, 2.3923, 1.6624,\n",
              "                       4.0230, 1.5729, 1.7077, 2.0069, 1.8153, 1.8850, 4.8736, 2.1808, 2.6108,\n",
              "                       5.0321, 1.7174, 2.1055, 2.8477, 1.8918, 6.3611, 2.7800, 1.9058, 1.9689,\n",
              "                       1.8678, 4.3287, 1.3864, 2.3786, 1.7586, 1.8624, 4.0414, 2.3299, 2.9497,\n",
              "                       2.5346, 2.5854, 4.3088, 2.2550, 2.8832, 5.3184, 3.7465, 2.6521, 2.2733,\n",
              "                       3.1758, 1.5843, 1.7118, 1.4377, 2.4321, 1.8518, 2.1820, 3.4718, 1.6843,\n",
              "                       1.9083, 4.8507, 1.7997, 2.3118, 4.7561, 2.3808, 2.6469, 2.3545, 2.3128,\n",
              "                       1.8483, 1.2501, 1.9449, 3.2591, 2.1822, 2.0835, 2.9119, 3.8260, 1.7870,\n",
              "                       2.3804, 3.4064, 2.9347, 2.3938, 3.4224, 2.4359, 1.6209, 1.7440, 2.8203,\n",
              "                       3.7142, 1.7257, 1.6802, 2.3390, 1.9238, 4.3244, 2.3606, 2.7226, 1.7332,\n",
              "                       2.4594, 5.5262, 2.3657, 2.7061, 1.7416, 2.0836, 2.1361, 2.4892, 4.2058,\n",
              "                       3.2058, 4.8552, 2.3331, 1.7194, 1.8086, 1.5310, 1.3519, 2.0942, 2.9286,\n",
              "                       3.4427, 1.2923, 3.2538, 1.7776, 1.9001, 3.3123, 1.5967, 2.1312, 2.4414,\n",
              "                       2.5797, 2.9666], dtype=torch.float64)),\n",
              "              ('batch4.num_batches_tracked', tensor(6320)),\n",
              "              ('conv5.weight',\n",
              "               tensor([[[[ 0.2115, -0.0110,  0.1352],\n",
              "                         [ 0.0490,  0.0510,  0.1564],\n",
              "                         [ 0.0995,  0.0399,  0.0290]],\n",
              "               \n",
              "                        [[-0.1120, -0.0709, -0.0976],\n",
              "                         [-0.0573, -0.1141, -0.1456],\n",
              "                         [ 0.0103, -0.0300, -0.1691]],\n",
              "               \n",
              "                        [[ 0.0358, -0.0281, -0.0451],\n",
              "                         [-0.0914, -0.0110,  0.1358],\n",
              "                         [ 0.0800,  0.0268,  0.0865]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-0.1319,  0.0170,  0.1471],\n",
              "                         [-0.0329,  0.1180, -0.1121],\n",
              "                         [-0.0750, -0.0908, -0.2027]],\n",
              "               \n",
              "                        [[-0.0430,  0.0765,  0.1388],\n",
              "                         [ 0.0329,  0.1435,  0.0794],\n",
              "                         [ 0.0168, -0.1344, -0.0573]],\n",
              "               \n",
              "                        [[ 0.0516, -0.0793, -0.2250],\n",
              "                         [-0.0824, -0.0882, -0.0272],\n",
              "                         [-0.1299, -0.1078,  0.1195]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.0494, -0.0548, -0.0582],\n",
              "                         [ 0.0204, -0.0745,  0.0269],\n",
              "                         [ 0.0697,  0.0051,  0.0817]],\n",
              "               \n",
              "                        [[-0.1484, -0.0317,  0.0342],\n",
              "                         [-0.0110, -0.0460, -0.0629],\n",
              "                         [ 0.0095, -0.1417, -0.1590]],\n",
              "               \n",
              "                        [[-0.0092,  0.0086,  0.0898],\n",
              "                         [-0.0310, -0.0144, -0.0066],\n",
              "                         [-0.0489, -0.0399, -0.0558]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-0.0016, -0.0658, -0.0061],\n",
              "                         [ 0.0530,  0.0089, -0.0119],\n",
              "                         [-0.0208, -0.0051,  0.1389]],\n",
              "               \n",
              "                        [[-0.0678, -0.0240,  0.0258],\n",
              "                         [ 0.0899, -0.0752,  0.0302],\n",
              "                         [-0.0434, -0.0615,  0.1004]],\n",
              "               \n",
              "                        [[-0.0245, -0.0076,  0.1868],\n",
              "                         [-0.0024,  0.0398,  0.0689],\n",
              "                         [ 0.0162, -0.0892,  0.0352]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.0856, -0.0858, -0.0738],\n",
              "                         [ 0.0275, -0.0707,  0.0638],\n",
              "                         [-0.0916, -0.0344,  0.0349]],\n",
              "               \n",
              "                        [[-0.1374,  0.1064, -0.0794],\n",
              "                         [-0.1805, -0.1019, -0.0907],\n",
              "                         [-0.1107,  0.1148, -0.0185]],\n",
              "               \n",
              "                        [[-0.0494, -0.0263,  0.0205],\n",
              "                         [ 0.0733, -0.0310, -0.0072],\n",
              "                         [ 0.0682, -0.0152,  0.0755]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 0.0921, -0.0448, -0.0348],\n",
              "                         [-0.0159, -0.0471,  0.0923],\n",
              "                         [ 0.0758,  0.0346,  0.1672]],\n",
              "               \n",
              "                        [[ 0.0650, -0.1085, -0.0813],\n",
              "                         [ 0.0204, -0.0872,  0.0354],\n",
              "                         [-0.0661,  0.0279, -0.0709]],\n",
              "               \n",
              "                        [[ 0.0930, -0.0451, -0.0064],\n",
              "                         [ 0.0887,  0.0643,  0.0194],\n",
              "                         [ 0.0540,  0.0395,  0.0778]]],\n",
              "               \n",
              "               \n",
              "                       ...,\n",
              "               \n",
              "               \n",
              "                       [[[-0.0450,  0.0546,  0.1075],\n",
              "                         [ 0.0842,  0.1201,  0.0527],\n",
              "                         [ 0.1352,  0.0546,  0.0961]],\n",
              "               \n",
              "                        [[-0.0553,  0.0278, -0.1193],\n",
              "                         [-0.1239,  0.1120, -0.1091],\n",
              "                         [-0.1495, -0.0523, -0.1102]],\n",
              "               \n",
              "                        [[-0.0359, -0.0120, -0.0119],\n",
              "                         [-0.0787, -0.0800,  0.0580],\n",
              "                         [-0.1276,  0.0437,  0.0211]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-0.0195,  0.0109, -0.1077],\n",
              "                         [-0.0245,  0.0197, -0.1133],\n",
              "                         [ 0.0712, -0.0306, -0.0810]],\n",
              "               \n",
              "                        [[ 0.0084,  0.1314,  0.0113],\n",
              "                         [-0.1541,  0.0101,  0.0897],\n",
              "                         [ 0.0438,  0.1114, -0.1009]],\n",
              "               \n",
              "                        [[-0.0278, -0.0371, -0.0181],\n",
              "                         [-0.0799, -0.0548, -0.0519],\n",
              "                         [ 0.0171, -0.1663, -0.0768]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.0025, -0.0081, -0.0214],\n",
              "                         [ 0.0904, -0.0746,  0.0762],\n",
              "                         [-0.0546,  0.0048,  0.1094]],\n",
              "               \n",
              "                        [[-0.0413, -0.1138,  0.0264],\n",
              "                         [-0.0740, -0.0840,  0.0427],\n",
              "                         [-0.0333, -0.1656, -0.0923]],\n",
              "               \n",
              "                        [[-0.0737, -0.0570,  0.0432],\n",
              "                         [-0.0873, -0.0532, -0.0190],\n",
              "                         [-0.0426,  0.0583,  0.0808]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[-0.0509, -0.1791, -0.0474],\n",
              "                         [-0.0595, -0.1854, -0.0475],\n",
              "                         [-0.0528, -0.0984, -0.1159]],\n",
              "               \n",
              "                        [[-0.1145,  0.0088,  0.1146],\n",
              "                         [-0.0296, -0.2006, -0.1290],\n",
              "                         [-0.0208, -0.1162, -0.1353]],\n",
              "               \n",
              "                        [[-0.0710, -0.1485,  0.0866],\n",
              "                         [ 0.0116, -0.0948, -0.0163],\n",
              "                         [-0.0136, -0.1107,  0.0786]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.1153, -0.0627, -0.0401],\n",
              "                         [-0.0414,  0.0080,  0.0091],\n",
              "                         [-0.1775, -0.0479,  0.0196]],\n",
              "               \n",
              "                        [[-0.0708, -0.0724,  0.0707],\n",
              "                         [-0.0822, -0.1493,  0.0993],\n",
              "                         [-0.0837, -0.0620, -0.0656]],\n",
              "               \n",
              "                        [[ 0.0880, -0.0390,  0.0239],\n",
              "                         [ 0.0884,  0.1039,  0.0380],\n",
              "                         [-0.0546,  0.1465,  0.0229]],\n",
              "               \n",
              "                        ...,\n",
              "               \n",
              "                        [[ 0.1136,  0.0123,  0.0837],\n",
              "                         [ 0.0044,  0.0766,  0.0828],\n",
              "                         [ 0.1478,  0.0482,  0.1452]],\n",
              "               \n",
              "                        [[-0.0456,  0.0031,  0.2354],\n",
              "                         [ 0.0326,  0.1617,  0.1405],\n",
              "                         [ 0.0128, -0.0112, -0.0205]],\n",
              "               \n",
              "                        [[-0.0567,  0.0708,  0.0477],\n",
              "                         [ 0.0025,  0.0046,  0.0687],\n",
              "                         [-0.0604,  0.1228,  0.0003]]]], dtype=torch.float64)),\n",
              "              ('conv5.bias',\n",
              "               tensor([-0.0279,  0.0088,  0.0234,  0.0263,  0.0022, -0.0148,  0.0285, -0.0195,\n",
              "                       -0.0218,  0.0068, -0.0103, -0.0250, -0.0219, -0.0238, -0.0229,  0.0027,\n",
              "                       -0.0048,  0.0072,  0.0055, -0.0284, -0.0082,  0.0277,  0.0054,  0.0253,\n",
              "                        0.0249,  0.0177, -0.0010,  0.0230, -0.0268, -0.0099,  0.0264,  0.0062,\n",
              "                        0.0135,  0.0294,  0.0038, -0.0265,  0.0119,  0.0007,  0.0199, -0.0036,\n",
              "                        0.0244, -0.0075,  0.0280, -0.0292, -0.0031,  0.0236, -0.0230,  0.0166,\n",
              "                        0.0256, -0.0264,  0.0003,  0.0260,  0.0244,  0.0085,  0.0207, -0.0016,\n",
              "                        0.0155,  0.0254, -0.0092, -0.0251, -0.0112,  0.0125,  0.0280, -0.0026,\n",
              "                        0.0218, -0.0292,  0.0107, -0.0007, -0.0243,  0.0251,  0.0196, -0.0022,\n",
              "                        0.0042, -0.0270,  0.0169, -0.0118,  0.0138,  0.0055, -0.0271, -0.0053,\n",
              "                        0.0286,  0.0253, -0.0055,  0.0011,  0.0111,  0.0221,  0.0133,  0.0291,\n",
              "                        0.0263,  0.0148,  0.0025,  0.0197,  0.0142,  0.0112, -0.0248,  0.0092,\n",
              "                       -0.0031,  0.0097, -0.0006, -0.0152, -0.0014, -0.0031,  0.0214, -0.0166,\n",
              "                        0.0029, -0.0123,  0.0053,  0.0208,  0.0141, -0.0052, -0.0169,  0.0294,\n",
              "                       -0.0220, -0.0022,  0.0098,  0.0011,  0.0281, -0.0138,  0.0274, -0.0239,\n",
              "                        0.0082, -0.0151, -0.0135,  0.0147, -0.0041, -0.0140,  0.0122, -0.0196],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch5.weight',\n",
              "               tensor([0.9960, 0.8588, 0.8573, 0.9711, 0.9032, 0.9513, 0.8859, 0.8666, 0.8523,\n",
              "                       0.9492, 0.7719, 0.8891, 0.9514, 0.8195, 0.9097, 0.8506, 1.1508, 0.9745,\n",
              "                       1.0612, 1.0078, 1.1812, 1.0553, 0.8992, 0.9900, 0.8594, 0.9103, 0.9940,\n",
              "                       0.8835, 0.8547, 0.9669, 1.0336, 1.0006, 0.9544, 0.9735, 0.9904, 0.9267,\n",
              "                       0.9888, 1.0150, 1.0320, 0.8761, 0.9683, 0.9457, 0.9950, 0.9830, 1.0272,\n",
              "                       0.9879, 0.8649, 0.8902, 0.8678, 0.9924, 0.7883, 0.9029, 0.9771, 1.0173,\n",
              "                       0.9380, 0.9925, 0.9623, 0.8662, 0.9987, 0.9076, 0.9125, 0.9019, 0.9363,\n",
              "                       0.9758, 0.9549, 0.9072, 1.0186, 0.9330, 1.0134, 0.8611, 0.9270, 0.9015,\n",
              "                       0.9076, 0.9174, 0.8272, 1.2096, 0.8830, 0.8588, 0.9651, 0.9419, 1.0072,\n",
              "                       0.9308, 0.9967, 0.8702, 0.8958, 0.9179, 0.9114, 0.8684, 0.9771, 1.0271,\n",
              "                       0.9195, 0.8732, 1.0715, 0.9710, 1.1104, 0.9925, 0.9414, 0.9626, 1.0984,\n",
              "                       0.9815, 0.8889, 0.9112, 1.0005, 0.9191, 0.9996, 1.0060, 0.9466, 0.9403,\n",
              "                       0.8541, 0.8472, 0.8521, 0.9925, 1.1572, 0.9151, 0.8947, 0.9382, 0.8659,\n",
              "                       1.0056, 1.0096, 0.9937, 0.9357, 0.9066, 0.9657, 0.9243, 1.0097, 0.8505,\n",
              "                       0.8660, 0.9183], dtype=torch.float64)),\n",
              "              ('batch5.bias',\n",
              "               tensor([-0.0238, -0.3129, -0.2167, -0.0673, -0.0790, -0.0448, -0.1238, -0.1964,\n",
              "                       -0.2573, -0.2227, -0.2962, -0.1867, -0.0759, -0.2027, -0.2788, -0.2248,\n",
              "                       -0.3550, -0.1348, -0.1259, -0.1571, -0.0857, -0.0911, -0.0906, -0.0753,\n",
              "                       -0.1427, -0.0890,  0.0038, -0.1691, -0.1296, -0.2040, -0.0808,  0.0090,\n",
              "                       -0.1021, -0.0398,  0.0059, -0.0734, -0.0327, -0.0796, -0.0434, -0.1365,\n",
              "                       -0.0617, -0.0529, -0.0176, -0.0550, -0.0547, -0.0304, -0.2122, -0.0943,\n",
              "                       -0.2470, -0.0149, -0.2752, -0.0765, -0.1059,  0.0218, -0.0488, -0.0042,\n",
              "                       -0.0885, -0.2558, -0.0387, -0.0885, -0.1615, -0.1187, -0.1663, -0.0390,\n",
              "                       -0.1205, -0.1865, -0.0203, -0.0594, -0.0264, -0.1506, -0.0857, -0.2593,\n",
              "                       -0.1517, -0.1666, -0.1703, -0.0845, -0.1419, -0.1527, -0.0955, -0.0709,\n",
              "                       -0.0997, -0.0630, -0.0143, -0.1687, -0.0853, -0.0970, -0.0669, -0.2702,\n",
              "                       -0.0207, -0.1792, -0.3150, -0.2588, -0.0212, -0.0405, -0.1045, -0.0394,\n",
              "                       -0.0446, -0.0608, -0.2400, -0.0374, -0.2255, -0.2333, -0.1910, -0.2137,\n",
              "                       -0.0068, -0.0183, -0.1949, -0.1450, -0.1553, -0.2428, -0.1753, -0.0990,\n",
              "                       -0.1675, -0.1235, -0.1327, -0.0657, -0.1545, -0.0805, -0.0378, -0.0595,\n",
              "                       -0.0803, -0.1438, -0.0087, -0.0675, -0.0322, -0.2655, -0.1709, -0.2213],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch5.running_mean',\n",
              "               tensor([-2.9989e+00, -5.4593e+00, -4.8539e+00, -2.4385e+00, -4.7600e+00,\n",
              "                       -6.5193e+00, -4.8015e+00, -3.9533e+00, -4.2966e+00, -1.3157e+01,\n",
              "                       -3.3891e+00, -3.4264e+00, -6.1273e-01, -2.9829e+00,  6.4218e-02,\n",
              "                       -4.5884e+00, -1.4306e+00, -2.8075e+00, -3.7845e+00,  1.5270e+00,\n",
              "                        1.3162e+00,  2.0996e+00, -4.9996e+00,  1.5712e+00, -3.9027e+00,\n",
              "                       -4.1695e+00,  2.9694e+00, -4.4309e+00, -5.8925e+00, -1.2381e+00,\n",
              "                       -7.6144e-01,  4.0949e+00, -2.3370e+00,  1.2493e-01,  9.4877e-01,\n",
              "                       -2.7822e+00,  1.6233e+00,  1.4830e+00, -5.3788e+00, -4.4989e+00,\n",
              "                       -2.8792e+00,  5.7577e-01, -1.5720e+00, -1.0603e+00, -1.1720e+00,\n",
              "                       -2.6492e-01, -2.1299e+00, -4.3520e+00, -5.3990e+00,  1.9855e+00,\n",
              "                       -7.3676e+00,  1.1424e+00,  8.4803e-01,  9.2087e-01,  1.3040e+00,\n",
              "                       -2.5559e+00, -4.2526e+00, -6.9552e+00, -3.6241e-01, -1.5932e+00,\n",
              "                       -4.7496e+00, -2.9743e+00,  2.2410e+00, -8.7348e-01, -1.8698e+00,\n",
              "                       -2.6257e+00, -1.6451e+00, -4.5691e-01, -3.4626e+00, -5.8685e+00,\n",
              "                       -3.9438e+00, -4.5137e+00, -3.0367e+00, -2.6869e+00, -6.8645e+00,\n",
              "                       -7.1599e+00, -6.4199e+00, -5.7419e+00, -7.2536e-03, -9.2851e-01,\n",
              "                       -3.8869e+00, -5.1249e+00,  1.5874e+00, -7.2243e+00, -1.1923e+00,\n",
              "                       -6.2966e+00, -7.2222e+00,  5.7292e+00,  1.0278e+00,  4.6256e+00,\n",
              "                       -3.8307e+00, -4.5114e+00, -5.4876e+00, -3.9068e+00, -8.3927e+00,\n",
              "                       -1.2424e+00, -5.7511e+00,  2.7782e+00, -3.4984e-01, -2.8187e+00,\n",
              "                       -5.3354e+00, -6.0235e+00, -2.5984e+00,  2.3304e+00,  1.6625e+00,\n",
              "                       -1.0283e+00, -1.1342e+01,  3.5351e-01, -5.3869e+00, -8.3975e+00,\n",
              "                       -3.8166e+00,  1.1972e+00, -1.0018e+01, -2.4899e+00, -5.4427e+00,\n",
              "                       -1.7256e+00, -4.6739e+00, -1.8033e+00,  1.8357e+00, -1.5866e+00,\n",
              "                       -5.8538e+00, -3.7042e+00,  2.5210e+00, -2.3264e+00, -1.9674e+00,\n",
              "                       -3.2248e+00, -6.0205e+00,  4.2338e-01], dtype=torch.float64)),\n",
              "              ('batch5.running_var',\n",
              "               tensor([14.3196, 14.6305, 20.1232,  9.8606, 37.6911, 20.3907, 25.3048, 20.9204,\n",
              "                       14.3196, 16.7983, 26.4669, 15.2441,  9.7650, 37.4801, 14.6722, 18.5440,\n",
              "                       10.5325,  7.9248,  8.8414,  6.4228,  7.6158,  5.8898, 41.4873,  9.4156,\n",
              "                       31.1989, 26.1257, 13.0128, 14.8559, 23.8627,  8.0334,  8.3954, 14.8251,\n",
              "                        9.9811, 11.1815, 13.8868, 17.0303,  9.3227,  8.7197, 12.4750, 19.2195,\n",
              "                       13.0491, 17.2167,  9.2827, 15.8331, 12.9968, 13.0600, 17.7687, 15.4035,\n",
              "                       15.7192, 13.6247, 26.1894, 19.7404, 12.7366, 16.0998, 17.6954, 11.7184,\n",
              "                       12.0537, 19.1126, 11.1995, 31.4052, 18.7926, 13.0116, 14.2689, 16.5954,\n",
              "                       13.2718, 17.8100, 10.2095, 19.2574, 11.9097, 34.1910, 40.5895, 15.7062,\n",
              "                       12.0136, 10.4642, 34.5187, 18.9599, 23.0650, 36.3752, 10.4764, 19.4704,\n",
              "                        9.9179, 16.7647, 11.7491, 22.0719, 25.7622, 16.5637, 23.4515, 31.1340,\n",
              "                       18.6129,  9.5548, 11.2303, 23.1560,  7.4942, 15.8237, 19.5611, 14.5882,\n",
              "                       19.8138, 10.7519,  9.3264, 18.1648, 13.7334, 11.6900, 10.7556,  9.5087,\n",
              "                       13.2939,  8.5197, 18.2141, 10.4736, 30.2313, 16.8328, 16.6115,  9.9507,\n",
              "                       16.5068, 14.4892, 26.2708, 20.9421, 29.9915,  9.9821, 11.3902, 11.8835,\n",
              "                       14.6238, 22.0201, 13.5934, 34.7580, 12.1746, 14.2612, 18.7840, 14.1714],\n",
              "                      dtype=torch.float64)),\n",
              "              ('batch5.num_batches_tracked', tensor(6320)),\n",
              "              ('fc1.weight',\n",
              "               tensor([[ 0.0374,  0.0072, -0.0839,  ..., -0.0996,  0.0174, -0.0002],\n",
              "                       [-0.0403, -0.0292,  0.0692,  ...,  0.0887, -0.0128, -0.0011],\n",
              "                       [ 0.0278,  0.0264, -0.0669,  ..., -0.0769, -0.0046, -0.0047],\n",
              "                       ...,\n",
              "                       [-0.0443, -0.0259,  0.0906,  ...,  0.0717, -0.0225,  0.0049],\n",
              "                       [ 0.0400,  0.0221, -0.0430,  ..., -0.0629,  0.0234, -0.0106],\n",
              "                       [ 0.0356,  0.0217, -0.0738,  ..., -0.0749,  0.0060,  0.0069]],\n",
              "                      dtype=torch.float64)),\n",
              "              ('fc1.bias',\n",
              "               tensor([-0.0383,  0.0426, -0.0486, -0.0473,  0.0577, -0.0355, -0.0483, -0.0234,\n",
              "                       -0.0545, -0.0270,  0.0341,  0.0416, -0.0316, -0.0529,  0.0385,  0.0206,\n",
              "                       -0.0441,  0.0297, -0.0314, -0.0598,  0.0178,  0.0587, -0.0134,  0.0266,\n",
              "                        0.0141, -0.0295, -0.0254, -0.0321, -0.0475,  0.0229, -0.0327, -0.0093,\n",
              "                       -0.0261,  0.0242,  0.0299, -0.0418,  0.0335,  0.0311,  0.0308,  0.0357,\n",
              "                        0.0506, -0.0476, -0.0416, -0.0138,  0.0368, -0.0192, -0.0160,  0.0334,\n",
              "                       -0.0068,  0.0433, -0.0366, -0.0247,  0.0331, -0.0100, -0.0421,  0.0513,\n",
              "                        0.0431,  0.0332, -0.0457, -0.0492, -0.0499,  0.0477, -0.0498, -0.0272,\n",
              "                        0.0193,  0.0298, -0.0141, -0.0410], dtype=torch.float64)),\n",
              "              ('fc2.weight',\n",
              "               tensor([[-0.0890,  0.0526, -0.1081, -0.0634,  0.0961, -0.0761, -0.0561, -0.0200,\n",
              "                        -0.1086, -0.0312,  0.0399,  0.0736, -0.0440, -0.0785,  0.0351,  0.0116,\n",
              "                        -0.0509,  0.0866, -0.0535, -0.0984,  0.0015,  0.0949, -0.0019,  0.0720,\n",
              "                         0.0111, -0.0139, -0.0181, -0.0060, -0.1123,  0.0015, -0.1142, -0.0055,\n",
              "                        -0.0007,  0.0091,  0.0786, -0.0942,  0.0953,  0.0006,  0.0582,  0.0594,\n",
              "                         0.1011, -0.0939, -0.0822, -0.0010,  0.0664, -0.0175, -0.0030,  0.0511,\n",
              "                        -0.0017,  0.1108, -0.0292, -0.0059,  0.0658, -0.0014, -0.0422,  0.1099,\n",
              "                         0.0868,  0.1087, -0.0639, -0.0795, -0.0906,  0.0419, -0.0874, -0.0697,\n",
              "                         0.0013,  0.0693, -0.0070, -0.0861,  0.0265]], dtype=torch.float64)),\n",
              "              ('fc2.bias', tensor([-0.0557], dtype=torch.float64))]),\n",
              " 'optimizer': {'state': {0: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[[[ 3.7029e-01,  3.9343e-01,  1.7303e-01],\n",
              "              [ 3.8071e-01,  4.4982e-01,  2.2676e-01],\n",
              "              [ 3.6035e-01,  3.3056e-01,  8.5683e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[ 2.7684e+00,  2.8670e+00,  3.0888e+00],\n",
              "              [ 3.1012e+00,  3.0829e+00,  3.1269e+00],\n",
              "              [ 3.0996e+00,  2.8990e+00,  2.9100e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[ 1.4787e-03,  4.8935e-04,  9.1970e-04],\n",
              "              [ 1.0096e-03, -4.5051e-04, -1.0211e-03],\n",
              "              [ 6.0529e-04, -7.2199e-05, -9.2371e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[ 2.6425e+00,  2.8250e+00,  2.8461e+00],\n",
              "              [ 2.2956e+00,  2.5512e+00,  2.5557e+00],\n",
              "              [ 1.8805e+00,  2.1810e+00,  2.1288e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[-1.3061e-03,  1.1019e-03,  2.9698e-03],\n",
              "              [-1.9181e-03,  9.7379e-05,  1.0006e-03],\n",
              "              [-1.0103e-03,  5.1056e-04,  8.5866e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[ 3.2698e-02,  2.7413e-02,  4.8239e-02],\n",
              "              [ 6.1932e-02,  4.9012e-02,  8.0785e-02],\n",
              "              [ 9.6314e-02,  1.0731e-01,  1.0514e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 3.3163e-01,  4.2358e-01,  5.5792e-01],\n",
              "              [ 3.5857e-01,  4.8666e-01,  6.6533e-01],\n",
              "              [ 2.3147e-01,  4.4522e-01,  6.6945e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 4.1325e-01,  3.8258e-01,  3.9251e-01],\n",
              "              [ 4.7842e-01,  4.9459e-01,  5.0549e-01],\n",
              "              [ 4.8798e-01,  5.0430e-01,  5.1551e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 6.7482e-01,  7.3897e-01,  8.3600e-01],\n",
              "              [ 3.8354e-01,  2.3824e-01,  4.5787e-01],\n",
              "              [ 3.9698e-01,  2.4718e-01,  5.0784e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 1.5505e+00,  1.9018e+00,  2.0399e+00],\n",
              "              [ 1.9077e+00,  2.3047e+00,  2.2987e+00],\n",
              "              [ 2.4152e+00,  2.5992e+00,  2.6502e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[ 7.4116e-03,  3.8686e-03, -1.4177e-02],\n",
              "              [ 1.0851e-02,  4.1225e-03, -1.4257e-02],\n",
              "              [ 1.0264e-02,  5.6519e-03, -5.6961e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[ 5.0925e-02,  4.8199e-02,  2.8927e-02],\n",
              "              [ 5.2385e-02,  4.0818e-02,  1.9535e-02],\n",
              "              [ 4.9069e-02,  3.8208e-02,  1.5824e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[-1.0818e-02, -9.8826e-03, -2.5863e-02],\n",
              "              [-1.4832e-02, -9.3370e-03, -1.3023e-02],\n",
              "              [ 4.1761e-03, -3.2255e-03, -1.7003e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[-5.5756e-01, -6.2211e-01, -5.9915e-01],\n",
              "              [-4.6317e-01, -5.3869e-01, -4.9386e-01],\n",
              "              [-5.0750e-01, -5.2940e-01, -4.9720e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[-8.9115e-03,  1.3360e-03,  5.8916e-02],\n",
              "              [-1.7708e-02,  5.7067e-02,  8.7267e-02],\n",
              "              [ 1.2401e-01,  1.4657e-01,  1.5591e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 2.9537e-01,  2.5043e-01,  1.2329e-01],\n",
              "              [ 1.9893e-01,  9.8089e-02,  6.2110e-02],\n",
              "              [ 4.2778e-01,  2.0889e-01,  1.6802e-01]]]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[[[9.0448e+00, 1.0718e+01, 1.1827e+01],\n",
              "              [1.0759e+01, 1.0432e+01, 1.0308e+01],\n",
              "              [1.0584e+01, 1.0070e+01, 9.4706e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[3.7846e+01, 3.6790e+01, 3.6444e+01],\n",
              "              [3.7718e+01, 3.7448e+01, 3.7033e+01],\n",
              "              [3.8593e+01, 3.8975e+01, 3.8191e+01]]],\n",
              "    \n",
              "    \n",
              "            [[[1.0037e-04, 2.0876e-05, 3.4074e-05],\n",
              "              [4.5536e-05, 4.5863e-06, 3.3476e-05],\n",
              "              [3.0577e-05, 1.0033e-05, 3.8735e-05]]],\n",
              "    \n",
              "    \n",
              "            [[[1.9758e+01, 1.9136e+01, 1.8669e+01],\n",
              "              [1.9705e+01, 1.8587e+01, 1.8316e+01],\n",
              "              [1.9092e+01, 1.7948e+01, 1.7319e+01]]],\n",
              "    \n",
              "    \n",
              "            [[[8.2696e-04, 3.3446e-04, 2.2477e-04],\n",
              "              [4.9662e-04, 7.9005e-05, 6.6409e-05],\n",
              "              [2.8496e-04, 2.4821e-05, 1.0090e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[2.7913e-01, 3.9198e-01, 5.1073e-01],\n",
              "              [2.8022e-01, 3.9029e-01, 5.1210e-01],\n",
              "              [3.0177e-01, 4.0940e-01, 5.3017e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[9.0022e+00, 9.2304e+00, 9.1598e+00],\n",
              "              [7.6862e+00, 7.3157e+00, 8.0446e+00],\n",
              "              [9.4619e+00, 9.5704e+00, 9.3395e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[1.5082e+00, 1.4195e+00, 1.4330e+00],\n",
              "              [1.7386e+00, 1.7122e+00, 1.7908e+00],\n",
              "              [2.3552e+00, 2.2567e+00, 2.2333e+00]]],\n",
              "    \n",
              "    \n",
              "            [[[3.4051e+01, 3.1296e+01, 3.0134e+01],\n",
              "              [3.1872e+01, 3.0689e+01, 3.0527e+01],\n",
              "              [3.1330e+01, 3.0556e+01, 2.9871e+01]]],\n",
              "    \n",
              "    \n",
              "            [[[1.1778e+02, 1.1695e+02, 1.1819e+02],\n",
              "              [1.1763e+02, 1.1632e+02, 1.1796e+02],\n",
              "              [1.1727e+02, 1.1969e+02, 1.1971e+02]]],\n",
              "    \n",
              "    \n",
              "            [[[8.2267e-04, 4.7084e-04, 4.7469e-04],\n",
              "              [4.9713e-04, 2.1054e-04, 3.0372e-04],\n",
              "              [6.1261e-04, 2.1859e-04, 3.8082e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[3.0970e-02, 1.8894e-02, 1.0441e-02],\n",
              "              [2.8998e-02, 1.2739e-02, 5.7912e-03],\n",
              "              [2.4636e-02, 9.5258e-03, 3.4867e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[1.3134e-03, 1.5382e-03, 2.6321e-03],\n",
              "              [3.8048e-04, 6.1774e-04, 1.8128e-03],\n",
              "              [5.7554e-04, 3.0371e-04, 1.2570e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[1.2875e+00, 1.1188e+00, 9.2863e-01],\n",
              "              [1.2100e+00, 9.5901e-01, 7.9847e-01],\n",
              "              [1.1362e+00, 9.2893e-01, 8.8076e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[1.4856e+01, 1.5090e+01, 1.5228e+01],\n",
              "              [1.5029e+01, 1.5500e+01, 1.5576e+01],\n",
              "              [1.5292e+01, 1.5926e+01, 1.6134e+01]]],\n",
              "    \n",
              "    \n",
              "            [[[6.2401e+01, 6.1370e+01, 6.1489e+01],\n",
              "              [6.4399e+01, 6.3678e+01, 6.2746e+01],\n",
              "              [6.2204e+01, 6.2969e+01, 6.2793e+01]]]], dtype=torch.float64)},\n",
              "   1: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-3.7570e-11,  1.4769e-11, -3.4098e-14, -7.1862e-11, -2.6650e-14,\n",
              "             1.7116e-12, -3.8511e-11, -2.0525e-12,  5.8173e-11, -2.3125e-11,\n",
              "             3.8189e-13, -9.3721e-14, -1.1182e-13,  6.1782e-12,  8.8811e-12,\n",
              "             2.7180e-13], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([8.8584e-20, 1.5726e-20, 4.3169e-25, 2.4741e-19, 1.1344e-24, 3.0292e-22,\n",
              "            7.2611e-20, 2.6936e-22, 5.4454e-20, 1.1031e-19, 2.4346e-24, 4.1130e-24,\n",
              "            6.2081e-25, 2.9013e-22, 9.2728e-21, 1.4270e-23], dtype=torch.float64)},\n",
              "   2: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.0305,  0.4292,  0.0886,  0.1113,  0.0652,  0.0324, -0.1108, -0.4055,\n",
              "            -0.1394, -0.3899,  0.0458,  0.1181,  0.0236, -0.3821,  0.2635,  0.0167],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.3376, 0.7694, 0.1326, 0.5241, 0.1147, 0.7700, 0.3636, 0.5488, 0.6040,\n",
              "            1.0666, 0.2279, 0.2180, 0.3550, 0.4134, 2.0655, 1.3620],\n",
              "           dtype=torch.float64)},\n",
              "   3: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.1610, -0.0848,  0.0140,  0.0125, -0.0442,  0.1231, -0.0323, -0.8184,\n",
              "            -0.1834, -0.0842,  0.1541,  0.1105,  0.0301, -0.1135,  0.0446,  0.3260],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.5718, 0.4392, 0.2575, 0.3842, 0.2149, 0.3727, 1.3090, 2.0767, 0.3287,\n",
              "            0.3505, 0.2223, 0.4994, 0.5131, 0.3850, 1.5173, 0.6887],\n",
              "           dtype=torch.float64)},\n",
              "   4: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[[[-2.7939e-03,  3.5133e-03, -5.7769e-04],\n",
              "              [-2.2518e-03,  2.9545e-03,  1.4221e-04],\n",
              "              [ 1.1186e-03,  6.3513e-03, -4.5498e-03]],\n",
              "    \n",
              "             [[-2.0668e-02, -7.2654e-03, -5.2174e-03],\n",
              "              [-1.0971e-02, -3.2238e-03, -1.3069e-02],\n",
              "              [-3.1424e-03,  1.3425e-03, -9.3596e-03]],\n",
              "    \n",
              "             [[ 1.4495e-02,  1.4127e-02,  9.0827e-03],\n",
              "              [ 1.5069e-02,  1.4599e-02,  9.7701e-03],\n",
              "              [ 1.6107e-02,  1.6220e-02,  1.1218e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-3.7587e-03, -1.1119e-03, -2.3949e-03],\n",
              "              [-4.5926e-03,  2.2634e-04,  1.1657e-03],\n",
              "              [-1.1478e-02,  4.1870e-04,  2.1626e-05]],\n",
              "    \n",
              "             [[-9.7390e-04,  4.4609e-03, -2.7851e-04],\n",
              "              [-6.2789e-03, -2.2540e-04, -3.3103e-03],\n",
              "              [-4.9780e-03, -1.5874e-03,  7.2961e-04]],\n",
              "    \n",
              "             [[-2.5639e-02, -1.3236e-02, -1.5451e-02],\n",
              "              [-1.5457e-02, -1.1170e-02, -7.4601e-04],\n",
              "              [-5.4662e-02, -4.0387e-02, -2.5093e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[-2.3507e-02, -1.4081e-02,  1.2763e-03],\n",
              "              [-3.5416e-03,  2.8495e-02, -3.1380e-04],\n",
              "              [ 2.4787e-02,  3.7363e-02,  5.6134e-03]],\n",
              "    \n",
              "             [[-9.7182e-03, -9.4894e-02, -9.0056e-02],\n",
              "              [ 1.4681e-02, -1.7552e-03, -9.1391e-04],\n",
              "              [ 8.4071e-02,  9.4521e-02,  7.0982e-02]],\n",
              "    \n",
              "             [[ 1.2361e-02,  1.5029e-02,  1.5751e-02],\n",
              "              [ 1.5443e-02,  1.5853e-02,  1.5193e-02],\n",
              "              [ 1.5390e-02,  1.6237e-02,  1.4998e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-4.2157e-03,  1.9965e-02,  1.7909e-02],\n",
              "              [ 1.5119e-02,  5.8175e-02,  2.4098e-02],\n",
              "              [ 4.8511e-02, -3.3060e-04, -1.0555e-02]],\n",
              "    \n",
              "             [[-1.3741e-02,  1.7234e-02, -4.1359e-02],\n",
              "              [-8.8414e-03,  1.0993e-01, -2.0838e-02],\n",
              "              [ 4.1518e-02,  8.4798e-02, -6.8793e-03]],\n",
              "    \n",
              "             [[-9.2613e-02,  1.8035e-02,  3.5906e-03],\n",
              "              [ 1.9008e-02,  3.2106e-03,  1.0769e-03],\n",
              "              [ 2.3656e-02, -3.1226e-02, -2.1911e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[ 4.1287e-02,  3.8220e-02,  2.6454e-02],\n",
              "              [ 4.2032e-02,  3.8285e-02,  5.6128e-02],\n",
              "              [ 3.3755e-02,  3.8236e-02,  5.6697e-02]],\n",
              "    \n",
              "             [[ 4.9590e-03, -3.7840e-02,  5.5444e-04],\n",
              "              [ 2.8489e-02, -1.8524e-03,  4.2149e-02],\n",
              "              [ 2.6016e-02, -2.5781e-03,  2.6402e-02]],\n",
              "    \n",
              "             [[ 4.3170e-02,  3.7567e-02,  3.6077e-02],\n",
              "              [ 4.5867e-02,  3.9111e-02,  3.6263e-02],\n",
              "              [ 4.7611e-02,  4.0658e-02,  3.5734e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-2.2312e-03, -9.4458e-03,  1.2268e-02],\n",
              "              [ 8.0427e-04,  1.2878e-02,  3.2096e-02],\n",
              "              [ 9.4612e-03,  1.3578e-02,  5.1144e-02]],\n",
              "    \n",
              "             [[ 2.8343e-02,  9.4485e-03,  4.9385e-02],\n",
              "              [ 2.5815e-02,  1.8248e-02,  6.4536e-02],\n",
              "              [ 2.2882e-02,  2.7323e-02,  5.6905e-02]],\n",
              "    \n",
              "             [[-2.2917e-02, -3.5955e-02,  1.2497e-02],\n",
              "              [-4.1213e-05,  1.0412e-02,  3.6384e-02],\n",
              "              [ 3.1419e-02,  5.5686e-02,  9.1757e-02]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[-2.8688e-02, -2.5261e-02,  1.0099e-02],\n",
              "              [-2.6042e-02, -7.4075e-03, -5.1222e-03],\n",
              "              [-1.9170e-02, -1.3164e-02,  3.7192e-02]],\n",
              "    \n",
              "             [[-7.1759e-02, -1.0920e-01, -6.1731e-02],\n",
              "              [ 2.0175e-02,  5.2699e-02,  1.2273e-01],\n",
              "              [ 9.2598e-02,  1.1403e-01,  2.6244e-01]],\n",
              "    \n",
              "             [[ 2.8066e-03,  4.4659e-03,  6.7093e-03],\n",
              "              [ 2.5053e-03,  2.3151e-04,  3.9353e-03],\n",
              "              [ 3.1530e-03, -7.4515e-04, -5.8711e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 7.9224e-03,  1.1935e-02,  9.9670e-02],\n",
              "              [ 4.9307e-02,  3.8700e-02,  6.8395e-02],\n",
              "              [ 9.1545e-02,  5.3811e-02,  6.7795e-02]],\n",
              "    \n",
              "             [[ 6.4573e-02,  2.3462e-02,  1.2731e-01],\n",
              "              [ 9.2993e-02, -1.8644e-02,  1.3425e-01],\n",
              "              [ 1.0233e-01, -5.3632e-02,  8.4900e-02]],\n",
              "    \n",
              "             [[ 5.2788e-03,  3.6572e-02,  1.2082e-01],\n",
              "              [ 7.7223e-02,  3.4732e-02,  6.8127e-02],\n",
              "              [ 1.6594e-01,  1.0595e-01,  6.5189e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[-2.4935e-02,  3.5299e-02, -7.3946e-03],\n",
              "              [ 2.8075e-04, -9.7802e-03,  1.2667e-02],\n",
              "              [ 4.6920e-02, -6.7939e-02, -1.1049e-02]],\n",
              "    \n",
              "             [[-2.5919e-01, -1.9525e-01, -1.4084e-01],\n",
              "              [-8.3715e-02, -1.3584e-01, -9.2944e-02],\n",
              "              [ 5.8755e-02, -4.3759e-02, -8.6989e-02]],\n",
              "    \n",
              "             [[ 8.6959e-03,  1.9060e-02,  3.8427e-02],\n",
              "              [ 8.5330e-03,  1.6868e-02,  3.3020e-02],\n",
              "              [ 9.3299e-03,  1.7564e-02,  2.7511e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-8.5907e-02, -1.1268e-01, -9.9387e-02],\n",
              "              [-8.1402e-02, -1.9981e-01, -1.9163e-01],\n",
              "              [-1.4813e-01, -1.8812e-01, -1.2341e-01]],\n",
              "    \n",
              "             [[-5.9235e-02, -2.1076e-01, -1.1983e-01],\n",
              "              [-5.9857e-03, -2.0461e-01, -1.2930e-01],\n",
              "              [ 2.8644e-02, -1.4561e-01, -1.7034e-01]],\n",
              "    \n",
              "             [[-8.7874e-03, -1.2619e-01, -1.5891e-01],\n",
              "              [-1.7264e-01, -2.3578e-01, -2.0166e-01],\n",
              "              [-1.2676e-01, -1.3332e-01, -1.3360e-01]]],\n",
              "    \n",
              "    \n",
              "            [[[ 7.5616e-02,  7.1279e-03,  4.0491e-02],\n",
              "              [ 4.4155e-02,  3.8207e-02,  3.8904e-02],\n",
              "              [ 5.7691e-02,  3.1304e-02,  4.7863e-02]],\n",
              "    \n",
              "             [[-3.5838e-02, -4.8212e-02, -4.9657e-02],\n",
              "              [-8.5607e-02, -6.1500e-02, -3.5381e-03],\n",
              "              [-8.3720e-03, -9.9570e-04, -6.0510e-03]],\n",
              "    \n",
              "             [[ 3.6231e-02,  3.2278e-02,  3.1347e-02],\n",
              "              [ 3.9879e-02,  3.2869e-02,  3.2393e-02],\n",
              "              [ 3.9950e-02,  3.6586e-02,  3.4733e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-1.5750e-02, -9.5190e-03,  1.9938e-02],\n",
              "              [ 3.4380e-03,  4.1291e-03,  2.5748e-02],\n",
              "              [-7.2341e-03, -1.6986e-02,  1.2415e-02]],\n",
              "    \n",
              "             [[-6.3020e-03, -5.4444e-03,  1.7163e-02],\n",
              "              [ 2.4736e-02,  4.9659e-03,  4.2754e-02],\n",
              "              [ 1.4302e-02,  3.0816e-02,  1.2411e-02]],\n",
              "    \n",
              "             [[-2.4633e-03, -1.6729e-02,  2.4917e-02],\n",
              "              [-1.7489e-02, -5.1227e-03, -2.4234e-02],\n",
              "              [-2.1637e-02, -1.0848e-02,  1.9412e-02]]]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[[[0.0057, 0.0046, 0.0047],\n",
              "              [0.0049, 0.0048, 0.0045],\n",
              "              [0.0048, 0.0049, 0.0059]],\n",
              "    \n",
              "             [[0.0022, 0.0015, 0.0012],\n",
              "              [0.0026, 0.0027, 0.0019],\n",
              "              [0.0013, 0.0016, 0.0014]],\n",
              "    \n",
              "             [[0.0055, 0.0054, 0.0053],\n",
              "              [0.0055, 0.0055, 0.0053],\n",
              "              [0.0053, 0.0055, 0.0053]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0036, 0.0025, 0.0023],\n",
              "              [0.0035, 0.0023, 0.0021],\n",
              "              [0.0062, 0.0045, 0.0034]],\n",
              "    \n",
              "             [[0.0013, 0.0007, 0.0004],\n",
              "              [0.0012, 0.0007, 0.0005],\n",
              "              [0.0012, 0.0007, 0.0006]],\n",
              "    \n",
              "             [[0.0072, 0.0034, 0.0025],\n",
              "              [0.0043, 0.0024, 0.0013],\n",
              "              [0.0218, 0.0150, 0.0080]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0126, 0.0122, 0.0094],\n",
              "              [0.0088, 0.0084, 0.0141],\n",
              "              [0.0140, 0.0105, 0.0101]],\n",
              "    \n",
              "             [[0.0709, 0.0734, 0.0690],\n",
              "              [0.0352, 0.0250, 0.0353],\n",
              "              [0.0664, 0.0725, 0.0817]],\n",
              "    \n",
              "             [[0.0040, 0.0031, 0.0027],\n",
              "              [0.0041, 0.0031, 0.0026],\n",
              "              [0.0042, 0.0031, 0.0027]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0337, 0.0354, 0.0378],\n",
              "              [0.0408, 0.0443, 0.0408],\n",
              "              [0.0370, 0.0460, 0.0349]],\n",
              "    \n",
              "             [[0.0459, 0.0422, 0.0292],\n",
              "              [0.0512, 0.0572, 0.0270],\n",
              "              [0.0490, 0.0666, 0.0299]],\n",
              "    \n",
              "             [[0.0446, 0.0501, 0.0554],\n",
              "              [0.0861, 0.0966, 0.0737],\n",
              "              [0.0390, 0.0422, 0.0442]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0150, 0.0201, 0.0148],\n",
              "              [0.0151, 0.0162, 0.0158],\n",
              "              [0.0138, 0.0140, 0.0158]],\n",
              "    \n",
              "             [[0.0063, 0.0065, 0.0074],\n",
              "              [0.0090, 0.0046, 0.0063],\n",
              "              [0.0190, 0.0078, 0.0082]],\n",
              "    \n",
              "             [[0.0115, 0.0117, 0.0114],\n",
              "              [0.0111, 0.0112, 0.0112],\n",
              "              [0.0108, 0.0108, 0.0108]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0095, 0.0059, 0.0065],\n",
              "              [0.0091, 0.0056, 0.0098],\n",
              "              [0.0075, 0.0052, 0.0143]],\n",
              "    \n",
              "             [[0.0188, 0.0062, 0.0136],\n",
              "              [0.0210, 0.0051, 0.0163],\n",
              "              [0.0200, 0.0056, 0.0210]],\n",
              "    \n",
              "             [[0.0436, 0.0239, 0.0221],\n",
              "              [0.0243, 0.0202, 0.0281],\n",
              "              [0.0176, 0.0209, 0.0383]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[0.0327, 0.0404, 0.0190],\n",
              "              [0.0404, 0.0151, 0.0291],\n",
              "              [0.0316, 0.0213, 0.0210]],\n",
              "    \n",
              "             [[0.0893, 0.0841, 0.0934],\n",
              "              [0.1159, 0.1140, 0.1255],\n",
              "              [0.1358, 0.2039, 0.3385]],\n",
              "    \n",
              "             [[0.0026, 0.0026, 0.0027],\n",
              "              [0.0027, 0.0029, 0.0026],\n",
              "              [0.0027, 0.0032, 0.0030]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0755, 0.0563, 0.0534],\n",
              "              [0.0515, 0.0480, 0.0534],\n",
              "              [0.0512, 0.0616, 0.0604]],\n",
              "    \n",
              "             [[0.1987, 0.0327, 0.0798],\n",
              "              [0.2091, 0.0530, 0.0833],\n",
              "              [0.1569, 0.0886, 0.1020]],\n",
              "    \n",
              "             [[0.1796, 0.0900, 0.0879],\n",
              "              [0.0786, 0.0928, 0.1170],\n",
              "              [0.2412, 0.1520, 0.1213]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0328, 0.0358, 0.0326],\n",
              "              [0.0220, 0.0331, 0.0654],\n",
              "              [0.0361, 0.0530, 0.0350]],\n",
              "    \n",
              "             [[0.1968, 0.1809, 0.1461],\n",
              "              [0.0963, 0.0589, 0.0762],\n",
              "              [0.3494, 0.2181, 0.1629]],\n",
              "    \n",
              "             [[0.0182, 0.0180, 0.0182],\n",
              "              [0.0180, 0.0175, 0.0172],\n",
              "              [0.0179, 0.0176, 0.0170]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.1182, 0.1093, 0.1053],\n",
              "              [0.1414, 0.1704, 0.1395],\n",
              "              [0.1506, 0.1364, 0.0920]],\n",
              "    \n",
              "             [[0.0439, 0.1384, 0.1147],\n",
              "              [0.0566, 0.1472, 0.1194],\n",
              "              [0.1053, 0.1084, 0.1532]],\n",
              "    \n",
              "             [[0.1224, 0.2106, 0.2065],\n",
              "              [0.3017, 0.3618, 0.2819],\n",
              "              [0.1672, 0.0862, 0.1123]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0347, 0.0270, 0.0211],\n",
              "              [0.0256, 0.0184, 0.0173],\n",
              "              [0.0182, 0.0144, 0.0149]],\n",
              "    \n",
              "             [[0.0831, 0.1048, 0.1142],\n",
              "              [0.0965, 0.0517, 0.0576],\n",
              "              [0.0677, 0.0304, 0.0277]],\n",
              "    \n",
              "             [[0.0097, 0.0087, 0.0083],\n",
              "              [0.0119, 0.0095, 0.0086],\n",
              "              [0.0129, 0.0108, 0.0092]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0551, 0.0419, 0.0320],\n",
              "              [0.0422, 0.0387, 0.0335],\n",
              "              [0.0372, 0.0337, 0.0332]],\n",
              "    \n",
              "             [[0.0340, 0.0253, 0.0345],\n",
              "              [0.0379, 0.0105, 0.0163],\n",
              "              [0.0339, 0.0147, 0.0113]],\n",
              "    \n",
              "             [[0.0996, 0.0470, 0.0282],\n",
              "              [0.0561, 0.0584, 0.0349],\n",
              "              [0.0314, 0.0389, 0.0389]]]], dtype=torch.float64)},\n",
              "   5: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-9.3977e-18,  2.4585e-15,  1.2811e-15, -6.0700e-15, -1.2794e-15,\n",
              "             3.3958e-15,  1.3111e-15,  4.2187e-16, -4.2016e-15, -5.4445e-15,\n",
              "             8.7190e-15,  1.7915e-16, -8.2440e-15,  2.6131e-16,  1.6312e-15,\n",
              "             1.2422e-15, -4.1911e-16, -6.7442e-16,  5.5536e-16,  2.1059e-15,\n",
              "            -7.1017e-16, -1.5229e-15,  3.1262e-15, -2.0040e-15, -1.2803e-15,\n",
              "             2.5559e-15,  3.1386e-15, -1.0201e-15, -1.2574e-15,  5.6661e-16,\n",
              "             1.1942e-15, -4.0948e-15], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([2.4203e-28, 4.2272e-28, 7.7098e-28, 6.6084e-28, 3.5664e-28, 5.9626e-28,\n",
              "            1.1753e-27, 2.0315e-28, 3.9597e-28, 2.3260e-27, 2.4820e-27, 1.1550e-27,\n",
              "            1.0395e-26, 1.2972e-27, 2.0638e-27, 1.9652e-28, 1.2774e-28, 5.9765e-29,\n",
              "            2.7186e-28, 5.6486e-28, 2.8222e-28, 3.4910e-27, 1.4793e-27, 2.0126e-27,\n",
              "            2.1075e-28, 3.5835e-28, 6.8476e-28, 1.8985e-28, 1.2473e-28, 3.9567e-28,\n",
              "            8.6785e-28, 2.5385e-28], dtype=torch.float64)},\n",
              "   6: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.0283,  0.0156,  0.0061,  0.0516,  0.2067, -0.1905,  0.1076, -0.1223,\n",
              "             0.0449, -0.0725, -0.1888,  0.0056,  0.2008,  0.0706, -0.2633, -0.1418,\n",
              "            -0.0325,  0.0276, -0.1682,  0.1065, -0.0419,  0.0021,  0.1848,  0.0905,\n",
              "            -0.0088,  0.1129, -0.1225,  0.2020,  0.0318, -0.1871, -0.0413,  0.0241],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.0423, 0.1030, 0.1060, 0.1268, 0.4915, 0.2422, 0.1151, 1.3293, 0.4424,\n",
              "            0.3049, 0.4778, 0.1496, 0.6121, 0.1496, 0.1909, 0.3165, 0.3652, 0.1356,\n",
              "            0.3316, 0.1986, 0.0229, 0.1985, 0.1767, 0.4144, 0.5369, 0.0404, 0.4972,\n",
              "            0.2960, 0.0324, 0.3984, 0.1004, 0.0792], dtype=torch.float64)},\n",
              "   7: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.0468, -0.0938, -0.0426,  0.0946, -0.1016,  0.1187,  0.0806, -0.0775,\n",
              "            -0.1411, -0.0396, -0.2859, -0.0664,  0.2048,  0.0048, -0.1542, -0.0284,\n",
              "            -0.0141,  0.1485, -0.2193,  0.0899, -0.0274,  0.1633,  0.3284,  0.1034,\n",
              "             0.1437,  0.2626, -0.0350, -0.0684,  0.0996, -0.0910,  0.0282, -0.0254],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.1833, 0.1763, 0.4229, 0.4516, 0.2322, 0.2344, 0.2718, 0.3603, 0.6366,\n",
              "            0.3435, 0.4533, 0.1149, 0.7711, 0.6709, 0.2049, 0.1493, 0.3568, 0.1441,\n",
              "            0.4335, 0.5372, 0.0943, 0.4580, 0.6523, 1.2948, 0.2512, 0.1743, 0.7416,\n",
              "            0.2140, 0.1112, 0.3613, 0.0976, 0.2058], dtype=torch.float64)},\n",
              "   8: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[[[-4.5524e-03,  5.9340e-05, -1.8616e-04],\n",
              "              [-7.4915e-03, -5.4242e-03, -2.5158e-03],\n",
              "              [-5.0967e-03, -5.0453e-03, -2.3586e-03]],\n",
              "    \n",
              "             [[-7.9663e-03, -1.5621e-02, -1.2632e-02],\n",
              "              [-3.5539e-03, -8.0130e-04, -1.7866e-03],\n",
              "              [-1.5842e-03, -8.9852e-03,  3.3948e-03]],\n",
              "    \n",
              "             [[ 9.9487e-03,  9.7231e-03,  7.2483e-03],\n",
              "              [ 7.9862e-03,  2.9680e-03,  6.9788e-03],\n",
              "              [ 3.8345e-03,  5.8233e-03,  8.4451e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-7.0720e-03, -6.3427e-03,  2.7429e-03],\n",
              "              [-1.8034e-02, -1.5614e-02,  6.5578e-06],\n",
              "              [-7.7777e-03, -2.6035e-02,  2.1357e-03]],\n",
              "    \n",
              "             [[-1.1628e-02, -1.2355e-02, -5.3808e-03],\n",
              "              [-2.6448e-02,  2.2617e-03,  2.8919e-03],\n",
              "              [-2.8989e-02,  3.4116e-03, -7.3613e-03]],\n",
              "    \n",
              "             [[-1.3680e-02, -5.0891e-03,  9.3717e-03],\n",
              "              [-2.0086e-02, -1.8333e-02,  1.0341e-02],\n",
              "              [-1.8480e-02,  1.1952e-03,  7.9226e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[-2.3506e-03,  2.5104e-03, -1.8482e-03],\n",
              "              [-2.3124e-03,  7.2450e-04, -1.3924e-03],\n",
              "              [ 2.3104e-03,  1.4573e-03, -1.3953e-03]],\n",
              "    \n",
              "             [[-1.5649e-02,  2.0200e-02, -2.9859e-02],\n",
              "              [-3.1385e-02,  2.8289e-02, -3.2822e-02],\n",
              "              [-4.7216e-02, -7.4129e-03, -2.7551e-02]],\n",
              "    \n",
              "             [[ 1.9961e-03, -3.3751e-03,  1.0354e-02],\n",
              "              [-1.7964e-03, -7.7092e-04,  8.6422e-03],\n",
              "              [ 4.9041e-03, -3.8537e-03,  1.7191e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-1.8979e-02, -3.1608e-02, -1.7493e-02],\n",
              "              [-1.3559e-02, -3.9135e-02, -4.3574e-03],\n",
              "              [-7.3646e-03, -3.4291e-02,  7.7524e-03]],\n",
              "    \n",
              "             [[-4.8874e-02, -2.3040e-02, -1.1114e-02],\n",
              "              [-2.7375e-02, -7.3083e-03, -1.4491e-02],\n",
              "              [-1.0046e-02, -7.3538e-03, -4.1111e-03]],\n",
              "    \n",
              "             [[-2.2398e-03, -3.8040e-03,  2.2970e-02],\n",
              "              [-1.6111e-02, -1.5396e-02,  3.2856e-02],\n",
              "              [-7.4948e-03,  4.1258e-03,  3.3102e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[ 5.0221e-03,  1.6629e-02,  1.6310e-02],\n",
              "              [ 6.5312e-03,  7.0500e-03,  5.3891e-03],\n",
              "              [-5.5820e-03,  5.8017e-03,  1.3291e-02]],\n",
              "    \n",
              "             [[ 2.4187e-02,  3.6067e-04, -3.3924e-02],\n",
              "              [ 8.9411e-02,  1.8735e-02,  1.4108e-02],\n",
              "              [ 5.9861e-02, -4.0085e-03, -2.7012e-02]],\n",
              "    \n",
              "             [[ 1.1559e-02,  2.1208e-02, -1.2033e-02],\n",
              "              [ 6.5939e-03,  5.6774e-04, -1.8909e-03],\n",
              "              [ 8.7266e-03,  1.3602e-03,  6.8819e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 4.6436e-02,  4.9949e-02, -1.3947e-02],\n",
              "              [-1.5350e-02,  2.5247e-02,  2.0911e-02],\n",
              "              [-1.0331e-02,  5.2688e-02,  4.5664e-02]],\n",
              "    \n",
              "             [[-4.2047e-02,  2.7073e-02,  4.5032e-02],\n",
              "              [ 6.2174e-02,  7.3480e-02,  7.7640e-03],\n",
              "              [ 1.4606e-02,  4.0781e-02,  4.9780e-02]],\n",
              "    \n",
              "             [[ 3.1045e-03,  3.4012e-02, -2.5746e-02],\n",
              "              [-4.1298e-02,  2.5701e-02,  4.6538e-02],\n",
              "              [ 1.7968e-02,  2.6102e-02,  4.2639e-02]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[ 2.2739e-02,  1.6763e-02,  8.3200e-03],\n",
              "              [ 2.6729e-02,  2.5235e-02,  2.0058e-02],\n",
              "              [ 2.9135e-02,  2.8935e-02,  1.4488e-02]],\n",
              "    \n",
              "             [[-2.2051e-02, -5.0695e-03,  5.5231e-02],\n",
              "              [-1.1609e-02, -2.0617e-02,  3.1102e-02],\n",
              "              [-8.2592e-02,  2.0017e-02,  4.4505e-02]],\n",
              "    \n",
              "             [[ 3.5574e-02,  4.6536e-02,  3.4366e-02],\n",
              "              [ 5.9960e-02,  3.4817e-02,  5.0662e-02],\n",
              "              [ 5.5270e-02,  5.0953e-02,  4.8899e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-3.3383e-02, -3.2282e-02, -1.0922e-01],\n",
              "              [-2.8307e-04, -2.0186e-03, -3.0370e-02],\n",
              "              [-2.7939e-02, -9.7431e-02, -3.3990e-02]],\n",
              "    \n",
              "             [[ 6.4838e-02, -3.4925e-02,  8.0311e-03],\n",
              "              [ 2.2744e-05, -1.0113e-02,  1.6550e-02],\n",
              "              [ 2.6310e-02,  3.1551e-02, -9.6772e-04]],\n",
              "    \n",
              "             [[-5.1653e-04, -7.7463e-02, -8.1817e-02],\n",
              "              [ 7.6833e-03,  4.9178e-02, -4.0695e-02],\n",
              "              [-8.6417e-03,  4.3130e-02,  3.2045e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[-4.2733e-03, -1.5768e-02, -2.3065e-02],\n",
              "              [-8.8184e-03, -1.3265e-02, -1.5328e-02],\n",
              "              [-1.0369e-02, -1.2945e-02, -1.6703e-02]],\n",
              "    \n",
              "             [[-4.3356e-02, -3.7069e-02, -3.6881e-02],\n",
              "              [-5.1207e-02, -6.6425e-02, -4.0735e-02],\n",
              "              [-4.0914e-02, -7.7526e-02, -3.4770e-02]],\n",
              "    \n",
              "             [[ 1.0562e-02,  1.9595e-02, -7.5679e-03],\n",
              "              [ 6.4622e-03,  6.7143e-03, -2.1811e-02],\n",
              "              [ 9.5811e-03, -2.8687e-03, -1.4196e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-3.8220e-02, -2.9365e-03, -1.8631e-02],\n",
              "              [-3.4480e-02, -4.3557e-02, -4.5005e-02],\n",
              "              [-3.2174e-02, -1.3582e-02,  2.1110e-02]],\n",
              "    \n",
              "             [[-2.7666e-03, -2.0507e-02, -5.3128e-02],\n",
              "              [-8.1954e-02, -1.3845e-01, -5.2847e-02],\n",
              "              [-3.8076e-02, -2.4754e-02, -4.0921e-02]],\n",
              "    \n",
              "             [[ 1.0144e-02,  1.7139e-02,  1.9810e-02],\n",
              "              [ 8.8802e-03,  7.0940e-04, -5.3716e-02],\n",
              "              [-1.1724e-02, -2.9355e-02, -1.0205e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[ 1.6492e-03, -4.2780e-03,  4.1170e-04],\n",
              "              [ 1.9284e-03, -3.0612e-03,  1.7765e-03],\n",
              "              [-4.3430e-03, -5.0437e-03, -9.2995e-04]],\n",
              "    \n",
              "             [[-2.3257e-02, -1.1217e-02, -2.0838e-02],\n",
              "              [-3.5277e-02, -2.1065e-02, -2.5542e-02],\n",
              "              [-2.8273e-02, -1.3360e-02, -3.7465e-02]],\n",
              "    \n",
              "             [[ 2.9784e-04,  1.7427e-03,  4.4066e-03],\n",
              "              [ 1.0064e-02,  4.0722e-03,  5.9347e-03],\n",
              "              [ 1.1126e-02, -1.2245e-03,  3.3319e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-3.8474e-02, -4.5434e-02, -1.3780e-02],\n",
              "              [-6.2539e-03, -2.7721e-02, -2.2235e-02],\n",
              "              [-2.1024e-03, -4.1387e-03, -1.1922e-02]],\n",
              "    \n",
              "             [[-1.3496e-02, -2.5459e-02, -7.3381e-03],\n",
              "              [-5.4016e-03,  4.9117e-04,  2.2232e-03],\n",
              "              [-2.6907e-02,  1.0682e-02,  5.2865e-03]],\n",
              "    \n",
              "             [[-1.2706e-03,  5.7707e-04,  1.2751e-02],\n",
              "              [-3.2486e-03, -9.0622e-03, -3.3142e-03],\n",
              "              [-6.1221e-03,  3.5420e-05, -7.0142e-03]]]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[[[0.0005, 0.0004, 0.0004],\n",
              "              [0.0004, 0.0004, 0.0004],\n",
              "              [0.0004, 0.0005, 0.0005]],\n",
              "    \n",
              "             [[0.0032, 0.0016, 0.0015],\n",
              "              [0.0032, 0.0023, 0.0013],\n",
              "              [0.0044, 0.0031, 0.0026]],\n",
              "    \n",
              "             [[0.0022, 0.0016, 0.0014],\n",
              "              [0.0024, 0.0020, 0.0015],\n",
              "              [0.0018, 0.0016, 0.0016]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0146, 0.0070, 0.0050],\n",
              "              [0.0119, 0.0093, 0.0056],\n",
              "              [0.0117, 0.0086, 0.0101]],\n",
              "    \n",
              "             [[0.0088, 0.0056, 0.0021],\n",
              "              [0.0055, 0.0021, 0.0014],\n",
              "              [0.0055, 0.0055, 0.0053]],\n",
              "    \n",
              "             [[0.0060, 0.0047, 0.0021],\n",
              "              [0.0050, 0.0066, 0.0027],\n",
              "              [0.0034, 0.0022, 0.0032]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0013, 0.0013, 0.0018],\n",
              "              [0.0011, 0.0012, 0.0020],\n",
              "              [0.0011, 0.0012, 0.0018]],\n",
              "    \n",
              "             [[0.0067, 0.0063, 0.0111],\n",
              "              [0.0073, 0.0063, 0.0099],\n",
              "              [0.0085, 0.0071, 0.0108]],\n",
              "    \n",
              "             [[0.0034, 0.0039, 0.0037],\n",
              "              [0.0032, 0.0027, 0.0027],\n",
              "              [0.0035, 0.0026, 0.0026]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0100, 0.0134, 0.0136],\n",
              "              [0.0095, 0.0121, 0.0123],\n",
              "              [0.0130, 0.0138, 0.0159]],\n",
              "    \n",
              "             [[0.0054, 0.0029, 0.0045],\n",
              "              [0.0027, 0.0040, 0.0061],\n",
              "              [0.0031, 0.0026, 0.0040]],\n",
              "    \n",
              "             [[0.0049, 0.0058, 0.0039],\n",
              "              [0.0048, 0.0040, 0.0038],\n",
              "              [0.0119, 0.0038, 0.0046]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0010, 0.0027, 0.0030],\n",
              "              [0.0012, 0.0028, 0.0022],\n",
              "              [0.0013, 0.0021, 0.0017]],\n",
              "    \n",
              "             [[0.0254, 0.0268, 0.0215],\n",
              "              [0.0278, 0.0316, 0.0227],\n",
              "              [0.0319, 0.0282, 0.0132]],\n",
              "    \n",
              "             [[0.0087, 0.0050, 0.0101],\n",
              "              [0.0073, 0.0054, 0.0072],\n",
              "              [0.0069, 0.0049, 0.0067]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0822, 0.1148, 0.0867],\n",
              "              [0.0495, 0.0425, 0.0387],\n",
              "              [0.0269, 0.0259, 0.0410]],\n",
              "    \n",
              "             [[0.0253, 0.0346, 0.0383],\n",
              "              [0.0259, 0.0313, 0.0324],\n",
              "              [0.0103, 0.0093, 0.0125]],\n",
              "    \n",
              "             [[0.0074, 0.0128, 0.0248],\n",
              "              [0.0184, 0.0270, 0.0247],\n",
              "              [0.0102, 0.0079, 0.0143]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[0.0061, 0.0052, 0.0036],\n",
              "              [0.0055, 0.0037, 0.0038],\n",
              "              [0.0056, 0.0038, 0.0036]],\n",
              "    \n",
              "             [[0.0405, 0.0424, 0.0355],\n",
              "              [0.0571, 0.0416, 0.0290],\n",
              "              [0.0810, 0.0393, 0.0194]],\n",
              "    \n",
              "             [[0.0308, 0.0225, 0.0225],\n",
              "              [0.0242, 0.0241, 0.0220],\n",
              "              [0.0261, 0.0226, 0.0178]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.1415, 0.1854, 0.0882],\n",
              "              [0.0944, 0.2719, 0.1544],\n",
              "              [0.0448, 0.0984, 0.2055]],\n",
              "    \n",
              "             [[0.0489, 0.0438, 0.0666],\n",
              "              [0.0249, 0.0344, 0.0498],\n",
              "              [0.0217, 0.0158, 0.0358]],\n",
              "    \n",
              "             [[0.0161, 0.0366, 0.0200],\n",
              "              [0.0148, 0.0592, 0.0680],\n",
              "              [0.0104, 0.0285, 0.0807]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0045, 0.0036, 0.0032],\n",
              "              [0.0043, 0.0037, 0.0031],\n",
              "              [0.0044, 0.0035, 0.0031]],\n",
              "    \n",
              "             [[0.0306, 0.0179, 0.0108],\n",
              "              [0.0403, 0.0219, 0.0116],\n",
              "              [0.0382, 0.0248, 0.0148]],\n",
              "    \n",
              "             [[0.0253, 0.0354, 0.0194],\n",
              "              [0.0292, 0.0323, 0.0203],\n",
              "              [0.0261, 0.0201, 0.0159]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0469, 0.0427, 0.0422],\n",
              "              [0.0470, 0.0542, 0.0806],\n",
              "              [0.0436, 0.0433, 0.0502]],\n",
              "    \n",
              "             [[0.0076, 0.0222, 0.0295],\n",
              "              [0.0528, 0.0645, 0.0308],\n",
              "              [0.0147, 0.0166, 0.0159]],\n",
              "    \n",
              "             [[0.0065, 0.0074, 0.0089],\n",
              "              [0.0073, 0.0109, 0.0459],\n",
              "              [0.0113, 0.0107, 0.0123]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0004, 0.0005, 0.0008],\n",
              "              [0.0004, 0.0006, 0.0007],\n",
              "              [0.0006, 0.0007, 0.0008]],\n",
              "    \n",
              "             [[0.0045, 0.0079, 0.0129],\n",
              "              [0.0026, 0.0041, 0.0094],\n",
              "              [0.0021, 0.0026, 0.0087]],\n",
              "    \n",
              "             [[0.0020, 0.0026, 0.0032],\n",
              "              [0.0027, 0.0031, 0.0035],\n",
              "              [0.0033, 0.0034, 0.0027]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0134, 0.0160, 0.0144],\n",
              "              [0.0054, 0.0091, 0.0057],\n",
              "              [0.0052, 0.0091, 0.0070]],\n",
              "    \n",
              "             [[0.0053, 0.0059, 0.0055],\n",
              "              [0.0020, 0.0023, 0.0025],\n",
              "              [0.0054, 0.0047, 0.0034]],\n",
              "    \n",
              "             [[0.0039, 0.0019, 0.0028],\n",
              "              [0.0022, 0.0016, 0.0015],\n",
              "              [0.0026, 0.0009, 0.0011]]]], dtype=torch.float64)},\n",
              "   9: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([ 5.3104e-16,  9.8080e-17,  5.5046e-16, -5.5474e-16, -1.6404e-16,\n",
              "             7.7365e-16, -7.8299e-16,  4.5923e-17,  4.2423e-16, -7.3265e-17,\n",
              "             3.2727e-16,  2.2318e-16,  6.4823e-17,  4.7975e-16, -1.8721e-16,\n",
              "            -9.8274e-17, -6.4197e-16, -4.5975e-16, -3.5872e-16,  1.3964e-16,\n",
              "             3.5336e-16,  2.0535e-16,  9.2745e-17, -4.2063e-16, -2.9274e-16,\n",
              "            -2.1474e-16, -1.1925e-16,  5.0037e-17, -1.2294e-16, -9.2061e-17,\n",
              "             3.4179e-17, -2.5830e-15, -4.8028e-16,  5.9999e-16, -1.9130e-17,\n",
              "            -9.8922e-17, -1.2952e-15,  4.9167e-16,  4.1397e-16,  1.4489e-16,\n",
              "            -2.3415e-16, -1.8574e-16, -1.0031e-15, -1.0047e-16,  2.2713e-16,\n",
              "             3.1725e-17, -1.3258e-16, -4.2661e-16, -4.5763e-18,  5.3109e-16,\n",
              "            -7.8452e-17,  8.5335e-16, -8.9546e-17, -4.3060e-16, -4.2416e-16,\n",
              "            -2.0363e-16,  5.4811e-16, -6.9882e-16, -2.1212e-16, -1.7557e-15,\n",
              "             7.2958e-17, -7.0013e-16,  4.3238e-17,  5.1583e-17],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([5.4778e-30, 8.5760e-31, 6.3870e-29, 2.9443e-29, 4.7887e-30, 7.7786e-30,\n",
              "            1.1493e-28, 2.4383e-29, 2.7545e-29, 2.5432e-30, 1.0875e-29, 8.7931e-30,\n",
              "            4.1276e-30, 2.2976e-29, 1.2805e-30, 2.8473e-30, 8.4956e-29, 1.3457e-29,\n",
              "            1.0333e-29, 1.5724e-30, 1.2765e-29, 1.0159e-29, 1.6133e-29, 1.6358e-30,\n",
              "            5.1372e-30, 4.0658e-30, 1.7298e-29, 2.8339e-29, 2.6169e-30, 2.7271e-30,\n",
              "            1.6653e-30, 5.6660e-29, 1.3701e-29, 1.0596e-28, 2.6961e-30, 1.1487e-30,\n",
              "            1.2705e-29, 4.3187e-30, 6.1111e-29, 2.5374e-30, 9.3499e-30, 4.3587e-30,\n",
              "            1.5721e-29, 2.4246e-30, 6.9800e-29, 2.0171e-29, 1.5797e-29, 1.6351e-29,\n",
              "            8.1897e-30, 2.9031e-29, 8.6296e-30, 8.3358e-30, 1.8609e-29, 3.1197e-29,\n",
              "            3.2682e-29, 2.5337e-29, 2.3842e-29, 3.7187e-29, 2.0506e-30, 5.3001e-29,\n",
              "            7.4483e-30, 3.0703e-29, 1.2186e-29, 7.7903e-30], dtype=torch.float64)},\n",
              "   10: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.0326, -0.0019, -0.0036, -0.0958,  0.0083,  0.0418, -0.1115, -0.0339,\n",
              "            -0.0346, -0.0330,  0.0474, -0.0865, -0.0591,  0.0034,  0.0194,  0.0152,\n",
              "            -0.1478,  0.0578,  0.0223,  0.0401, -0.0016,  0.0505,  0.0110, -0.0334,\n",
              "            -0.0641, -0.0294, -0.0547, -0.0462, -0.0239,  0.0084,  0.0578,  0.0630,\n",
              "             0.0272,  0.0104,  0.1034,  0.0082,  0.1486, -0.0401, -0.0429, -0.0657,\n",
              "            -0.1011,  0.1074, -0.0887,  0.1553,  0.0650,  0.0671, -0.0198,  0.0928,\n",
              "            -0.0363, -0.0365,  0.0679,  0.0171, -0.0840, -0.0015,  0.0416,  0.0765,\n",
              "             0.0376,  0.0280,  0.0269, -0.1235, -0.0523, -0.0087, -0.0527, -0.0229],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.0260, 0.0679, 0.1010, 0.0624, 0.0784, 0.1443, 0.2042, 0.0839, 0.1066,\n",
              "            0.0347, 0.0474, 0.0783, 0.1108, 0.0663, 0.0278, 0.0300, 0.2592, 0.1634,\n",
              "            0.1222, 0.0177, 0.1065, 0.0487, 0.0311, 0.0352, 0.0419, 0.0300, 0.0530,\n",
              "            0.4262, 0.0246, 0.0360, 0.0297, 0.0974, 0.0604, 0.1031, 0.1822, 0.0253,\n",
              "            0.0478, 0.0943, 0.0800, 0.0451, 0.4422, 0.0381, 0.1077, 0.0773, 0.0689,\n",
              "            0.0780, 0.0967, 0.0923, 0.0499, 0.0727, 0.0843, 0.0459, 0.0408, 0.0998,\n",
              "            0.1859, 0.0713, 0.0428, 0.0437, 0.0293, 0.0687, 0.0314, 0.0978, 0.1017,\n",
              "            0.0779], dtype=torch.float64)},\n",
              "   11: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-0.0183,  0.0878, -0.1230,  0.0828,  0.0320, -0.0234, -0.0491,  0.0524,\n",
              "             0.0549,  0.0036,  0.0555, -0.0271, -0.1314,  0.0844,  0.0296, -0.0683,\n",
              "             0.0125,  0.1845,  0.0264,  0.0352, -0.0361, -0.0085,  0.0047, -0.0386,\n",
              "             0.0013, -0.0553, -0.1858,  0.0358, -0.0673,  0.0006,  0.0919,  0.1158,\n",
              "            -0.0504,  0.0548, -0.0463,  0.0233,  0.1562, -0.0163,  0.0114, -0.0495,\n",
              "             0.0586,  0.0956, -0.1360,  0.1429,  0.0552, -0.0773, -0.0035,  0.0462,\n",
              "            -0.0835, -0.1159,  0.1115,  0.0509, -0.0940, -0.0471,  0.1124,  0.0287,\n",
              "            -0.0962, -0.0320,  0.0483, -0.0285, -0.0509, -0.0379,  0.0051,  0.0037],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.0724, 0.2200, 0.1124, 0.0868, 0.3963, 0.3905, 0.0803, 0.1477, 0.0993,\n",
              "            0.2471, 0.1761, 0.0405, 0.4376, 0.1247, 0.0864, 0.0711, 0.1036, 1.1506,\n",
              "            0.3523, 0.0440, 0.4697, 0.1988, 0.0601, 0.1069, 0.0618, 0.1072, 0.1411,\n",
              "            0.1211, 0.0864, 0.1680, 0.0690, 0.1789, 0.0934, 0.1061, 0.0772, 0.1378,\n",
              "            0.1550, 0.0462, 0.1122, 0.2084, 0.4119, 0.1672, 0.2577, 0.2427, 0.0688,\n",
              "            0.0471, 0.0517, 0.1100, 0.0573, 0.2023, 0.1226, 0.0766, 0.0360, 0.0769,\n",
              "            0.9070, 0.1567, 0.0996, 0.0937, 0.1400, 0.0368, 0.0652, 0.2911, 0.2986,\n",
              "            0.2787], dtype=torch.float64)},\n",
              "   12: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[[[ 3.6743e-03, -5.4978e-03, -6.5560e-03],\n",
              "              [ 4.9953e-04, -8.1750e-03, -5.8763e-03],\n",
              "              [-2.2201e-03,  7.0175e-03, -6.9665e-03]],\n",
              "    \n",
              "             [[-5.0025e-03, -9.8512e-03, -5.2999e-03],\n",
              "              [-7.8392e-03, -1.1075e-02, -6.9421e-03],\n",
              "              [-4.9394e-04, -2.0008e-02,  3.1742e-03]],\n",
              "    \n",
              "             [[ 1.9922e-02,  5.7510e-03, -1.3181e-02],\n",
              "              [-1.2663e-02,  5.2740e-03,  2.2452e-02],\n",
              "              [ 4.8503e-03,  9.8656e-03,  9.4961e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 1.5448e-02,  1.6290e-02,  9.4531e-03],\n",
              "              [ 3.5904e-03,  7.5024e-03,  4.5288e-02],\n",
              "              [ 8.6851e-03,  1.7896e-03,  9.8009e-03]],\n",
              "    \n",
              "             [[ 4.6634e-03, -2.7496e-03, -4.0937e-03],\n",
              "              [ 4.9160e-03, -7.5674e-03,  4.2713e-03],\n",
              "              [ 1.2428e-02, -3.2967e-03, -9.2473e-03]],\n",
              "    \n",
              "             [[ 9.9688e-03,  3.6239e-03,  3.2491e-03],\n",
              "              [ 1.4368e-02,  3.2409e-03, -1.6024e-03],\n",
              "              [ 8.6284e-03,  7.0840e-03,  1.8776e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[ 3.8332e-03, -4.4076e-03, -1.1540e-02],\n",
              "              [ 3.0130e-03,  4.8559e-03, -3.6621e-03],\n",
              "              [ 4.0048e-03, -1.2760e-03,  4.8697e-03]],\n",
              "    \n",
              "             [[ 5.8799e-04,  2.7333e-02,  2.2559e-02],\n",
              "              [ 1.1492e-02,  1.5717e-02,  1.1083e-02],\n",
              "              [-1.2094e-02, -7.2938e-03, -2.4404e-02]],\n",
              "    \n",
              "             [[-1.5605e-03, -6.5175e-02, -5.3981e-02],\n",
              "              [-4.6790e-02, -8.6057e-02, -6.8302e-02],\n",
              "              [-2.2478e-02, -1.5944e-02, -1.7392e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-2.9212e-02, -2.5949e-02, -5.2220e-02],\n",
              "              [-4.2027e-02, -2.9299e-02, -9.2795e-02],\n",
              "              [-1.0268e-02, -2.0562e-02, -8.2448e-02]],\n",
              "    \n",
              "             [[-2.7594e-02, -2.2519e-02, -4.2629e-03],\n",
              "              [-4.1645e-02, -2.3848e-02, -1.3393e-02],\n",
              "              [-4.0073e-02, -2.7376e-02,  2.1798e-02]],\n",
              "    \n",
              "             [[-2.7441e-02, -1.0682e-02,  5.7944e-03],\n",
              "              [-2.1904e-02, -1.7267e-02,  1.7466e-02],\n",
              "              [-3.2038e-02, -1.0574e-02, -3.2687e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[ 4.3352e-03,  3.2657e-03, -5.3311e-03],\n",
              "              [ 2.8986e-03,  4.7130e-03, -6.8525e-04],\n",
              "              [-9.9588e-04,  6.5508e-03,  2.2206e-03]],\n",
              "    \n",
              "             [[-6.0851e-03, -1.2781e-02, -8.2519e-04],\n",
              "              [-5.3898e-03, -1.5732e-02,  9.6967e-03],\n",
              "              [ 2.6793e-03, -1.3655e-02,  2.9852e-03]],\n",
              "    \n",
              "             [[ 1.8636e-03,  1.2542e-02,  5.9185e-04],\n",
              "              [-1.3517e-02, -1.2274e-02, -1.9818e-02],\n",
              "              [ 6.2624e-03,  2.3369e-03, -2.1360e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-1.2932e-02, -4.4503e-04, -8.3871e-03],\n",
              "              [-6.2081e-03, -5.3945e-03, -2.2424e-02],\n",
              "              [-1.0133e-02,  1.2597e-03,  4.9238e-03]],\n",
              "    \n",
              "             [[-1.0217e-02, -9.6704e-03,  4.5810e-03],\n",
              "              [-1.3324e-02, -1.4708e-03, -3.5326e-04],\n",
              "              [-3.4440e-04, -9.8090e-03,  2.1038e-03]],\n",
              "    \n",
              "             [[-9.6453e-04,  1.2893e-03,  2.4242e-03],\n",
              "              [-1.3904e-03,  6.4286e-03,  2.7724e-03],\n",
              "              [ 6.3953e-03,  6.9295e-03,  7.1865e-04]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[ 6.8875e-03,  9.6688e-03,  3.7196e-03],\n",
              "              [ 3.2914e-03,  5.2861e-04,  2.5237e-03],\n",
              "              [ 3.8595e-03,  1.9892e-03,  1.3474e-03]],\n",
              "    \n",
              "             [[-1.0624e-02, -2.1529e-03,  1.4219e-03],\n",
              "              [-8.5201e-03, -1.0336e-02, -6.6707e-03],\n",
              "              [-1.0618e-02, -5.6928e-03, -7.3511e-03]],\n",
              "    \n",
              "             [[ 1.2618e-02,  1.2164e-02,  1.0828e-02],\n",
              "              [ 8.5567e-03,  2.2574e-02,  7.5714e-03],\n",
              "              [ 1.2520e-02,  4.5878e-03,  3.8773e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 5.3613e-03, -8.0612e-03, -8.2457e-04],\n",
              "              [-4.3746e-03, -1.0684e-02,  5.7252e-03],\n",
              "              [ 9.6617e-03,  2.9109e-03, -2.7362e-03]],\n",
              "    \n",
              "             [[-2.5723e-04,  3.7198e-04, -9.8207e-03],\n",
              "              [-1.2540e-03, -8.1295e-03, -3.4183e-03],\n",
              "              [ 4.0663e-03, -1.1952e-03, -3.2706e-03]],\n",
              "    \n",
              "             [[ 3.0698e-03, -4.4923e-04, -5.7777e-03],\n",
              "              [ 7.2555e-04,  1.0112e-02,  1.0202e-02],\n",
              "              [ 1.0817e-02,  1.2043e-02,  5.3939e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[-6.6688e-03,  8.8748e-03,  2.9874e-03],\n",
              "              [-6.6935e-03,  1.3552e-02,  4.8746e-04],\n",
              "              [ 5.9271e-03,  2.1666e-03,  2.4743e-03]],\n",
              "    \n",
              "             [[-1.4651e-02,  4.4651e-03,  1.0325e-02],\n",
              "              [-1.2410e-02, -2.1527e-03,  2.9746e-03],\n",
              "              [-1.7832e-02, -1.0104e-02, -7.9844e-04]],\n",
              "    \n",
              "             [[-2.6092e-03,  9.9916e-03, -2.2972e-02],\n",
              "              [-6.4017e-03,  2.0461e-02, -4.5094e-04],\n",
              "              [-1.8770e-02, -1.7005e-02, -1.9749e-02]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 2.0266e-03, -1.1125e-02, -2.2942e-02],\n",
              "              [-7.1676e-03, -1.2383e-02,  2.0898e-02],\n",
              "              [ 1.9552e-04, -1.6863e-03, -1.5771e-02]],\n",
              "    \n",
              "             [[-1.1013e-02, -6.5907e-04, -3.2866e-04],\n",
              "              [ 1.3889e-02,  7.6472e-03,  9.1384e-03],\n",
              "              [ 1.0185e-02, -1.7601e-03, -1.9178e-02]],\n",
              "    \n",
              "             [[-6.3983e-03,  3.7724e-03, -8.2922e-03],\n",
              "              [ 1.9413e-03,  7.9708e-04, -5.6783e-04],\n",
              "              [ 7.6881e-03,  5.0743e-03, -1.2317e-02]]],\n",
              "    \n",
              "    \n",
              "            [[[ 4.7812e-03,  4.2669e-03,  7.0385e-04],\n",
              "              [ 1.4481e-03, -1.2235e-03, -4.0382e-03],\n",
              "              [ 1.4558e-03, -1.2961e-03, -2.3875e-03]],\n",
              "    \n",
              "             [[-4.3592e-03,  2.7406e-03,  1.0088e-02],\n",
              "              [ 1.7553e-03,  1.3612e-03,  2.2828e-02],\n",
              "              [-5.8346e-03,  3.7866e-03,  1.0474e-02]],\n",
              "    \n",
              "             [[ 1.7025e-02,  1.0736e-02,  6.7195e-03],\n",
              "              [ 9.1188e-03, -4.9487e-03, -9.3049e-03],\n",
              "              [-5.7845e-03,  5.8695e-03, -5.2273e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 4.9867e-03,  1.6647e-02,  1.0797e-02],\n",
              "              [-1.3036e-03,  1.3095e-02,  3.9478e-04],\n",
              "              [ 5.5157e-03, -2.4985e-03,  5.0802e-03]],\n",
              "    \n",
              "             [[ 5.5740e-03, -2.3037e-05, -8.4953e-04],\n",
              "              [-1.1094e-02, -3.0151e-03, -5.7431e-03],\n",
              "              [-6.7295e-03, -3.2342e-03, -4.5123e-03]],\n",
              "    \n",
              "             [[ 3.8684e-03,  1.8610e-03,  4.4508e-03],\n",
              "              [-2.9083e-03, -7.8635e-04,  9.9023e-04],\n",
              "              [-4.1554e-03,  2.0428e-03,  2.7752e-03]]]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[[[0.0004, 0.0007, 0.0008],\n",
              "              [0.0005, 0.0004, 0.0007],\n",
              "              [0.0006, 0.0004, 0.0007]],\n",
              "    \n",
              "             [[0.0028, 0.0036, 0.0022],\n",
              "              [0.0022, 0.0034, 0.0033],\n",
              "              [0.0018, 0.0025, 0.0031]],\n",
              "    \n",
              "             [[0.0016, 0.0014, 0.0014],\n",
              "              [0.0028, 0.0035, 0.0030],\n",
              "              [0.0022, 0.0036, 0.0025]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0030, 0.0045, 0.0021],\n",
              "              [0.0024, 0.0061, 0.0025],\n",
              "              [0.0027, 0.0043, 0.0024]],\n",
              "    \n",
              "             [[0.0011, 0.0017, 0.0016],\n",
              "              [0.0008, 0.0015, 0.0010],\n",
              "              [0.0010, 0.0012, 0.0009]],\n",
              "    \n",
              "             [[0.0006, 0.0005, 0.0007],\n",
              "              [0.0007, 0.0006, 0.0006],\n",
              "              [0.0013, 0.0010, 0.0008]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0023, 0.0031, 0.0033],\n",
              "              [0.0028, 0.0043, 0.0037],\n",
              "              [0.0030, 0.0033, 0.0033]],\n",
              "    \n",
              "             [[0.0090, 0.0054, 0.0046],\n",
              "              [0.0088, 0.0047, 0.0040],\n",
              "              [0.0168, 0.0075, 0.0060]],\n",
              "    \n",
              "             [[0.0209, 0.0212, 0.0217],\n",
              "              [0.0110, 0.0538, 0.0314],\n",
              "              [0.0161, 0.0171, 0.0157]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0151, 0.0153, 0.0151],\n",
              "              [0.0080, 0.0289, 0.0410],\n",
              "              [0.0116, 0.0126, 0.0118]],\n",
              "    \n",
              "             [[0.0037, 0.0040, 0.0033],\n",
              "              [0.0044, 0.0077, 0.0053],\n",
              "              [0.0045, 0.0063, 0.0034]],\n",
              "    \n",
              "             [[0.0049, 0.0071, 0.0097],\n",
              "              [0.0049, 0.0041, 0.0094],\n",
              "              [0.0041, 0.0043, 0.0068]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0003, 0.0002, 0.0005],\n",
              "              [0.0003, 0.0003, 0.0004],\n",
              "              [0.0003, 0.0003, 0.0003]],\n",
              "    \n",
              "             [[0.0018, 0.0015, 0.0006],\n",
              "              [0.0022, 0.0017, 0.0007],\n",
              "              [0.0025, 0.0019, 0.0011]],\n",
              "    \n",
              "             [[0.0010, 0.0007, 0.0009],\n",
              "              [0.0006, 0.0007, 0.0014],\n",
              "              [0.0011, 0.0015, 0.0017]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0013, 0.0014, 0.0030],\n",
              "              [0.0011, 0.0016, 0.0026],\n",
              "              [0.0012, 0.0013, 0.0021]],\n",
              "    \n",
              "             [[0.0011, 0.0028, 0.0014],\n",
              "              [0.0006, 0.0014, 0.0010],\n",
              "              [0.0009, 0.0017, 0.0008]],\n",
              "    \n",
              "             [[0.0003, 0.0004, 0.0003],\n",
              "              [0.0002, 0.0003, 0.0003],\n",
              "              [0.0003, 0.0004, 0.0003]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[0.0004, 0.0003, 0.0003],\n",
              "              [0.0004, 0.0003, 0.0002],\n",
              "              [0.0003, 0.0003, 0.0002]],\n",
              "    \n",
              "             [[0.0007, 0.0007, 0.0006],\n",
              "              [0.0007, 0.0010, 0.0007],\n",
              "              [0.0007, 0.0010, 0.0009]],\n",
              "    \n",
              "             [[0.0012, 0.0013, 0.0010],\n",
              "              [0.0013, 0.0006, 0.0008],\n",
              "              [0.0013, 0.0007, 0.0007]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0009, 0.0010, 0.0007],\n",
              "              [0.0010, 0.0007, 0.0008],\n",
              "              [0.0012, 0.0007, 0.0006]],\n",
              "    \n",
              "             [[0.0006, 0.0005, 0.0007],\n",
              "              [0.0009, 0.0005, 0.0008],\n",
              "              [0.0009, 0.0005, 0.0005]],\n",
              "    \n",
              "             [[0.0008, 0.0005, 0.0005],\n",
              "              [0.0005, 0.0003, 0.0003],\n",
              "              [0.0005, 0.0004, 0.0004]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0008, 0.0011, 0.0006],\n",
              "              [0.0007, 0.0014, 0.0010],\n",
              "              [0.0007, 0.0013, 0.0017]],\n",
              "    \n",
              "             [[0.0010, 0.0017, 0.0011],\n",
              "              [0.0007, 0.0015, 0.0011],\n",
              "              [0.0008, 0.0032, 0.0012]],\n",
              "    \n",
              "             [[0.0025, 0.0034, 0.0040],\n",
              "              [0.0062, 0.0027, 0.0033],\n",
              "              [0.0059, 0.0028, 0.0035]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0039, 0.0026, 0.0035],\n",
              "              [0.0050, 0.0016, 0.0028],\n",
              "              [0.0046, 0.0016, 0.0034]],\n",
              "    \n",
              "             [[0.0007, 0.0006, 0.0014],\n",
              "              [0.0008, 0.0004, 0.0016],\n",
              "              [0.0019, 0.0005, 0.0018]],\n",
              "    \n",
              "             [[0.0008, 0.0010, 0.0013],\n",
              "              [0.0008, 0.0009, 0.0013],\n",
              "              [0.0008, 0.0006, 0.0010]]],\n",
              "    \n",
              "    \n",
              "            [[[0.0004, 0.0003, 0.0002],\n",
              "              [0.0004, 0.0004, 0.0003],\n",
              "              [0.0003, 0.0003, 0.0006]],\n",
              "    \n",
              "             [[0.0007, 0.0008, 0.0009],\n",
              "              [0.0008, 0.0007, 0.0009],\n",
              "              [0.0008, 0.0006, 0.0009]],\n",
              "    \n",
              "             [[0.0012, 0.0010, 0.0016],\n",
              "              [0.0016, 0.0012, 0.0014],\n",
              "              [0.0025, 0.0012, 0.0008]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[0.0010, 0.0017, 0.0011],\n",
              "              [0.0015, 0.0023, 0.0007],\n",
              "              [0.0016, 0.0014, 0.0006]],\n",
              "    \n",
              "             [[0.0006, 0.0005, 0.0006],\n",
              "              [0.0010, 0.0006, 0.0004],\n",
              "              [0.0005, 0.0004, 0.0003]],\n",
              "    \n",
              "             [[0.0007, 0.0010, 0.0007],\n",
              "              [0.0003, 0.0005, 0.0004],\n",
              "              [0.0006, 0.0004, 0.0004]]]], dtype=torch.float64)},\n",
              "   13: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-9.7834e-17, -2.7589e-16,  3.7434e-17, -1.1276e-17, -3.0400e-17,\n",
              "             5.6713e-17,  2.4203e-17,  4.2523e-17, -4.2764e-17,  2.3903e-16,\n",
              "            -3.9048e-16, -1.9859e-17,  1.8200e-16, -9.4773e-18,  1.7847e-17,\n",
              "             4.9081e-17, -1.7300e-16, -1.5354e-17, -1.6292e-17, -5.0557e-17,\n",
              "             1.8690e-16, -2.3386e-17,  1.3553e-17,  6.8539e-16,  1.3435e-16,\n",
              "             8.7939e-17, -8.3928e-17, -1.1661e-16, -1.3105e-17,  9.3218e-17,\n",
              "             1.5366e-17, -8.6837e-17, -8.5139e-17, -1.3494e-17,  6.7550e-17,\n",
              "            -1.0530e-16, -6.9034e-18,  1.3510e-17, -1.8962e-17,  1.4766e-16,\n",
              "             1.6603e-17, -6.0258e-17,  5.9394e-17, -1.2154e-17,  1.4126e-17,\n",
              "             9.8250e-17, -8.8517e-17,  7.3780e-17,  4.1366e-17,  1.4575e-17,\n",
              "            -2.0872e-17, -9.0315e-17,  7.9269e-18,  6.5737e-17,  3.2185e-16,\n",
              "             8.6529e-17,  2.0423e-16,  4.0831e-17,  9.0099e-17,  7.8264e-17,\n",
              "            -7.8116e-17,  2.7406e-18,  3.0455e-16,  4.6729e-17, -8.7869e-17,\n",
              "             2.8405e-17, -1.9091e-17, -3.4936e-17, -1.0265e-16,  1.2343e-16,\n",
              "             3.2216e-17, -2.1667e-17,  3.1035e-16,  4.9148e-17, -5.8112e-17,\n",
              "             9.3267e-18, -8.3621e-17,  2.6082e-16, -9.7198e-17,  1.5347e-16,\n",
              "             2.2394e-17,  7.5583e-17, -2.9912e-18, -2.9718e-17, -1.3751e-16,\n",
              "             2.6572e-17,  4.5668e-16,  9.9405e-17, -7.3320e-17, -1.9855e-17,\n",
              "             6.0421e-17,  3.2432e-17,  1.8962e-17, -5.7090e-17, -5.3180e-16,\n",
              "             4.3964e-18,  3.1151e-16,  1.2070e-17, -1.6771e-16, -9.2391e-17,\n",
              "            -5.5618e-17, -5.0928e-17, -9.1175e-17,  6.7940e-17,  2.4429e-16,\n",
              "             1.0641e-17,  1.5258e-16, -8.9799e-17,  1.9544e-17, -1.1234e-17,\n",
              "            -6.4390e-18,  6.6900e-17, -1.9668e-16, -4.0571e-16, -9.6271e-17,\n",
              "             5.7325e-17,  1.6907e-16,  2.9133e-18, -2.7781e-17,  1.7872e-17,\n",
              "             1.4336e-17, -6.3434e-20, -7.7780e-17, -5.1454e-17, -6.0953e-17,\n",
              "            -5.8847e-17, -1.4229e-16, -2.8807e-17], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([2.4145e-30, 2.7078e-30, 9.0817e-31, 1.4358e-30, 9.0696e-32, 8.6768e-32,\n",
              "            4.7618e-31, 2.6507e-31, 1.1834e-30, 5.0153e-31, 2.1124e-30, 9.2481e-31,\n",
              "            4.5836e-31, 1.0854e-31, 2.4309e-30, 3.0262e-31, 8.8499e-31, 1.7193e-31,\n",
              "            1.4561e-31, 1.2505e-30, 2.7592e-30, 3.5598e-32, 4.8152e-32, 1.1929e-29,\n",
              "            1.3634e-31, 1.4348e-30, 1.7760e-31, 1.1282e-31, 1.6180e-31, 4.0299e-32,\n",
              "            1.4426e-31, 1.3931e-30, 3.2557e-31, 3.8474e-30, 1.4241e-30, 1.1303e-30,\n",
              "            4.0916e-32, 9.6993e-32, 6.2750e-32, 1.2464e-30, 7.6867e-31, 5.4165e-31,\n",
              "            9.6166e-32, 7.4009e-31, 1.7149e-30, 1.0932e-31, 2.3682e-31, 2.4095e-31,\n",
              "            5.6133e-31, 3.9239e-32, 1.1167e-31, 1.8403e-31, 6.0742e-31, 2.5676e-31,\n",
              "            1.8126e-30, 2.1407e-30, 1.7169e-30, 4.7487e-31, 5.2087e-32, 1.9307e-31,\n",
              "            8.4665e-31, 6.7041e-32, 3.2459e-30, 1.2281e-30, 4.2225e-32, 3.0049e-32,\n",
              "            3.0426e-31, 9.6404e-32, 5.0658e-31, 2.4378e-30, 4.3795e-32, 1.8397e-31,\n",
              "            1.0591e-30, 2.2558e-31, 1.5621e-30, 2.7743e-32, 5.5214e-31, 1.6807e-31,\n",
              "            5.2204e-31, 3.5113e-31, 1.0257e-30, 1.5201e-31, 5.2796e-32, 7.4849e-31,\n",
              "            3.5424e-31, 5.0848e-31, 9.9177e-31, 4.9547e-31, 9.4395e-32, 3.9912e-31,\n",
              "            2.7277e-31, 2.7028e-31, 5.6205e-31, 2.0763e-31, 6.1328e-30, 1.2924e-32,\n",
              "            4.1992e-31, 1.8528e-31, 4.3041e-31, 6.3910e-31, 2.1580e-31, 1.7094e-32,\n",
              "            2.8691e-31, 1.8910e-31, 1.2840e-30, 3.1399e-32, 4.1414e-31, 1.7296e-31,\n",
              "            2.2508e-31, 8.0218e-31, 5.5620e-32, 1.1550e-31, 4.8471e-31, 6.9968e-30,\n",
              "            7.5365e-31, 4.5284e-32, 5.1373e-31, 5.3356e-32, 2.6243e-31, 1.5752e-31,\n",
              "            6.3908e-31, 9.6471e-31, 1.7048e-31, 5.0420e-30, 2.2608e-31, 2.3524e-31,\n",
              "            2.7783e-31, 3.0045e-32], dtype=torch.float64)},\n",
              "   14: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([ 0.0576,  0.0482, -0.0007, -0.0920, -0.0234,  0.0215,  0.0202,  0.0070,\n",
              "            -0.0997, -0.0046,  0.0942, -0.0520,  0.0295, -0.0270, -0.0381,  0.0337,\n",
              "            -0.0531,  0.0418, -0.0705,  0.1001,  0.0249, -0.0180, -0.0090, -0.0444,\n",
              "            -0.0700, -0.0746,  0.0149,  0.0120,  0.0405,  0.0072,  0.0227,  0.0284,\n",
              "             0.0047, -0.0045, -0.0102, -0.0456,  0.0683, -0.0716, -0.0015,  0.0583,\n",
              "             0.0920,  0.0216, -0.0551,  0.0046,  0.0229,  0.0130,  0.0570,  0.0019,\n",
              "             0.0425, -0.0134, -0.0263,  0.0114, -0.0265,  0.0082, -0.1067,  0.0649,\n",
              "             0.0429,  0.0188, -0.0179, -0.0068, -0.0178, -0.0172,  0.0201, -0.1274,\n",
              "             0.0061,  0.0040,  0.0483, -0.0258, -0.0405, -0.1132,  0.0272, -0.0327,\n",
              "             0.0200,  0.0764,  0.0711, -0.0482,  0.0094, -0.0002,  0.0665,  0.0482,\n",
              "             0.0753, -0.0073, -0.0557,  0.0255,  0.0341,  0.0137, -0.0723, -0.0225,\n",
              "            -0.0426,  0.0334,  0.0101,  0.0425, -0.0099, -0.0414, -0.0083,  0.0039,\n",
              "            -0.0337, -0.0471, -0.0416,  0.0407, -0.0043,  0.0132,  0.0526, -0.0434,\n",
              "             0.0003, -0.0780, -0.0070, -0.0168, -0.0470,  0.0402, -0.0092,  0.0392,\n",
              "            -0.0353,  0.0324,  0.0100,  0.0083,  0.0350, -0.0248, -0.0367,  0.0010,\n",
              "             0.0029, -0.0855,  0.0181, -0.0709,  0.0498, -0.0409, -0.0055, -0.0037],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.1517, 0.1354, 0.0168, 0.2093, 0.0070, 0.0052, 0.0242, 0.0176, 0.0818,\n",
              "            0.0140, 0.0487, 0.0731, 0.0139, 0.0856, 0.0871, 0.0129, 0.1556, 0.0198,\n",
              "            0.1313, 0.0646, 0.0494, 0.0145, 0.0326, 0.1518, 0.0691, 0.0482, 0.0053,\n",
              "            0.0102, 0.0149, 0.0723, 0.0295, 0.0312, 0.0143, 0.0670, 0.0670, 0.0377,\n",
              "            0.0288, 0.0567, 0.0446, 0.0172, 0.0418, 0.0165, 0.0941, 0.0105, 0.0357,\n",
              "            0.0075, 0.0172, 0.0065, 0.0216, 0.0045, 0.0092, 0.0164, 0.0453, 0.0185,\n",
              "            0.2586, 0.0740, 0.3402, 0.0156, 0.0183, 0.0368, 0.0575, 0.0215, 0.0809,\n",
              "            0.0538, 0.0021, 0.0190, 0.0264, 0.0098, 0.0212, 0.1341, 0.0093, 0.0127,\n",
              "            0.0079, 0.0882, 0.0893, 0.0218, 0.0176, 0.0143, 0.0368, 0.0112, 0.0338,\n",
              "            0.0412, 0.0338, 0.0165, 0.0659, 0.0317, 0.0488, 0.0195, 0.0715, 0.0113,\n",
              "            0.0090, 0.0373, 0.0199, 0.1103, 0.0606, 0.0087, 0.0073, 0.0711, 0.0568,\n",
              "            0.0630, 0.0097, 0.0077, 0.0166, 0.0831, 0.0273, 0.1127, 0.0109, 0.0080,\n",
              "            0.0066, 0.0262, 0.0108, 0.0190, 0.0705, 0.0772, 0.0289, 0.0269, 0.0441,\n",
              "            0.0029, 0.0132, 0.0086, 0.0350, 0.0337, 0.0097, 0.1537, 0.0241, 0.0150,\n",
              "            0.0079, 0.0065], dtype=torch.float64)},\n",
              "   15: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([ 0.0093,  0.0040,  0.0162, -0.0279, -0.0073,  0.0364,  0.0085, -0.0014,\n",
              "            -0.0485,  0.0043,  0.0624, -0.0006,  0.0513,  0.0227, -0.0201,  0.0510,\n",
              "             0.0080,  0.0159,  0.0354,  0.0060, -0.0402, -0.0067,  0.0099, -0.0492,\n",
              "            -0.0957, -0.0587, -0.0060, -0.0046,  0.0117,  0.0012,  0.0276,  0.0086,\n",
              "             0.0237, -0.0013,  0.0188, -0.0098, -0.0071, -0.0500, -0.0222,  0.0148,\n",
              "             0.0282, -0.0129,  0.0339, -0.0252,  0.0240,  0.0248,  0.0034,  0.0040,\n",
              "            -0.0022, -0.0078,  0.0137,  0.0239, -0.0493,  0.0030, -0.0292, -0.0132,\n",
              "            -0.0146, -0.0045, -0.0319,  0.0012,  0.0492, -0.0138,  0.0606, -0.0507,\n",
              "             0.0254,  0.0036, -0.0021, -0.0341,  0.0672, -0.0108, -0.0098,  0.0146,\n",
              "             0.0200,  0.0289, -0.0135,  0.0146, -0.0005, -0.0006,  0.0354,  0.0828,\n",
              "             0.0482, -0.0039, -0.0495, -0.0012,  0.0618, -0.0011, -0.0162, -0.0130,\n",
              "            -0.0178,  0.0244,  0.0158,  0.0213,  0.0022, -0.0055, -0.0091, -0.0309,\n",
              "             0.0226, -0.0112, -0.0112,  0.0160,  0.0328, -0.0115,  0.0434,  0.0129,\n",
              "             0.0287,  0.0088,  0.0088, -0.0119, -0.0210,  0.0405,  0.0060,  0.0330,\n",
              "            -0.0442, -0.0202,  0.0016,  0.0204,  0.0774, -0.0410, -0.0091,  0.0172,\n",
              "             0.0178, -0.0618,  0.0506, -0.0331,  0.0247, -0.0257,  0.0103, -0.0096],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.0286, 0.0927, 0.0153, 0.0278, 0.0059, 0.0149, 0.0124, 0.0113, 0.0098,\n",
              "            0.0047, 0.0138, 0.0156, 0.0115, 0.0215, 0.0087, 0.0522, 0.0209, 0.0091,\n",
              "            0.0191, 0.0193, 0.0187, 0.0124, 0.0109, 0.0628, 0.0971, 0.0658, 0.0042,\n",
              "            0.0299, 0.0061, 0.0151, 0.0212, 0.0086, 0.0535, 0.0302, 0.0213, 0.0153,\n",
              "            0.0104, 0.0483, 0.0114, 0.0106, 0.0084, 0.0108, 0.0214, 0.0040, 0.0130,\n",
              "            0.0082, 0.0065, 0.0236, 0.0113, 0.0048, 0.0201, 0.0392, 0.0177, 0.0072,\n",
              "            0.0170, 0.0062, 0.0498, 0.0036, 0.0080, 0.0119, 0.0313, 0.0305, 0.0427,\n",
              "            0.0171, 0.0054, 0.0112, 0.0101, 0.0258, 0.0153, 0.0173, 0.0064, 0.0132,\n",
              "            0.0043, 0.0167, 0.0073, 0.0138, 0.0165, 0.0029, 0.0262, 0.0153, 0.0177,\n",
              "            0.0278, 0.0236, 0.0070, 0.0574, 0.0537, 0.0083, 0.0058, 0.0103, 0.0128,\n",
              "            0.0250, 0.0087, 0.0106, 0.0185, 0.0153, 0.0117, 0.0029, 0.0138, 0.0146,\n",
              "            0.0542, 0.0259, 0.0038, 0.0300, 0.0453, 0.0133, 0.0259, 0.0091, 0.0153,\n",
              "            0.0113, 0.0400, 0.0102, 0.0136, 0.0227, 0.0115, 0.0149, 0.0143, 0.0669,\n",
              "            0.0082, 0.0058, 0.0206, 0.0291, 0.0104, 0.0238, 0.0345, 0.0063, 0.0102,\n",
              "            0.0066, 0.0065], dtype=torch.float64)},\n",
              "   16: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[[[-1.4826e-02,  2.1081e-03, -1.1759e-03],\n",
              "              [ 1.2219e-02,  5.4789e-03,  1.1853e-02],\n",
              "              [ 6.2257e-03,  2.8894e-03,  1.0929e-02]],\n",
              "    \n",
              "             [[-2.9246e-03, -1.5528e-02,  4.9669e-03],\n",
              "              [ 1.6846e-03, -8.8560e-03,  1.8925e-02],\n",
              "              [ 1.3217e-02,  1.2853e-02, -2.7990e-04]],\n",
              "    \n",
              "             [[-3.7891e-03, -1.1952e-02, -3.1956e-03],\n",
              "              [ 1.0112e-02,  5.2138e-03,  1.4990e-03],\n",
              "              [ 6.9517e-04,  1.0216e-02,  1.1900e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 7.5660e-03, -5.5223e-03, -7.6616e-04],\n",
              "              [ 4.4966e-03, -1.6131e-03,  6.6688e-03],\n",
              "              [ 6.7530e-03,  4.4097e-03, -4.3594e-03]],\n",
              "    \n",
              "             [[ 3.4495e-03,  1.3892e-02,  2.3948e-03],\n",
              "              [-4.8737e-04,  6.0245e-03, -2.1651e-03],\n",
              "              [-5.3352e-03,  1.0639e-02, -4.9013e-03]],\n",
              "    \n",
              "             [[-1.0614e-03, -5.4461e-03, -2.2419e-03],\n",
              "              [ 1.2341e-03,  3.2803e-03,  2.7209e-03],\n",
              "              [ 8.2764e-03,  3.0928e-03,  3.3453e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[ 1.5493e-02,  6.0162e-03, -1.8171e-03],\n",
              "              [ 5.0860e-04, -3.9440e-04, -5.4162e-03],\n",
              "              [ 2.5040e-03,  1.7941e-03, -8.6350e-03]],\n",
              "    \n",
              "             [[ 4.5014e-03, -1.0224e-02,  5.4186e-03],\n",
              "              [-4.2099e-03, -9.5590e-04, -4.3243e-03],\n",
              "              [ 4.8661e-03, -5.8121e-03, -4.8422e-03]],\n",
              "    \n",
              "             [[ 4.2280e-04,  3.7002e-03, -3.2631e-03],\n",
              "              [ 4.4141e-03, -2.6891e-03, -5.3931e-04],\n",
              "              [ 2.5831e-04, -4.3882e-03,  2.8417e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-4.2760e-03,  3.3906e-04, -8.7939e-03],\n",
              "              [-6.0511e-03, -3.4635e-03, -4.8179e-03],\n",
              "              [-3.7994e-03, -7.0736e-03, -1.2207e-03]],\n",
              "    \n",
              "             [[ 2.2097e-03,  8.3248e-04, -1.1954e-03],\n",
              "              [-6.6804e-03, -4.9712e-04, -1.4261e-03],\n",
              "              [-3.8272e-03, -3.7551e-03,  6.3304e-04]],\n",
              "    \n",
              "             [[-1.8639e-03,  6.5073e-03, -5.2916e-03],\n",
              "              [ 2.4079e-03,  2.5462e-03, -6.2380e-03],\n",
              "              [-5.6294e-03, -4.2881e-04, -3.3805e-03]]],\n",
              "    \n",
              "    \n",
              "            [[[-1.1436e-03, -1.2912e-04,  3.3993e-03],\n",
              "              [-3.3566e-03,  1.4128e-03, -3.9567e-04],\n",
              "              [ 3.0508e-03,  1.3109e-04,  2.6696e-03]],\n",
              "    \n",
              "             [[ 2.1756e-03, -1.7616e-03, -4.6185e-03],\n",
              "              [ 2.5767e-03,  2.2336e-03,  3.0351e-03],\n",
              "              [ 7.8096e-03,  7.7607e-03,  3.5969e-03]],\n",
              "    \n",
              "             [[-1.8748e-03, -3.2974e-03, -2.8183e-04],\n",
              "              [ 7.0429e-04, -4.9514e-03, -2.0494e-03],\n",
              "              [ 1.7840e-04,  1.4430e-03, -5.3101e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-8.0345e-04, -4.5379e-03, -1.4927e-03],\n",
              "              [ 2.5384e-03, -4.8420e-03, -1.0939e-03],\n",
              "              [ 7.3944e-03, -1.9369e-03, -1.9955e-03]],\n",
              "    \n",
              "             [[ 2.6314e-04, -4.9718e-04,  3.9724e-04],\n",
              "              [ 9.7424e-04, -3.4379e-03,  1.8412e-03],\n",
              "              [ 2.4947e-03, -6.7943e-04,  6.7263e-05]],\n",
              "    \n",
              "             [[-8.7729e-05,  1.5014e-03, -2.5538e-03],\n",
              "              [-1.5149e-05, -2.8559e-04, -2.9433e-03],\n",
              "              [ 2.4949e-03,  5.0621e-03, -2.3003e-03]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[ 5.6801e-03,  5.8279e-03,  1.2461e-02],\n",
              "              [ 1.4745e-03, -2.6563e-03,  7.8337e-03],\n",
              "              [ 3.8868e-03,  3.5123e-03, -1.7812e-03]],\n",
              "    \n",
              "             [[ 1.8237e-04,  6.1442e-03, -3.8060e-03],\n",
              "              [ 9.6215e-03, -5.1853e-03, -6.7340e-04],\n",
              "              [-5.1212e-03,  2.5592e-04, -8.2650e-03]],\n",
              "    \n",
              "             [[ 1.7933e-03,  6.2663e-03,  5.0302e-03],\n",
              "              [-9.7489e-04,  5.7460e-04,  6.3528e-04],\n",
              "              [ 2.9736e-05,  2.5944e-04, -1.0389e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 2.3518e-03,  7.9979e-03,  5.9107e-03],\n",
              "              [ 3.6931e-03,  7.5825e-03, -2.0433e-03],\n",
              "              [ 1.4579e-03,  2.3480e-03, -5.9657e-03]],\n",
              "    \n",
              "             [[ 9.3863e-04, -6.2300e-04,  1.1841e-04],\n",
              "              [ 3.9614e-03,  3.1246e-03, -1.5667e-03],\n",
              "              [-2.4551e-03, -3.3273e-03, -4.0848e-03]],\n",
              "    \n",
              "             [[ 2.9399e-03,  2.0262e-03,  6.1365e-04],\n",
              "              [ 6.9698e-03,  3.2676e-03, -4.2630e-03],\n",
              "              [-9.0368e-04, -4.2710e-03, -3.5113e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[ 4.9484e-03,  1.0077e-03,  2.9849e-03],\n",
              "              [-4.0763e-03, -2.8743e-03,  3.6840e-03],\n",
              "              [ 5.3443e-03, -1.7983e-03, -1.6902e-03]],\n",
              "    \n",
              "             [[-6.5348e-03, -9.2343e-03, -7.9700e-03],\n",
              "              [-1.0271e-02,  1.6837e-03,  1.4966e-03],\n",
              "              [ 1.9535e-03,  7.2667e-03,  7.8212e-03]],\n",
              "    \n",
              "             [[ 2.3376e-03,  1.1324e-03,  5.3201e-03],\n",
              "              [ 1.5325e-03,  1.3793e-03,  4.9622e-03],\n",
              "              [ 4.7788e-03,  1.7341e-03,  3.1024e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[ 5.5042e-03, -2.1409e-04, -7.3296e-04],\n",
              "              [ 2.1999e-03, -6.4275e-04,  9.8492e-04],\n",
              "              [ 4.3030e-03, -2.6586e-03,  6.3948e-03]],\n",
              "    \n",
              "             [[ 3.0542e-03,  1.9056e-03, -2.8028e-03],\n",
              "              [-2.3203e-03, -2.1419e-03,  7.4433e-03],\n",
              "              [ 1.0799e-03,  4.4658e-03,  2.7574e-03]],\n",
              "    \n",
              "             [[-1.9001e-03,  2.6634e-03, -1.5433e-03],\n",
              "              [ 1.1012e-03, -6.2157e-03, -4.8147e-03],\n",
              "              [ 1.5092e-03, -1.8986e-03,  1.3709e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[ 1.3492e-02,  2.2550e-03, -2.4367e-04],\n",
              "              [ 8.9860e-03,  6.8127e-03,  1.2904e-02],\n",
              "              [ 5.7559e-03,  1.1994e-03, -4.2065e-03]],\n",
              "    \n",
              "             [[ 9.1781e-03,  8.0675e-03, -1.3883e-03],\n",
              "              [ 6.9951e-03,  4.9924e-03,  3.1259e-03],\n",
              "              [ 6.7693e-03,  9.6532e-03, -2.4471e-03]],\n",
              "    \n",
              "             [[-1.0279e-03,  4.0171e-03, -1.8122e-03],\n",
              "              [ 4.2335e-03,  3.9782e-03,  2.2002e-03],\n",
              "              [ 5.0348e-03, -3.1190e-03, -1.2561e-03]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[-7.6314e-03,  1.5502e-03, -3.4014e-04],\n",
              "              [-6.2302e-03,  1.9344e-03, -4.3937e-03],\n",
              "              [-7.4787e-03, -3.3307e-03, -7.1730e-03]],\n",
              "    \n",
              "             [[ 2.3731e-03,  6.3219e-03,  3.0991e-03],\n",
              "              [ 4.8887e-03,  3.6595e-04,  5.2842e-04],\n",
              "              [-2.3534e-03, -8.4074e-04,  9.3751e-04]],\n",
              "    \n",
              "             [[-1.3215e-03,  8.3026e-03, -8.5759e-03],\n",
              "              [-2.0445e-03, -5.0711e-03, -3.2549e-03],\n",
              "              [ 3.7651e-03, -3.1819e-03, -3.0257e-03]]]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[[[2.3792e-03, 2.0516e-03, 1.7336e-03],\n",
              "              [2.6327e-03, 2.3383e-03, 2.0235e-03],\n",
              "              [2.6144e-03, 2.9179e-03, 2.0755e-03]],\n",
              "    \n",
              "             [[3.3969e-03, 2.5283e-03, 1.7704e-03],\n",
              "              [3.7885e-03, 2.6879e-03, 2.2171e-03],\n",
              "              [3.3043e-03, 2.8816e-03, 1.5154e-03]],\n",
              "    \n",
              "             [[8.1766e-04, 6.6646e-04, 6.3255e-04],\n",
              "              [9.5620e-04, 8.2749e-04, 9.3254e-04],\n",
              "              [1.1553e-03, 8.5309e-04, 7.2104e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[3.1878e-04, 5.0591e-04, 3.7265e-04],\n",
              "              [3.5877e-04, 4.7032e-04, 3.4644e-04],\n",
              "              [6.2373e-04, 3.2741e-04, 4.4118e-04]],\n",
              "    \n",
              "             [[4.1255e-04, 4.4167e-04, 4.2618e-04],\n",
              "              [4.2213e-04, 3.8564e-04, 3.3596e-04],\n",
              "              [4.3719e-04, 3.4133e-04, 3.3705e-04]],\n",
              "    \n",
              "             [[2.9012e-04, 3.8806e-04, 3.2892e-04],\n",
              "              [3.0865e-04, 3.7907e-04, 3.8415e-04],\n",
              "              [4.1089e-04, 3.7648e-04, 6.2655e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[2.9902e-03, 1.3721e-03, 5.4279e-04],\n",
              "              [1.2631e-03, 6.8664e-04, 2.9631e-04],\n",
              "              [7.7924e-04, 7.6102e-04, 3.9989e-04]],\n",
              "    \n",
              "             [[5.3682e-04, 6.4580e-04, 4.5451e-04],\n",
              "              [5.6192e-04, 4.7468e-04, 3.0683e-04],\n",
              "              [4.8504e-04, 3.5357e-04, 3.3929e-04]],\n",
              "    \n",
              "             [[2.9112e-04, 3.3030e-04, 2.7444e-04],\n",
              "              [2.0405e-04, 1.6188e-04, 1.6817e-04],\n",
              "              [2.0751e-04, 2.7924e-04, 2.0171e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[3.1748e-04, 1.7297e-04, 6.0181e-04],\n",
              "              [4.1032e-04, 2.4110e-04, 4.3504e-04],\n",
              "              [3.6701e-04, 2.7637e-04, 2.8545e-04]],\n",
              "    \n",
              "             [[1.8195e-04, 1.2097e-04, 1.5902e-04],\n",
              "              [1.2452e-04, 9.9091e-05, 8.5461e-05],\n",
              "              [1.2056e-04, 9.3679e-05, 1.1347e-04]],\n",
              "    \n",
              "             [[2.2864e-04, 1.4590e-04, 2.4972e-04],\n",
              "              [3.7082e-04, 1.6051e-04, 2.2112e-04],\n",
              "              [5.7007e-04, 1.8731e-04, 1.9746e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[2.1883e-04, 1.5064e-04, 1.5270e-04],\n",
              "              [1.6322e-04, 1.3474e-04, 1.6342e-04],\n",
              "              [1.8101e-04, 2.2215e-04, 3.1079e-04]],\n",
              "    \n",
              "             [[3.0265e-04, 3.7914e-04, 1.9256e-04],\n",
              "              [2.8053e-04, 1.8954e-04, 1.4490e-04],\n",
              "              [2.7186e-04, 4.2498e-04, 4.6424e-04]],\n",
              "    \n",
              "             [[7.3368e-05, 5.6986e-05, 5.4407e-05],\n",
              "              [6.4980e-05, 6.0130e-05, 1.0181e-04],\n",
              "              [8.8167e-05, 7.6085e-05, 8.8050e-05]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[7.8015e-05, 8.2124e-05, 1.8904e-04],\n",
              "              [7.0047e-05, 7.9050e-05, 2.9596e-04],\n",
              "              [9.4147e-05, 7.7275e-05, 2.6513e-04]],\n",
              "    \n",
              "             [[7.0759e-05, 7.0752e-05, 1.0034e-04],\n",
              "              [5.7246e-05, 4.9532e-05, 5.2322e-05],\n",
              "              [6.1453e-05, 7.8403e-05, 6.9826e-05]],\n",
              "    \n",
              "             [[7.2574e-05, 1.0651e-04, 9.4943e-05],\n",
              "              [7.7711e-05, 7.6656e-05, 2.2177e-04],\n",
              "              [1.3724e-04, 8.7883e-05, 1.9597e-04]]],\n",
              "    \n",
              "    \n",
              "            ...,\n",
              "    \n",
              "    \n",
              "            [[[2.3596e-04, 2.0650e-04, 1.7113e-04],\n",
              "              [2.7718e-04, 3.0608e-04, 1.6915e-04],\n",
              "              [2.9955e-04, 2.8297e-04, 2.8191e-04]],\n",
              "    \n",
              "             [[7.2112e-04, 5.7916e-04, 4.3336e-04],\n",
              "              [2.1868e-04, 2.4764e-04, 2.4818e-04],\n",
              "              [2.2838e-04, 2.3755e-04, 2.8198e-04]],\n",
              "    \n",
              "             [[6.6533e-05, 1.5659e-04, 7.1987e-05],\n",
              "              [9.1805e-05, 6.6811e-05, 6.7760e-05],\n",
              "              [1.2192e-04, 1.0888e-04, 8.4439e-05]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[1.1898e-04, 1.8185e-04, 7.3003e-05],\n",
              "              [6.8530e-05, 1.7699e-04, 7.9884e-05],\n",
              "              [7.8648e-05, 1.0200e-04, 1.2826e-04]],\n",
              "    \n",
              "             [[1.4100e-04, 8.6633e-05, 9.1539e-05],\n",
              "              [7.5101e-05, 8.4580e-05, 7.4409e-05],\n",
              "              [8.8129e-05, 8.1112e-05, 7.8104e-05]],\n",
              "    \n",
              "             [[8.7647e-05, 1.0383e-04, 1.3626e-04],\n",
              "              [7.0154e-05, 1.2206e-04, 1.1851e-04],\n",
              "              [7.6234e-05, 1.0173e-04, 1.3026e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[2.1050e-04, 2.4277e-04, 2.0669e-04],\n",
              "              [2.8235e-04, 2.1910e-04, 2.3460e-04],\n",
              "              [2.7534e-04, 2.9694e-04, 3.7391e-04]],\n",
              "    \n",
              "             [[2.6341e-04, 1.7826e-04, 2.5685e-04],\n",
              "              [2.5680e-04, 2.2867e-04, 2.9193e-04],\n",
              "              [1.7802e-04, 2.7619e-04, 3.2032e-04]],\n",
              "    \n",
              "             [[1.0643e-04, 5.8539e-05, 8.8632e-05],\n",
              "              [1.0322e-04, 5.3170e-05, 6.5783e-05],\n",
              "              [1.0014e-04, 8.0150e-05, 9.1634e-05]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[2.9479e-04, 5.7851e-05, 2.0134e-04],\n",
              "              [2.0958e-04, 6.0675e-05, 1.7680e-04],\n",
              "              [1.2597e-04, 8.7241e-05, 8.7381e-05]],\n",
              "    \n",
              "             [[1.5185e-04, 7.7801e-05, 1.0106e-04],\n",
              "              [1.1902e-04, 6.6563e-05, 2.0790e-04],\n",
              "              [7.5038e-05, 1.0303e-04, 1.3397e-04]],\n",
              "    \n",
              "             [[1.5096e-04, 7.7972e-05, 1.2609e-04],\n",
              "              [1.1311e-04, 1.2960e-04, 1.0643e-04],\n",
              "              [1.0367e-04, 1.7743e-04, 1.3439e-04]]],\n",
              "    \n",
              "    \n",
              "            [[[1.0592e-03, 7.2698e-04, 5.3785e-04],\n",
              "              [8.6758e-04, 9.6960e-04, 7.6974e-04],\n",
              "              [6.5280e-04, 6.1050e-04, 6.2188e-04]],\n",
              "    \n",
              "             [[8.4098e-04, 4.6941e-04, 6.1336e-04],\n",
              "              [1.0650e-03, 5.7035e-04, 6.1542e-04],\n",
              "              [7.4606e-04, 8.0023e-04, 5.0984e-04]],\n",
              "    \n",
              "             [[1.7187e-04, 1.4702e-04, 1.6913e-04],\n",
              "              [1.4271e-04, 1.5109e-04, 1.7239e-04],\n",
              "              [2.5388e-04, 1.6684e-04, 1.6697e-04]],\n",
              "    \n",
              "             ...,\n",
              "    \n",
              "             [[3.6475e-04, 2.8108e-04, 2.4530e-04],\n",
              "              [3.8248e-04, 3.1153e-04, 3.4995e-04],\n",
              "              [3.3137e-04, 3.0622e-04, 2.5904e-04]],\n",
              "    \n",
              "             [[1.8692e-04, 1.8284e-04, 2.6979e-04],\n",
              "              [1.9231e-04, 1.2710e-04, 1.2390e-04],\n",
              "              [1.5573e-04, 1.2906e-04, 1.1529e-04]],\n",
              "    \n",
              "             [[3.5948e-04, 2.0658e-04, 2.6894e-04],\n",
              "              [2.6700e-04, 2.3457e-04, 1.7303e-04],\n",
              "              [1.9273e-04, 1.6026e-04, 1.3020e-04]]]], dtype=torch.float64)},\n",
              "   17: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-5.1526e-19, -1.0524e-18, -3.7702e-18,  4.9668e-17, -3.0714e-19,\n",
              "            -1.1505e-16, -6.4371e-18, -2.5516e-18,  9.9000e-18, -3.6968e-17,\n",
              "            -3.1890e-18,  1.2867e-18, -1.4136e-17, -1.7527e-18,  3.0065e-18,\n",
              "            -2.7867e-18,  3.5265e-18,  8.7377e-18,  1.1059e-16, -2.8787e-18,\n",
              "             7.0346e-17, -1.4623e-17,  1.3727e-17,  4.6535e-17, -2.6647e-18,\n",
              "             8.3418e-18,  1.1603e-16,  5.0736e-18, -3.8625e-19, -6.0853e-18,\n",
              "            -2.8417e-17, -1.4822e-16, -9.3212e-18, -1.2008e-17,  3.3021e-17,\n",
              "            -1.1156e-17,  4.6409e-17,  5.8304e-17, -2.3279e-16, -2.4722e-18,\n",
              "             2.1738e-17,  5.4617e-18,  1.6277e-17, -4.8279e-17, -3.5887e-17,\n",
              "            -1.7578e-17,  6.7551e-18, -5.1436e-17, -1.0192e-17, -3.6172e-17,\n",
              "             4.2599e-18, -1.2403e-18,  2.2439e-18,  1.3405e-17, -4.3494e-18,\n",
              "             1.8056e-16,  1.5049e-18, -7.9530e-18, -1.1017e-17, -1.6075e-18,\n",
              "             1.9196e-17, -1.6282e-17,  2.2548e-18,  7.6584e-18,  3.4311e-17,\n",
              "             3.1195e-18,  1.1253e-16,  1.2239e-17, -1.0580e-16, -5.7271e-18,\n",
              "             6.3052e-18, -2.2041e-17,  1.4267e-18,  1.5476e-17, -2.3303e-18,\n",
              "             7.4290e-17, -6.2329e-18,  8.3148e-18, -4.9923e-18, -4.5537e-18,\n",
              "             1.1165e-17,  5.6364e-17, -2.4267e-17,  5.9412e-18,  2.6843e-18,\n",
              "             1.8488e-17, -3.0826e-18,  7.4156e-18, -1.4227e-17, -1.0904e-16,\n",
              "            -1.6166e-17, -2.4241e-18,  2.4129e-16,  1.0841e-16, -4.8512e-17,\n",
              "            -6.1635e-18, -1.6390e-17,  8.4984e-17, -2.0282e-18, -5.0875e-17,\n",
              "             2.4457e-18,  2.6376e-17,  1.0574e-17, -2.0071e-18, -3.0380e-17,\n",
              "             5.8435e-17, -2.5039e-17,  2.1051e-18,  2.6044e-18,  1.0391e-17,\n",
              "            -3.8335e-18,  1.9633e-18,  4.6368e-17, -3.3740e-18,  5.2905e-18,\n",
              "             2.2866e-19, -2.1393e-19, -7.7780e-17,  1.1225e-16,  3.7223e-17,\n",
              "            -1.7678e-17,  8.1809e-18, -1.3173e-18,  1.1560e-17,  5.2779e-17,\n",
              "            -4.9077e-18, -1.6709e-17, -4.4081e-18], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([1.4880e-31, 3.1507e-33, 1.3497e-33, 1.8790e-31, 3.0326e-33, 1.8866e-31,\n",
              "            1.5223e-33, 5.2429e-34, 1.0407e-33, 5.9296e-32, 1.0121e-34, 2.3088e-33,\n",
              "            5.0327e-33, 1.3796e-34, 4.1693e-34, 6.5579e-34, 2.8338e-33, 1.0528e-32,\n",
              "            1.3252e-31, 7.2666e-32, 3.6495e-32, 9.1817e-32, 1.5175e-33, 1.8869e-32,\n",
              "            9.1806e-34, 2.9909e-33, 2.4682e-31, 3.8452e-33, 1.4215e-33, 6.7051e-33,\n",
              "            1.5690e-32, 3.3572e-31, 2.9102e-33, 1.6751e-32, 9.6396e-32, 1.6259e-32,\n",
              "            1.5333e-31, 1.0106e-31, 6.6887e-31, 3.4757e-33, 1.4415e-31, 5.2761e-33,\n",
              "            5.6430e-32, 4.0187e-32, 6.5491e-32, 1.6021e-32, 7.7927e-34, 1.1803e-32,\n",
              "            2.1827e-33, 1.3007e-31, 3.6417e-34, 3.5474e-33, 8.5767e-33, 1.2700e-31,\n",
              "            2.4412e-33, 1.8199e-31, 3.4986e-32, 3.4839e-33, 1.2376e-32, 8.7746e-34,\n",
              "            3.9752e-33, 6.9005e-33, 7.7778e-33, 1.3127e-32, 1.3122e-32, 1.7848e-33,\n",
              "            1.5385e-31, 2.0393e-33, 4.5976e-31, 7.8566e-34, 1.6342e-33, 5.1791e-33,\n",
              "            1.6896e-33, 5.2727e-33, 5.0059e-34, 2.3445e-31, 4.2570e-33, 7.7600e-34,\n",
              "            9.6100e-33, 2.0938e-33, 1.7074e-31, 2.2703e-32, 1.0562e-31, 2.4778e-33,\n",
              "            8.3286e-34, 2.7014e-32, 1.7541e-32, 1.0379e-32, 3.3017e-32, 9.1799e-31,\n",
              "            1.4704e-32, 9.3492e-34, 7.7570e-31, 1.9182e-31, 3.9881e-31, 5.5836e-32,\n",
              "            4.6993e-32, 1.7983e-31, 2.4352e-33, 9.8333e-32, 2.2939e-33, 6.7363e-33,\n",
              "            2.4691e-33, 1.0096e-32, 6.0041e-32, 1.0667e-31, 3.0871e-32, 4.5806e-33,\n",
              "            7.0286e-34, 3.1977e-33, 6.0283e-34, 1.1281e-32, 1.8624e-31, 2.3723e-33,\n",
              "            1.6718e-33, 2.9873e-33, 1.0811e-33, 9.4823e-32, 7.9085e-32, 1.3442e-31,\n",
              "            2.0396e-32, 1.4937e-33, 7.5908e-32, 3.4377e-33, 2.0740e-31, 4.4678e-34,\n",
              "            1.9556e-33, 4.5490e-34], dtype=torch.float64)},\n",
              "   18: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([ 0.2137,  0.0004,  0.0088,  0.1940,  0.0357,  0.1263,  0.0284,  0.0098,\n",
              "            -0.0019,  0.0187, -0.0248,  0.0198,  0.1387, -0.0038,  0.0220,  0.0073,\n",
              "             0.0203,  0.0865,  0.2038, -0.0989,  0.1946,  0.1074,  0.0277,  0.1121,\n",
              "             0.0115,  0.0359,  0.2079,  0.0222,  0.0139,  0.0501,  0.1521,  0.2619,\n",
              "             0.0203,  0.1533,  0.2543,  0.1118,  0.1256,  0.1449,  0.2133,  0.0063,\n",
              "             0.1578,  0.0514,  0.1842,  0.2102,  0.2572,  0.2065, -0.0172,  0.0662,\n",
              "            -0.0213,  0.2099, -0.0178,  0.0683,  0.0842,  0.2925,  0.0583,  0.2433,\n",
              "             0.0494,  0.0445,  0.2594,  0.0210,  0.0251,  0.0175,  0.0367,  0.0980,\n",
              "             0.1064,  0.0108,  0.3002,  0.0938,  0.2056,  0.0097,  0.0470,  0.0312,\n",
              "             0.0101,  0.0244,  0.0067,  0.1530,  0.0190, -0.0153,  0.1503,  0.0738,\n",
              "             0.1058,  0.0560,  0.1681,  0.0155,  0.0353,  0.0269,  0.0412, -0.0109,\n",
              "             0.2002, -0.1767,  0.0340,  0.0172,  0.2075,  0.1871,  0.1164,  0.2365,\n",
              "             0.0894,  0.1466,  0.1069,  0.2053,  0.0174,  0.0433,  0.0724,  0.0020,\n",
              "             0.2039,  0.1786,  0.0501,  0.0219,  0.0097,  0.0203,  0.0179,  0.1044,\n",
              "             0.1101, -0.0077,  0.0168,  0.0616,  0.0181,  0.1844,  0.2065,  0.1655,\n",
              "             0.0587,  0.0229,  0.1245,  0.0667,  0.2821, -0.0301, -0.0090,  0.0214],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([1.8104e+00, 7.6308e-03, 8.5841e-03, 1.0071e+00, 6.8885e-02, 5.3798e-01,\n",
              "            2.5295e-02, 6.1646e-03, 5.7403e-03, 3.3409e-02, 1.7520e-03, 1.2793e-02,\n",
              "            2.2441e-01, 3.1686e-03, 3.0289e-02, 5.4847e-03, 3.8269e-02, 5.0405e-02,\n",
              "            2.0149e-01, 6.1094e-01, 3.0678e-01, 1.7559e-01, 4.0345e-02, 3.4443e-01,\n",
              "            1.5741e-02, 4.5423e-02, 1.5019e+00, 1.9472e-02, 1.0277e-02, 6.7721e-02,\n",
              "            4.2660e-01, 1.5610e+00, 2.0626e-02, 6.9875e-01, 1.9498e+00, 1.7670e-01,\n",
              "            1.0599e+00, 5.2869e-01, 1.0501e+00, 2.0601e-02, 7.8992e-01, 1.1674e-01,\n",
              "            6.9208e-01, 1.7992e+00, 1.4669e+00, 1.9492e+00, 2.1211e-02, 5.3252e-02,\n",
              "            6.5812e-03, 1.1409e+00, 2.6349e-03, 1.7058e-01, 1.4713e-01, 1.8745e+00,\n",
              "            1.5131e-01, 2.1264e+00, 7.8749e-02, 1.2527e-02, 1.8001e+00, 3.3990e-02,\n",
              "            3.0181e-02, 6.2900e-02, 7.8194e-02, 1.0359e+00, 2.4389e-01, 1.9917e-02,\n",
              "            2.7868e+00, 2.5427e-01, 1.6792e+00, 1.1685e-02, 6.5810e-02, 1.5849e-02,\n",
              "            8.8719e-03, 1.9882e-02, 5.8076e-03, 4.0147e-01, 2.5596e-02, 1.1894e-02,\n",
              "            6.3796e-01, 2.1530e-01, 3.1653e-01, 8.9517e-02, 1.7941e+00, 1.5895e-02,\n",
              "            9.2929e-02, 7.5559e-02, 7.4493e-02, 1.3761e-01, 9.8921e-01, 1.5165e+00,\n",
              "            9.6940e-02, 6.0302e-03, 4.2246e-01, 1.2282e+00, 4.8865e-01, 1.7037e+00,\n",
              "            2.0150e-01, 5.3536e-01, 1.2106e-01, 1.3424e+00, 7.1087e-03, 1.2745e-02,\n",
              "            1.1295e-02, 2.9707e-02, 9.1290e-01, 1.2663e+00, 2.8769e-02, 8.5799e-02,\n",
              "            8.4937e-03, 6.0256e-03, 3.6464e-03, 1.7885e-01, 9.9586e-02, 2.8167e-02,\n",
              "            1.7920e-02, 1.3412e-01, 1.4155e-02, 9.1631e-01, 1.4775e+00, 1.0740e+00,\n",
              "            5.6546e-02, 2.0902e-02, 6.2342e-01, 1.8119e-01, 2.3064e+00, 4.3667e-03,\n",
              "            8.8426e-03, 2.2596e-02], dtype=torch.float64)},\n",
              "   19: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([ 0.1412,  0.0172,  0.0158,  0.1569,  0.0541,  0.1224,  0.0477,  0.0195,\n",
              "             0.0210,  0.0021, -0.0313,  0.0454,  0.0879,  0.0052, -0.0066,  0.0077,\n",
              "             0.0060,  0.0702,  0.1504, -0.0522,  0.0530,  0.0935,  0.0593,  0.0608,\n",
              "             0.0294,  0.0573,  0.1106,  0.0427,  0.0333,  0.0515,  0.0808,  0.1436,\n",
              "             0.0542,  0.0932,  0.1736,  0.0947,  0.1168,  0.1000,  0.2005,  0.0271,\n",
              "             0.0813,  0.0849,  0.1076,  0.1131,  0.1398,  0.1415, -0.0157,  0.0590,\n",
              "            -0.0281,  0.1095, -0.0088,  0.0943,  0.0760,  0.1654,  0.1006,  0.1915,\n",
              "             0.0717,  0.0636,  0.1084,  0.0594,  0.0503,  0.0332,  0.0223,  0.0635,\n",
              "             0.1075,  0.0352,  0.1369,  0.0948,  0.1055,  0.0210,  0.0720, -0.0033,\n",
              "             0.0224,  0.0473,  0.0058,  0.0639,  0.0551, -0.0091,  0.0733,  0.0855,\n",
              "             0.1008,  0.0810,  0.1448,  0.0106,  0.0708,  0.0656,  0.0630, -0.0091,\n",
              "             0.1737, -0.0486,  0.0036,  0.0155,  0.1294,  0.1698,  0.1095,  0.1076,\n",
              "             0.1087,  0.0873,  0.0404,  0.1175, -0.0031,  0.0396,  0.0459,  0.0063,\n",
              "             0.1000,  0.1446,  0.0225,  0.0513,  0.0325,  0.0469,  0.0406,  0.0983,\n",
              "             0.0865, -0.0026,  0.0288,  0.0680,  0.0417,  0.0632,  0.1702,  0.0735,\n",
              "             0.0518,  0.0343,  0.1153,  0.0938,  0.1199, -0.0271,  0.0093,  0.0518],\n",
              "           dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([1.0134, 0.0075, 0.0208, 0.8329, 0.1820, 0.6152, 0.0602, 0.0169, 0.0107,\n",
              "            0.0335, 0.0044, 0.0228, 0.1891, 0.0108, 0.0269, 0.0078, 0.0297, 0.0975,\n",
              "            0.2359, 0.2490, 0.1848, 0.1913, 0.1434, 0.2726, 0.0501, 0.1333, 0.5780,\n",
              "            0.0537, 0.0600, 0.0170, 0.2259, 0.7902, 0.1016, 0.2995, 1.0177, 0.2738,\n",
              "            0.9824, 0.3465, 0.7565, 0.0746, 0.3033, 0.2003, 0.4166, 0.8907, 0.3212,\n",
              "            1.0158, 0.0247, 0.1463, 0.0097, 0.6267, 0.0049, 0.3394, 0.1564, 0.8349,\n",
              "            0.3253, 1.5604, 0.2039, 0.0214, 0.5022, 0.1219, 0.0562, 0.1203, 0.0658,\n",
              "            0.6830, 0.3105, 0.0530, 1.3069, 0.3291, 0.6554, 0.0378, 0.2168, 0.0142,\n",
              "            0.0301, 0.0179, 0.0207, 0.2354, 0.0684, 0.0437, 0.1867, 0.3372, 0.2250,\n",
              "            0.2770, 1.1375, 0.0324, 0.1941, 0.1385, 0.2040, 0.0436, 1.1079, 0.4994,\n",
              "            0.0248, 0.0096, 0.2675, 1.2310, 0.3490, 0.5959, 0.3580, 0.3480, 0.0313,\n",
              "            0.5512, 0.0110, 0.0166, 0.0100, 0.0194, 0.3658, 0.8887, 0.0292, 0.1439,\n",
              "            0.0368, 0.0127, 0.0099, 0.1667, 0.0844, 0.0454, 0.0602, 0.2249, 0.0480,\n",
              "            0.1614, 0.8905, 0.2316, 0.0725, 0.0405, 0.6386, 0.3211, 0.8306, 0.0099,\n",
              "            0.0167, 0.0288], dtype=torch.float64)},\n",
              "   20: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[-4.4280e-03, -3.3079e-04, -1.8159e-04,  ..., -7.2233e-04,\n",
              "              5.2491e-04,  0.0000e+00],\n",
              "            [ 2.6205e-03,  1.9727e-04,  1.0920e-04,  ...,  4.2790e-04,\n",
              "             -3.0895e-04,  0.0000e+00],\n",
              "            [-5.3709e-03, -4.0042e-04, -2.1932e-04,  ..., -8.7591e-04,\n",
              "              6.3760e-04,  0.0000e+00],\n",
              "            ...,\n",
              "            [ 3.4508e-03,  2.5864e-04,  1.4250e-04,  ...,  5.6317e-04,\n",
              "             -4.0811e-04,  0.0000e+00],\n",
              "            [-3.5366e-04, -2.8151e-05, -1.6288e-05,  ..., -5.8148e-05,\n",
              "              3.9915e-05,  0.0000e+00],\n",
              "            [-4.2837e-03, -3.2015e-04, -1.7584e-04,  ..., -6.9883e-04,\n",
              "              5.0766e-04,  0.0000e+00]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[1.3674e-04, 8.1681e-05, 1.3748e-04,  ..., 4.9244e-05, 5.0353e-05,\n",
              "             0.0000e+00],\n",
              "            [4.8524e-05, 2.9235e-05, 4.9479e-05,  ..., 1.7757e-05, 1.8348e-05,\n",
              "             0.0000e+00],\n",
              "            [2.0076e-04, 1.1975e-04, 2.0137e-04,  ..., 7.2118e-05, 7.3624e-05,\n",
              "             0.0000e+00],\n",
              "            ...,\n",
              "            [8.3434e-05, 4.9994e-05, 8.4322e-05,  ..., 3.0232e-05, 3.1039e-05,\n",
              "             0.0000e+00],\n",
              "            [8.3635e-07, 5.5757e-07, 1.0065e-06,  ..., 4.1602e-07, 5.2511e-07,\n",
              "             0.0000e+00],\n",
              "            [1.2799e-04, 7.6475e-05, 1.2874e-04,  ..., 4.6133e-05, 4.7200e-05,\n",
              "             0.0000e+00]], dtype=torch.float64)},\n",
              "   21: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([-5.0895e-03,  3.0168e-03, -6.1707e-03, -3.6296e-03,  5.4886e-03,\n",
              "            -4.3534e-03, -3.2156e-03, -1.1564e-03, -6.2006e-03, -1.7971e-03,\n",
              "             2.2951e-03,  4.2113e-03, -2.5268e-03, -4.4916e-03,  2.0216e-03,\n",
              "             6.7327e-04, -2.9209e-03,  4.9500e-03, -3.0672e-03, -5.6200e-03,\n",
              "             8.8552e-05,  5.4232e-03, -1.1361e-04,  4.1196e-03,  6.4643e-04,\n",
              "            -8.0362e-04, -1.0466e-03, -3.5316e-04, -6.4098e-03,  8.8240e-05,\n",
              "            -6.5193e-03, -3.2639e-04, -4.0936e-05,  5.3093e-04,  4.4935e-03,\n",
              "            -5.3811e-03,  5.4476e-03,  2.9699e-05,  3.3341e-03,  3.4005e-03,\n",
              "             5.7766e-03, -5.3646e-03, -4.6981e-03, -6.0735e-05,  3.8021e-03,\n",
              "            -1.0089e-03, -1.8103e-04,  2.9325e-03, -1.0587e-04,  6.3278e-03,\n",
              "            -1.6795e-03, -3.5052e-04,  3.7652e-03, -8.4830e-05, -2.4217e-03,\n",
              "             6.2757e-03,  4.9644e-03,  6.2076e-03, -3.6564e-03, -4.5464e-03,\n",
              "            -5.1778e-03,  2.4068e-03, -4.9973e-03, -3.9907e-03,  7.9341e-05,\n",
              "             3.9691e-03, -4.0970e-04, -4.9242e-03], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([1.2273e-03, 4.3962e-04, 1.7991e-03, 6.3193e-04, 1.4282e-03, 9.0239e-04,\n",
              "            4.9771e-04, 7.5781e-05, 1.8148e-03, 1.6750e-04, 2.6317e-04, 8.4294e-04,\n",
              "            3.1735e-04, 9.5678e-04, 2.0694e-04, 2.3785e-05, 4.1340e-04, 1.1612e-03,\n",
              "            4.5508e-04, 1.4944e-03, 8.8099e-07, 1.3918e-03, 1.1301e-06, 8.0857e-04,\n",
              "            2.1771e-05, 3.6737e-05, 6.1072e-05, 6.1450e-06, 1.9403e-03, 9.0627e-07,\n",
              "            2.0084e-03, 5.1815e-06, 6.6914e-07, 1.4685e-05, 9.5712e-04, 1.3728e-03,\n",
              "            1.4046e-03, 5.0223e-07, 5.3538e-04, 5.5561e-04, 1.5793e-03, 1.3609e-03,\n",
              "            1.0497e-03, 7.4541e-07, 6.8937e-04, 5.7143e-05, 2.2017e-06, 4.1747e-04,\n",
              "            1.1225e-06, 1.8932e-03, 1.4808e-04, 6.1832e-06, 6.7707e-04, 1.0103e-06,\n",
              "            2.9094e-04, 1.8618e-03, 1.1678e-03, 1.8235e-03, 6.3856e-04, 9.8174e-04,\n",
              "            1.2692e-03, 2.8821e-04, 1.1841e-03, 7.5833e-04, 8.4104e-07, 7.5139e-04,\n",
              "            8.4052e-06, 1.1491e-03], dtype=torch.float64)},\n",
              "   22: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([[-3.0948,  2.1125, -3.3972, -2.4816,  3.1102, -2.7626, -2.2481, -0.7120,\n",
              "             -3.4134, -1.2207,  1.5972,  2.7295, -1.7565, -2.8536,  1.4034,  0.4488,\n",
              "             -2.0368,  3.0297, -2.0995, -3.2187,  0.0376,  3.1752, -0.0828,  2.6938,\n",
              "              0.4503, -0.4965, -0.6069, -0.3207, -3.4475,  0.0093, -3.5045, -0.2868,\n",
              "              0.0229,  0.3904,  2.8388, -3.1239,  3.1519, -0.0258,  2.3248,  2.3848,\n",
              "              3.2661, -3.1929, -2.9294,  0.0052,  2.5248, -0.6177, -0.1835,  2.0760,\n",
              "             -0.0696,  3.4019, -1.0775, -0.3229,  2.5262, -0.0443, -1.7023,  3.4328,\n",
              "              3.0420,  3.3812, -2.4501, -2.8488, -3.1241,  1.7184, -3.0338, -2.6726,\n",
              "              0.0426,  2.6108, -0.3332, -3.0660,  0.0000]], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([[247.8333, 110.9031, 300.3122, 155.9519, 250.4449, 196.5615, 126.0601,\n",
              "              13.0228, 301.1699,  35.8144,  61.1737, 190.2808,  77.5652, 209.8229,\n",
              "              48.5766,   4.0133, 103.9964, 237.1791, 111.6553, 268.0184,   0.6251,\n",
              "             258.3892,   0.7404, 182.8976,   3.8802,   5.7979,   9.7765,   1.8217,\n",
              "             311.4536,   0.6251, 320.9890,   1.6853,   0.5547,   3.1276, 206.5914,\n",
              "             255.1068, 258.1209,   0.5397, 135.7153, 139.9599, 278.5936, 261.4388,\n",
              "             217.4118,   0.5912, 162.6900,   9.0567,   1.1516, 107.9405,   0.7385,\n",
              "             302.1035,  29.6468,   1.9030, 162.5321,   0.6826,  71.0814, 305.2279,\n",
              "             236.2888, 299.9550, 151.4635, 205.7476, 252.6811,  71.5860, 236.2160,\n",
              "             179.3736,   0.6057, 174.5665,   2.1708, 235.7006,   0.0000]],\n",
              "           dtype=torch.float64)},\n",
              "   23: {'step': tensor(6320.),\n",
              "    'exp_avg': tensor([0.0569], dtype=torch.float64),\n",
              "    'exp_avg_sq': tensor([0.1544], dtype=torch.float64)}},\n",
              "  'param_groups': [{'lr': 0.0001,\n",
              "    'betas': (0.9, 0.999),\n",
              "    'eps': 1e-08,\n",
              "    'weight_decay': 0,\n",
              "    'amsgrad': False,\n",
              "    'maximize': False,\n",
              "    'foreach': None,\n",
              "    'capturable': False,\n",
              "    'differentiable': False,\n",
              "    'fused': None,\n",
              "    'params': [0,\n",
              "     1,\n",
              "     2,\n",
              "     3,\n",
              "     4,\n",
              "     5,\n",
              "     6,\n",
              "     7,\n",
              "     8,\n",
              "     9,\n",
              "     10,\n",
              "     11,\n",
              "     12,\n",
              "     13,\n",
              "     14,\n",
              "     15,\n",
              "     16,\n",
              "     17,\n",
              "     18,\n",
              "     19,\n",
              "     20,\n",
              "     21,\n",
              "     22,\n",
              "     23]}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BoneAgePredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BoneAgePredictor, self).__init__()\n",
        "        # Layer 1\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        self.batch1 = nn.BatchNorm2d(16)\n",
        "        # Layer 2\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        self.batch2 = nn.BatchNorm2d(32)\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
        "        nn.init.kaiming_normal_(self.conv3.weight)\n",
        "        self.batch3 = nn.BatchNorm2d(64)\n",
        "        # Layer 4\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3)\n",
        "        nn.init.kaiming_normal_(self.conv4.weight)\n",
        "        self.batch4 = nn.BatchNorm2d(128)\n",
        "        # Layer 5\n",
        "        self.conv5 = nn.Conv2d(128, 128, 3)\n",
        "        nn.init.kaiming_normal_(self.conv5.weight)\n",
        "        self.batch5 = nn.BatchNorm2d(128)\n",
        "        # Fully connected\n",
        "        self.fc1 = nn.Linear(4609, 68)\n",
        "        self.fc2 = nn.Linear(69, 1)\n",
        "        #self.fc2 = nn.Linear(64, 1)\n",
        "    \n",
        "        \n",
        "\n",
        "    def forward(self, x, m):\n",
        "        # Layer 1\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # Layer 2\n",
        "        x = F.relu(self.batch2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # Layer 3\n",
        "        x = F.relu(self.batch3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # Layer 4\n",
        "        x = F.relu(self.batch4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        # Layer 5\n",
        "        x = F.relu(self.batch5(self.conv5(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        # Pooling\n",
        "        x = x.view(-1,4608)\n",
        "        x = torch.cat((x,m), axis = 1)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.cat((x,m), axis = 1)\n",
        "        x = self.fc2(x)\n",
        "        #x = torch.cat((x,m), axis = 1)\n",
        "        #x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fdvPXez8LkH8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target, male) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data, male)\n",
        "        loss = F.l1_loss(output.view(-1), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                #epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                #100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "UXdVbnBtFghc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, device, val_loader, loader_name):\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target, male) in enumerate(val_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data, male)\n",
        "            loss += F.l1_loss(output.view(-1), target, reduction='sum').item()  # sum up batch loss            \n",
        "    loss /= len(val_loader.dataset)\n",
        "    print('\\n', loader_name, 'set: Average loss: {:.4f}\\n'.format(loss))\n",
        "    return loss;\n",
        "     "
      ],
      "metadata": {
        "id": "C50cnWSk5miu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
        "trainig_data_loader = torch.utils.data.DataLoader(\n",
        "    BoneAgeTrainingDataset('train_z.csv', 'boneage_training_dataset'),\n",
        "    batch_size=32, shuffle=True, **kwargs)\n",
        "validation_data_loader = torch.utils.data.DataLoader(\n",
        "    BoneAgeValidationDataset('validation_z.csv', 'boneage_validation_dataset'),\n",
        "    batch_size=32, shuffle=True, **kwargs)\n",
        "#testing_data_loader = torch.utils.data.DataLoader(\n",
        "    #BoneAgeTestingDataset('boneage-test-dataset.csv', 'boneage-test-dataset'),\n",
        "    #batch_size=32, shuffle=True, **kwargs)"
      ],
      "metadata": {
        "id": "ns7Mm3vQG1MH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gl_umZr6bJD",
        "outputId": "4ced1790-4caf-453e-b886-83c6fd834efc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BoneAgePredictor()"
      ],
      "metadata": {
        "id": "1KAuP2InSjhl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(state_model)\n",
        "model\n",
        "print(model)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=2, min_lr=0.0001, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "nPQsyeOTH0ny",
        "outputId": "2a3fdab8-4474-457f-dc1f-bc278a564fe4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6107adc189a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BoneAgePredictor:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"batch1.weight\", \"batch1.bias\", \"batch1.running_mean\", \"batch1.running_var\", \"conv2.weight\", \"conv2.bias\", \"batch2.weight\", \"batch2.bias\", \"batch2.running_mean\", \"batch2.running_var\", \"conv3.weight\", \"conv3.bias\", \"batch3.weight\", \"batch3.bias\", \"batch3.running_mean\", \"batch3.running_var\", \"conv4.weight\", \"conv4.bias\", \"batch4.weight\", \"batch4.bias\", \"batch4.running_mean\", \"batch4.running_var\", \"conv5.weight\", \"conv5.bias\", \"batch5.weight\", \"batch5.bias\", \"batch5.running_mean\", \"batch5.running_var\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"train_loss\", \"val_loss\", \"state_dict\", \"optimizer\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(20):\n",
        "        train(model, device, trainig_data_loader, optimizer, epoch)\n",
        "        train_loss = validation(model, device, trainig_data_loader,'Train')\n",
        "        val_loss = validation(model, device, validation_data_loader,'Validation')\n",
        "        scheduler.step(val_loss)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        checkpoint = torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_losses,\n",
        "            'val_loss': val_losses,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        },'model_2.pth')"
      ],
      "metadata": {
        "id": "sizddBfdIOdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('model_2.pth')\n",
        "checkpoint"
      ],
      "metadata": {
        "id": "hOhIfAkzP8-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model"
      ],
      "metadata": {
        "id": "-0h6W09LQDk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "optimizer"
      ],
      "metadata": {
        "id": "Qz4_E9D_QPAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = checkpoint['epoch']\n",
        "epoch"
      ],
      "metadata": {
        "id": "32OaBblOQQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = checkpoint['train_loss']\n",
        "train_loss"
      ],
      "metadata": {
        "id": "I6DEgWiGQSZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = checkpoint['val_loss']\n",
        "val_loss"
      ],
      "metadata": {
        "id": "qKzmpDroQULH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_losses, color='blue', linestyle='-', label='train loss')\n",
        "plt.plot(val_losses, color='red', linestyle='-', label='validataion loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L9yO8wiupb1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check = torch.rand(5,1,256,256)\n",
        "# model = BoneAgePredictor();\n",
        "# print(model.forward(check).size())"
      ],
      "metadata": {
        "id": "JV1tLDbUCw0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check = pd.read_csv(dataset_path('boneage-training-dataset.csv'));\n",
        "# print(check)\n",
        "# print(check['boneage'][0])\n",
        "# print(check['id'][1])\n",
        "# check = Image.open(dataset_path('boneage-training-dataset',str(check['id'][1])+'.png')).resize((256,256))\n",
        "# print(check)\n",
        "# # check = transform(check)\n",
        "# # print(check.size())\n",
        "# # check = torch.from_numpy(np.array(check['boneage'][0]))\n",
        "# # print(check)"
      ],
      "metadata": {
        "id": "W1zPxAL38T_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}